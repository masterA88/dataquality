{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: list index out of range\n",
      "['\\ufeffTTB000043833962', '8701', 'Blokir Kartu ATM karena kartu hilang', '2023-01-01 07:08:31.000', 'Phone', 'Maintenance', 'WATI SUSILAWATI', '436101009806534', '0.00', 'Closed', '2023-01-01 07:08:50.000', '2023-01-01 00:00:00.000', 'N/A', 'Blokir Kartu', '6013013389522694', 'LCC-CCTCALL', 'NULL', 'NULL', 'NULL', 'Novita Ayu Lestari', '085845602167', 'NULL', 'NULL', '20', 'SMG61072', '00196 -- KANWIL Semarang', 'Novita Ayu Lestari', 'Nasabah mengajukan pemblokiran kartu ATM BRI']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# List to store extracted data\n",
    "extracted_data = []\n",
    "\n",
    "try:\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        # Create a reader object to parse the CSV\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for row in reader:\n",
    "            # Assuming the data is located in a specific column, e.g., the first column\n",
    "            if \"TTB000043833962\" in row[0]:\n",
    "                extracted_data.append(row)  # Append the entire row if the ID is found\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "# Print the extracted data\n",
    "for data in extracted_data:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket_ID: TTB000043833962\n",
      "Call_Type_ID: 8701\n",
      "Call_Type: Blokir Kartu ATM karena kartu hilang\n",
      "Create_Date: 2023-01-01 07:08:31.000\n",
      "Phone: Phone\n",
      "Maintenance: Maintenance\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# File path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Regular expression patterns for the data points you listed\n",
    "patterns = {\n",
    "    \"Ticket_ID\": re.compile(r\"TTB\\d+\"),\n",
    "    \"Call_Type_ID\": re.compile(r\"\\b\\d{4}\\b\"),\n",
    "    \"Call_Type\": re.compile(r\"Blokir Kartu ATM karena kartu hilang\"),\n",
    "    \"Create_Date\": re.compile(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\"),\n",
    "    \"gateway\": re.compile(r\"Phone\"),\n",
    "    \"Maintenance\": re.compile(r\"Maintenance\"),\n",
    "    # Add more patterns as necessary\n",
    "}\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {key: None for key in patterns}\n",
    "\n",
    "# Read the file and search for patterns\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        for key, pattern in patterns.items():\n",
    "            match = pattern.search(content)\n",
    "            if match:\n",
    "                results[key] = match.group()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to read or process the file: {str(e)}\")\n",
    "\n",
    "# Display the results\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\n",
    "        \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "        \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "        \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assgined_to\", \"attachment_done\", \n",
    "        \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "        \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \"Jenis_Produk\", \n",
    "        \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \n",
    "        \"TID\", \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \n",
    "        \"Bank_BRI\", \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \n",
    "        \"Hasil_Kunjungan\", \"Log_Name\", \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \n",
    "        \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \"Notify_By\", \"Organization\", \n",
    "        \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \"Settlement_ID\", \n",
    "        \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "        \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \n",
    "        \"Tgl_In_Progress\", \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \n",
    "        \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "    ]\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "col = [\n",
    "        \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "        \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "        \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assgined_to\", \"attachment_done\", \n",
    "        \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "        \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \"Jenis_Produk\", \n",
    "        \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \n",
    "        \"TID\", \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \n",
    "        \"Bank_BRI\", \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \n",
    "        \"Hasil_Kunjungan\", \"Log_Name\", \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \n",
    "        \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \"Notify_By\", \"Organization\", \n",
    "        \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \"Settlement_ID\", \n",
    "        \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "        \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \n",
    "        \"Tgl_In_Progress\", \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \n",
    "        \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "    ]\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "def process_csv_with_complex_column(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the entire file content into a single string to process it line by line\n",
    "        content = file.read()\n",
    "        \n",
    "        # Split the content into rows based on a pattern that indicates the end of a complex entry\n",
    "        rows = content.split('================')  # This splits each \"block\" that should end up in Column 28\n",
    "        data = []\n",
    "\n",
    "        for row in rows:\n",
    "            # Split each row by commas up to Column 27, handle Column 28 separately, then continue after Column 28\n",
    "            parts = row.split(',')\n",
    "            if len(parts) > 29:  # Ensuring there are enough parts to form all columns\n",
    "                # The first 27 columns + the entire block of text that goes into Column 28\n",
    "                first_part = parts[:27]\n",
    "                col28 = ','.join(parts[27:-51])  # Joining parts that form the complex Column 28 (adjust range as needed)\n",
    "                last_part = parts[-51:]  # Remaining columns after Column 28\n",
    "                \n",
    "                # Combine all parts into a single row, ensuring 79 columns total\n",
    "                full_row = first_part + [col28] + last_part\n",
    "                if len(full_row) == 79:\n",
    "                    data.append(full_row)\n",
    "\n",
    "    # Create a DataFrame from the processed data\n",
    "    return pd.DataFrame(data, columns=col)\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path_v2 = file_path\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_v4 = process_csv_with_complex_column(csv_file_path_v2)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_v4_sample = structured_df_v4.head(10) if not structured_df_v4.empty else \"No data processed correctly.\"\n",
    "df2=structured_df_v4_sample.transpose()\n",
    "pd.set_option('display.max_columns', None)\n",
    "df2.to_csv(\"data_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>Column 10</th>\n",
       "      <th>Column 11</th>\n",
       "      <th>Column 12</th>\n",
       "      <th>Column 13</th>\n",
       "      <th>Column 14</th>\n",
       "      <th>Column 15</th>\n",
       "      <th>Column 16</th>\n",
       "      <th>Column 17</th>\n",
       "      <th>Column 18</th>\n",
       "      <th>Column 19</th>\n",
       "      <th>Column 20</th>\n",
       "      <th>Column 21</th>\n",
       "      <th>Column 22</th>\n",
       "      <th>Column 23</th>\n",
       "      <th>Column 24</th>\n",
       "      <th>Column 25</th>\n",
       "      <th>Column 26</th>\n",
       "      <th>Column 27</th>\n",
       "      <th>Column 28</th>\n",
       "      <th>Column 29</th>\n",
       "      <th>Column 30</th>\n",
       "      <th>Column 31</th>\n",
       "      <th>Column 32</th>\n",
       "      <th>Column 33</th>\n",
       "      <th>Column 34</th>\n",
       "      <th>Column 35</th>\n",
       "      <th>Column 36</th>\n",
       "      <th>Column 37</th>\n",
       "      <th>Column 38</th>\n",
       "      <th>Column 39</th>\n",
       "      <th>Column 40</th>\n",
       "      <th>Column 41</th>\n",
       "      <th>Column 42</th>\n",
       "      <th>Column 43</th>\n",
       "      <th>Column 44</th>\n",
       "      <th>Column 45</th>\n",
       "      <th>Column 46</th>\n",
       "      <th>Column 47</th>\n",
       "      <th>Column 48</th>\n",
       "      <th>Column 49</th>\n",
       "      <th>Column 50</th>\n",
       "      <th>Column 51</th>\n",
       "      <th>Column 52</th>\n",
       "      <th>Column 53</th>\n",
       "      <th>Column 54</th>\n",
       "      <th>Column 55</th>\n",
       "      <th>Column 56</th>\n",
       "      <th>Column 57</th>\n",
       "      <th>Column 58</th>\n",
       "      <th>Column 59</th>\n",
       "      <th>Column 60</th>\n",
       "      <th>Column 61</th>\n",
       "      <th>Column 62</th>\n",
       "      <th>Column 63</th>\n",
       "      <th>Column 64</th>\n",
       "      <th>Column 65</th>\n",
       "      <th>Column 66</th>\n",
       "      <th>Column 67</th>\n",
       "      <th>Column 68</th>\n",
       "      <th>Column 69</th>\n",
       "      <th>Column 70</th>\n",
       "      <th>Column 71</th>\n",
       "      <th>Column 72</th>\n",
       "      <th>Column 73</th>\n",
       "      <th>Column 74</th>\n",
       "      <th>Column 75</th>\n",
       "      <th>Column 76</th>\n",
       "      <th>Column 77</th>\n",
       "      <th>Column 78</th>\n",
       "      <th>Column 79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>085845602167</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>Nasabah mengajukan pemblokiran kartu ATM BRI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Permintaan pemblokiran ATM BRI.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alasan pemblokiran : Hilang</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tanggal Hilang : 31.12.2022</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jam Hilang : 21.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lokasi Kejadian : bri cikunir</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tanggal Pemblokiran :  01/01/2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jam Pemblokiran :  07:06 wib</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>================</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Column 1 Column 2  \\\n",
       "0                    ﻿TTB000043833962     8701   \n",
       "1     Permintaan pemblokiran ATM BRI.            \n",
       "2         Alasan pemblokiran : Hilang            \n",
       "3         Tanggal Hilang : 31.12.2022            \n",
       "4                  Jam Hilang : 21.00            \n",
       "5       Lokasi Kejadian : bri cikunir            \n",
       "6  Tanggal Pemblokiran :  01/01/2023             \n",
       "7        Jam Pemblokiran :  07:06 wib            \n",
       "8                                                \n",
       "9                    ================            \n",
       "\n",
       "                               Column 3                 Column 4 Column 5  \\\n",
       "0  Blokir Kartu ATM karena kartu hilang  2023-01-01 07:08:31.000    Phone   \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "5                                                                           \n",
       "6                                                                           \n",
       "7                                                                           \n",
       "8                                                                           \n",
       "9                                                                           \n",
       "\n",
       "      Column 6         Column 7         Column 8 Column 9 Column 10  \\\n",
       "0  Maintenance  WATI SUSILAWATI  436101009806534     0.00    Closed   \n",
       "1                                                                     \n",
       "2                                                                     \n",
       "3                                                                     \n",
       "4                                                                     \n",
       "5                                                                     \n",
       "6                                                                     \n",
       "7                                                                     \n",
       "8                                                                     \n",
       "9                                                                     \n",
       "\n",
       "                 Column 11                Column 12 Column 13     Column 14  \\\n",
       "0  2023-01-01 07:08:50.000  2023-01-01 00:00:00.000       N/A  Blokir Kartu   \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "5                                                                             \n",
       "6                                                                             \n",
       "7                                                                             \n",
       "8                                                                             \n",
       "9                                                                             \n",
       "\n",
       "          Column 15    Column 16 Column 17 Column 18 Column 19  \\\n",
       "0  6013013389522694  LCC-CCTCALL      NULL      NULL      NULL   \n",
       "1                                                                \n",
       "2                                                                \n",
       "3                                                                \n",
       "4                                                                \n",
       "5                                                                \n",
       "6                                                                \n",
       "7                                                                \n",
       "8                                                                \n",
       "9                                                                \n",
       "\n",
       "            Column 20     Column 21 Column 22 Column 23 Column 24 Column 25  \\\n",
       "0  Novita Ayu Lestari  085845602167      NULL      NULL        20  SMG61072   \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "5                                                                             \n",
       "6                                                                             \n",
       "7                                                                             \n",
       "8                                                                             \n",
       "9                                                                             \n",
       "\n",
       "                  Column 26           Column 27  \\\n",
       "0  00196 -- KANWIL Semarang  Novita Ayu Lestari   \n",
       "1                                                 \n",
       "2                                                 \n",
       "3                                                 \n",
       "4                                                 \n",
       "5                                                 \n",
       "6                                                 \n",
       "7                                                 \n",
       "8                                                 \n",
       "9                                                 \n",
       "\n",
       "                                      Column 28 Column 29 Column 30 Column 31  \\\n",
       "0  Nasabah mengajukan pemblokiran kartu ATM BRI                                 \n",
       "1                                                                               \n",
       "2                                                                               \n",
       "3                                                                               \n",
       "4                                                                               \n",
       "5                                                                               \n",
       "6                                                                               \n",
       "7                                                                               \n",
       "8                                                                               \n",
       "9                                                                               \n",
       "\n",
       "  Column 32 Column 33 Column 34 Column 35 Column 36 Column 37 Column 38  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 39 Column 40 Column 41 Column 42 Column 43 Column 44 Column 45  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 46 Column 47 Column 48 Column 49 Column 50 Column 51 Column 52  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 53 Column 54 Column 55 Column 56 Column 57 Column 58 Column 59  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 60 Column 61 Column 62 Column 63 Column 64 Column 65 Column 66  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 67 Column 68 Column 69 Column 70 Column 71 Column 72 Column 73  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 74 Column 75 Column 76 Column 77 Column 78 Column 79  \n",
       "0                                                              \n",
       "1                                                              \n",
       "2                                                              \n",
       "3                                                              \n",
       "4                                                              \n",
       "5                                                              \n",
       "6                                                              \n",
       "7                                                              \n",
       "8                                                              \n",
       "9                                                              "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Initialize a list to store the processed rows\n",
    "        data = []\n",
    "        \n",
    "        # Read the file line by line\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # Extract the first 27 columns directly\n",
    "            if len(row) < 79:\n",
    "                # Append empty fields if row is not long enough (handling potential errors in CSV formatting)\n",
    "                row += [''] * (79 - len(row))\n",
    "            \n",
    "            # Columns 1-27 are directly taken from the row based on your mapping\n",
    "            first_part = row[:27]\n",
    "            \n",
    "            # Column 28: Aggregating complex block data into one column (Example aggregation logic needed)\n",
    "            complex_data = ' '.join(row[27:28])  # Assuming we collect multiple pieces into one column here\n",
    "            \n",
    "            # Remaining columns, from 29 to 79\n",
    "            last_part = row[28:]\n",
    "\n",
    "            # Combine the parts into a full row ensuring it matches the expected 79 columns format\n",
    "            full_row = first_part + [complex_data] + last_part[:51]  # Adjust the slicing based on actual content need\n",
    "            if len(full_row) == 79:\n",
    "                data.append(full_row)\n",
    "            else:\n",
    "                # Padding in case there are missing columns to ensure each row has exactly 79 columns\n",
    "                full_row += [''] * (79 - len(full_row))\n",
    "                data.append(full_row)\n",
    "\n",
    "    # Create a DataFrame from the processed data\n",
    "    return pd.DataFrame(data, columns=[f\"Column {i+1}\" for i in range(79)])\n",
    "\n",
    "# Path to the updated CSV file\n",
    "updated_csv_file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(updated_csv_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Display a sample of the structured data\n",
    "pd.set_option('display.max_columns', None)\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "# structured_df_final_sample['Column 1'] = structured_df_final_sample['Column 1'].apply(lambda x: x if x.startswith('TTB') and len(x) == 15 else None)\n",
    "# structured_df_final_sample['Column 1'] = structured_df_final_sample.dropna(subset=['Column 1'])\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st 27 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>Column 10</th>\n",
       "      <th>Column 11</th>\n",
       "      <th>Column 12</th>\n",
       "      <th>Column 13</th>\n",
       "      <th>Column 14</th>\n",
       "      <th>Column 15</th>\n",
       "      <th>Column 16</th>\n",
       "      <th>Column 17</th>\n",
       "      <th>Column 18</th>\n",
       "      <th>Column 19</th>\n",
       "      <th>Column 20</th>\n",
       "      <th>Column 21</th>\n",
       "      <th>Column 22</th>\n",
       "      <th>Column 23</th>\n",
       "      <th>Column 24</th>\n",
       "      <th>Column 25</th>\n",
       "      <th>Column 26</th>\n",
       "      <th>Column 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>8.584560e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column 1 Column 2                              Column 3  \\\n",
       "0  TTB000043833962     8701  Blokir Kartu ATM karena kartu hilang   \n",
       "\n",
       "                  Column 4 Column 5     Column 6         Column 7  \\\n",
       "0  2023-01-01 07:08:31.000    Phone  Maintenance  WATI SUSILAWATI   \n",
       "\n",
       "          Column 8  Column 9 Column 10                Column 11  \\\n",
       "0  436101009806534       0.0    Closed  2023-01-01 07:08:50.000   \n",
       "\n",
       "                 Column 12  Column 13     Column 14         Column 15  \\\n",
       "0  2023-01-01 00:00:00.000        NaN  Blokir Kartu  6013013389522694   \n",
       "\n",
       "     Column 16  Column 17  Column 18 Column 19           Column 20  \\\n",
       "0  LCC-CCTCALL        NaN        NaN       NaN  Novita Ayu Lestari   \n",
       "\n",
       "      Column 21 Column 22  Column 23 Column 24 Column 25  \\\n",
       "0  8.584560e+10       NaN        NaN        20  SMG61072   \n",
       "\n",
       "                  Column 26           Column 27  \n",
       "0  00196 -- KANWIL Semarang  Novita Ayu Lestari  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "column_headers = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "    \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "    \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assigned_to\", \"attachment_done\", \n",
    "    \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "    \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\"\n",
    "]\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    # Load the CSV file into a DataFrame, processing only the necessary columns (first 27 columns)\n",
    "    df = pd.read_csv(file_path, usecols=range(27), header=None)\n",
    "\n",
    "    df = df.iloc[:1]\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    df.columns = [f\"Column {i+1}\" for i in range(27)]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(file_path)\n",
    "\n",
    "# Set display options for better output visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket_ID</th>\n",
       "      <th>Call_Type_ID</th>\n",
       "      <th>Call_Type</th>\n",
       "      <th>Create_Date</th>\n",
       "      <th>gateway</th>\n",
       "      <th>Jenis_Laporan</th>\n",
       "      <th>Nama_Nasabah</th>\n",
       "      <th>No_Rekening</th>\n",
       "      <th>Nominal</th>\n",
       "      <th>status</th>\n",
       "      <th>TanggalClosed</th>\n",
       "      <th>tanggalTransaksi</th>\n",
       "      <th>Chanel</th>\n",
       "      <th>Fitur</th>\n",
       "      <th>Nomor_Kartu</th>\n",
       "      <th>user_group</th>\n",
       "      <th>assigned_to</th>\n",
       "      <th>attachment_done</th>\n",
       "      <th>email</th>\n",
       "      <th>full_name</th>\n",
       "      <th>no_telepon</th>\n",
       "      <th>approver_login</th>\n",
       "      <th>approver_name</th>\n",
       "      <th>SLAResolution</th>\n",
       "      <th>submitter_login_id</th>\n",
       "      <th>submitter_user_group</th>\n",
       "      <th>user_login_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>8.584560e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket_ID Call_Type_ID                             Call_Type  \\\n",
       "0  TTB000043833962         8701  Blokir Kartu ATM karena kartu hilang   \n",
       "\n",
       "               Create_Date gateway Jenis_Laporan     Nama_Nasabah  \\\n",
       "0  2023-01-01 07:08:31.000   Phone   Maintenance  WATI SUSILAWATI   \n",
       "\n",
       "       No_Rekening  Nominal  status            TanggalClosed  \\\n",
       "0  436101009806534      0.0  Closed  2023-01-01 07:08:50.000   \n",
       "\n",
       "          tanggalTransaksi  Chanel         Fitur       Nomor_Kartu  \\\n",
       "0  2023-01-01 00:00:00.000     NaN  Blokir Kartu  6013013389522694   \n",
       "\n",
       "    user_group  assigned_to  attachment_done email           full_name  \\\n",
       "0  LCC-CCTCALL          NaN              NaN   NaN  Novita Ayu Lestari   \n",
       "\n",
       "     no_telepon approver_login  approver_name SLAResolution  \\\n",
       "0  8.584560e+10            NaN            NaN            20   \n",
       "\n",
       "  submitter_login_id      submitter_user_group     user_login_name  \n",
       "0           SMG61072  00196 -- KANWIL Semarang  Novita Ayu Lestari  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Specified column headers\n",
    "column_headers = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "    \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "    \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assigned_to\", \"attachment_done\", \n",
    "    \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "    \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\"\n",
    "]\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    # Load the CSV file into a DataFrame, processing only the necessary columns (first 27 columns)\n",
    "    df = pd.read_csv(file_path, usecols=range(27), header=None)\n",
    "\n",
    "    df = df.iloc[:1]\n",
    "\n",
    "    # Rename columns using the specified column headers\n",
    "    df.columns = column_headers\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(file_path)\n",
    "\n",
    "# Set display options for better output visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Splitting the text into a more manageable format\n",
    "    # Assume we split at the first occurrence of '================'\n",
    "    parts = text.split('================', 1)\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    # Column 1 will have 'Aku', Column 2 will have the rest of the text after '================'\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [\"Aku\"],\n",
    "        \"Column 2\": [parts[1].strip()]  # Using strip to remove leading/trailing whitespace\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace 'path_to_your_file.txt' with the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Splitting the text to extract the third column value\n",
    "    # Assume 'Tabungan' or similar values are added after the final '================,' so we split there first\n",
    "    parts = text.split('================,')\n",
    "    third_column_value = parts[1].strip() if len(parts) > 1 else \"Missing Value\"\n",
    "    \n",
    "    # Now split the first part further to separate out the main content\n",
    "    main_content_parts = parts[0].split('================', 1)\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    # Column 1 will have 'Aku', Column 2 will have the content after the first '================',\n",
    "    # and Column 3 will have the value from the third column\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [\"Aku\"],\n",
    "        \"Column 2\": [main_content_parts[1].strip() if len(main_content_parts) > 1 else \"Missing Content\"],  # Handle missing content\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace 'path_to_your_file.txt' with the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# search the ================, and set the value to be the value for the next column\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## great for 3 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Find the beginning of the content after \"Aku,\" to set up for Column 2\n",
    "    first_column_value = \"Aku\"\n",
    "    second_column_start = main_content.find(\"Aku,\") + len(\"Aku,\")\n",
    "    second_column_value = main_content[second_column_start:].strip()  # Remove any leading/trailing whitespace\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\" \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "# df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "\n",
    "df.to_csv(\"new_.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 4 starting from Kode ..., Column 5= empty, Column 6 Tabungan1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text using '================' as a separator\n",
    "    parts = text.split('================')\n",
    "    \n",
    "    # Assume the first line contains the labels for the first three columns, which are static\n",
    "    header_labels = parts[0].strip().split('\\n')[0].split(',')\n",
    "    if len(header_labels) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"Header format is not as expected. Check the first line for correct labels.\"]})\n",
    "\n",
    "    # Extracting the main body for Column 4, which includes multiple '================' sections\n",
    "    column4_content = '================'.join(parts[1:-1]).strip()\n",
    "\n",
    "    # Extract the last part for Columns 5 and 6\n",
    "    footer_labels = parts[-1].split(',')\n",
    "    if len(footer_labels) < 2:\n",
    "        return pd.DataFrame({\"Error\": [\"Footer format is not as expected. Insufficient labels after the last '================'.\"]})\n",
    "\n",
    "    # Trim and prepare the labels for the last two columns\n",
    "    column5_label = footer_labels[0].strip()\n",
    "    column6_label = footer_labels[1].strip()\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [header_labels[0].strip()],\n",
    "        \"Column 2\": [header_labels[1].strip()],\n",
    "        \"Column 3\": [header_labels[2].strip()],\n",
    "        \"Column 4\": [column4_content],\n",
    "        \"Column 5\": [column5_label],\n",
    "        \"Column 6\": [column6_label]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new4_.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text using '================' as a separator to isolate the main content and footer\n",
    "    parts = text.split('================')\n",
    "    if len(parts) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"The text does not contain enough sections separated by '================'.\"]})\n",
    "\n",
    "    # Extracting the main body for Column 4, assumed to be between the first and second '================'\n",
    "    column4_content = '\\n================\\n'.join(parts[1:-1]).strip()\n",
    "\n",
    "    # Extract the footer content right after the last '================'\n",
    "    # Assuming the footer starts with Tabungan1, Tabungan2 right after the last '================'\n",
    "    # footer_content = parts[-1].split(',')\n",
    "    # if len(footer_content) < 2:\n",
    "    #     return pd.DataFrame({\"Error\": [\"Footer content is not formatted as expected. Ensure it follows the last '================'.\"]})\n",
    "\n",
    "    footer_content=text.split('================,', 1)\n",
    "    # The first header should contain main labels if structured as expected\n",
    "    header_labels = parts[0].strip().split('\\n')[0].split(',')\n",
    "    if len(header_labels) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"Header labels are missing or incomplete.\"]})\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [header_labels[0].strip()],\n",
    "        \"Column 2\": [header_labels[1].strip()],\n",
    "        \"Column 3\": [header_labels[2].strip()],\n",
    "        \"Column 4\": [column4_content],\n",
    "        \"Column 5\": [footer_content[0].strip()]\n",
    "        # \"Column 5\": [footer_content[0].strip()],\n",
    "        # \"Column 6\": [footer_content[1].strip()]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new5_.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Column0 Column1\n",
      "0    Tab1    Tab2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with one column\n",
    "df = pd.DataFrame({'Column1': ['Tab1, Tab2']})\n",
    "\n",
    "# Split the single value in the column by comma (assuming there's only one comma)\n",
    "split_values = df['Column1'].str.split(',', expand=True)\n",
    "\n",
    "# Rename columns (optional)\n",
    "split_values.columns = ['Column0', 'Column1']\n",
    "\n",
    "# Update the DataFrame\n",
    "df = split_values.copy()\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main</td>\n",
       "      <td>Nasabah mengajukan pemblokiran kartu ATM BRI\\n...</td>\n",
       "      <td>Tabungan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column 1                                           Column 2  Column 3\n",
       "0     Main  Nasabah mengajukan pemblokiran kartu ATM BRI\\n...  Tabungan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "# df.to_csv(\"new_.csv\")\n",
    "df.to_csv(\"newbig_.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# file_path=r\"D:\\dataquality\\new_.csv\"\n",
    "file_path=r\"D:\\dataquality\\newbig_.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "column_2_expanded = data['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = data['Column 3'].str.split(',', expand=True)\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Naming the new columns\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "# Inserting these new columns before the original 'Column 2' and 'Column 3'\n",
    "new_data = pd.concat([data.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"new_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRICARE cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column 1 Column_2_1                            Column_2_2  \\\n",
      "0  ﻿TTB000043833962       8701  Blokir Kartu ATM karena kartu hilang   \n",
      "\n",
      "                Column_2_3 Column_2_4   Column_2_5       Column_2_6  \\\n",
      "0  2023-01-01 07:08:31.000      Phone  Maintenance  WATI SUSILAWATI   \n",
      "\n",
      "        Column_2_7 Column_2_8 Column_2_9  ... Column_3_42 Column_3_43  \\\n",
      "0  436101009806534       0.00     Closed  ...        NULL        NULL   \n",
      "\n",
      "  Column_3_44 Column_3_45 Column_3_46 Column_3_47 Column_3_48 Column_3_49  \\\n",
      "0        NULL        NULL        NULL        NULL       Notes        NULL   \n",
      "\n",
      "  Column_3_50      Column_3_51  \n",
      "0        Call  000000000000004  \n",
      "\n",
      "[1 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()\n",
    "\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "    second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "file_path = r\"D:\\test.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "column_2_expanded = df['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Column 3'].str.split(',', expand=True)\n",
    "\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "new_data = pd.concat([df.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"test.csv\")\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Ticket_ID Call_Type_ID                             Call_Type  \\\n",
      "0  ﻿TTB000043833962         8701  Blokir Kartu ATM karena kartu hilang   \n",
      "\n",
      "               Create_Date gateway Jenis_Laporan     Nama_Nasabah  \\\n",
      "0  2023-01-01 07:08:31.000   Phone   Maintenance  WATI SUSILAWATI   \n",
      "\n",
      "       No_Rekening Nominal  status  ... Tanggal_Settlement Tgl_Foward  \\\n",
      "0  436101009806534    0.00  Closed  ...               NULL       NULL   \n",
      "\n",
      "  Tgl_In_Progress Tgl_Returned Ticket_Referensi Tiket_Urgency Tipe_Remark  \\\n",
      "0            NULL         NULL             NULL          NULL       Notes   \n",
      "\n",
      "  UniqueID users     Usergroup_ID  \n",
      "0     NULL  Call  000000000000004  \n",
      "\n",
      "[1 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()\n",
    "\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "    second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "    # Create a DataFrame with initial rough columns\n",
    "    df = pd.DataFrame({\n",
    "        \"Initial_Column_1\": [first_column_value],\n",
    "        \"Initial_Column_2\": [second_column_value],\n",
    "        \"Initial_Column_3\": [third_column_value]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "file_path = r\"D:\\test.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "# Assuming 'Initial_Column_2' and 'Initial_Column_3' need to be expanded into multiple columns\n",
    "column_2_expanded = df['Initial_Column_2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Initial_Column_3'].str.split(',', expand=True)\n",
    "\n",
    "# List of all column names\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "# Concatenate expanded columns with the original DataFrame, dropping the initial columns used for expansion\n",
    "new_data = pd.concat([df.drop(['Initial_Column_2', 'Initial_Column_3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "# Ensure the total columns in DataFrame matches with the length of column_names\n",
    "new_data.columns = column_names[:new_data.shape[1]]\n",
    "\n",
    "new_data.to_csv(\"test.csv\")\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Line 1 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 2 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 3 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 4 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 5 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 6 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 7 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 8 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 9 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 10 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 11 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 12 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 13 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 14 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 15 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 16 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 17 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 18 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 19 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 20 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 21 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 22 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 23 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 24 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 25 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 26 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 27 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 28 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 29 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 30 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 31 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 32 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 33 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_df\n\u001b[0;32m     27\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest_bricare2line.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m---> 28\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataframe_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m column_2_expanded \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn 2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m column_3_expanded \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn 3\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mcreate_dataframe_from_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m formatted incorrectly and was skipped. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Concatenate all DataFrames into a single DataFrame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m combined_df\n",
      "File \u001b[1;32mc:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    dataframes = []  # List to hold all individual DataFrames\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line_number, line in enumerate(file, 1):  # Process each line individually\n",
    "            try:\n",
    "                main_content, third_column_value = line.split('================,', 1)\n",
    "                third_column_value = third_column_value.strip()\n",
    "\n",
    "                first_column_value = main_content.split(',', 1)[0].strip()\n",
    "                second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "                df = pd.DataFrame({\n",
    "                    \"Column 1\": [first_column_value],\n",
    "                    \"Column 2\": [second_column_value],\n",
    "                    \"Column 3\": [third_column_value]\n",
    "                })\n",
    "                dataframes.append(df)\n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: Line {line_number} formatted incorrectly and was skipped. Error: {str(e)}\")\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "file_path = r\"D:\\test_bricare2line.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "column_2_expanded = df['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Column 3'].str.split(',', expand=True)\n",
    "\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "new_data = pd.concat([df.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"test2.csv\", index=False)\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial to get everything in order before the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TTB000026204697', '5100', 'Informasi Tagihan, Status Pembayaran, Sisa limit, Fee, Bunga, Late Charge Kartu Kredit', '2020-01-01 07:06:22.000']\n"
     ]
    }
   ],
   "source": [
    "# please see my codes below, I have a list of column names \"column_names\" I want the output is dataframe and after date they would be the other columns\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "def parse_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Strip newline characters and other surrounding whitespace\n",
    "            line = line.strip()\n",
    "            # Use regular expressions to find all components\n",
    "            # Find the first column (TTB followed by 12 digits)\n",
    "            first_col = re.search(r'TTB\\d{12}', line).group(0)\n",
    "            # Find the second column (4 digits)\n",
    "            second_col = re.search(r',(\\d{4}),', line).group(1)\n",
    "            # Find the fourth column (date and time)\n",
    "            fourth_col = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}', line).group(0)\n",
    "            # Extract everything between second and fourth columns for third column\n",
    "            start_index = line.index(second_col) + len(second_col) + 1\n",
    "            end_index = line.index(fourth_col)\n",
    "            third_col = line[start_index:end_index].strip(',')\n",
    "            # Append the parsed columns to the data list\n",
    "            data.append([first_col, second_col, third_col, fourth_col])\n",
    "    return data\n",
    "\n",
    "# Usage\n",
    "file_path = r\"D:\\oneline.txt\"\n",
    "parsed_data = parse_file(file_path)\n",
    "\n",
    "for line in parsed_data:\n",
    "    print(line)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "def parse_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Strip newline characters and other surrounding whitespace\n",
    "            line = line.strip()\n",
    "            # Use regular expressions to find all components\n",
    "            # Find the first column (TTB followed by 12 digits)\n",
    "            first_col = re.search(r'TTB\\d{12}', line).group(0)\n",
    "            # Find the second column (4 digits)\n",
    "            second_col = re.search(r',(\\d{4}),', line).group(1)\n",
    "            # Find the fourth column (date and time)\n",
    "            fourth_col = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}', line).group(0)\n",
    "            # Extract everything between second and fourth columns for third column\n",
    "            start_index = line.index(second_col) + len(second_col) + 1\n",
    "            end_index = line.index(fourth_col)\n",
    "            third_col = line[start_index:end_index].strip(',')\n",
    "            # Split the rest of the line after the date for remaining columns\n",
    "            remaining_columns = line[end_index + len(fourth_col):].split(',')\n",
    "            # Append the parsed columns to the data list\n",
    "            data.append([first_col, second_col, third_col, fourth_col] + remaining_columns)\n",
    "\n",
    "#     # Create DataFrame from data list\n",
    "#     df = pd.DataFrame(data, columns=column_names)\n",
    "#     return df\n",
    "\n",
    "# # Usage\n",
    "# file_path = \"D:\\\\oneline.txt\"\n",
    "# parsed_data_df = parse_file(file_path)\n",
    "# print(parsed_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>Column_10</th>\n",
       "      <th>Column_11</th>\n",
       "      <th>Column_12</th>\n",
       "      <th>Column_13</th>\n",
       "      <th>Column_14</th>\n",
       "      <th>Column_15</th>\n",
       "      <th>Column_16</th>\n",
       "      <th>Column_17</th>\n",
       "      <th>Column_18</th>\n",
       "      <th>Column_19</th>\n",
       "      <th>Column_20</th>\n",
       "      <th>Column_21</th>\n",
       "      <th>Column_22</th>\n",
       "      <th>Column_23</th>\n",
       "      <th>Column_24</th>\n",
       "      <th>Column_25</th>\n",
       "      <th>Column_26</th>\n",
       "      <th>Column_27</th>\n",
       "      <th>Column_28</th>\n",
       "      <th>Column_29</th>\n",
       "      <th>Column_30</th>\n",
       "      <th>Column_31</th>\n",
       "      <th>Column_32</th>\n",
       "      <th>Column_33</th>\n",
       "      <th>Column_34</th>\n",
       "      <th>Column_35</th>\n",
       "      <th>Column_36</th>\n",
       "      <th>Column_37</th>\n",
       "      <th>Column_38</th>\n",
       "      <th>Column_39</th>\n",
       "      <th>Column_40</th>\n",
       "      <th>Column_41</th>\n",
       "      <th>Column_42</th>\n",
       "      <th>Column_43</th>\n",
       "      <th>Column_44</th>\n",
       "      <th>Column_45</th>\n",
       "      <th>Column_46</th>\n",
       "      <th>Column_47</th>\n",
       "      <th>Column_48</th>\n",
       "      <th>Column_49</th>\n",
       "      <th>Column_50</th>\n",
       "      <th>Column_51</th>\n",
       "      <th>Column_52</th>\n",
       "      <th>Column_53</th>\n",
       "      <th>Column_54</th>\n",
       "      <th>Column_55</th>\n",
       "      <th>Column_56</th>\n",
       "      <th>Column_57</th>\n",
       "      <th>Column_58</th>\n",
       "      <th>Column_59</th>\n",
       "      <th>Column_60</th>\n",
       "      <th>Column_61</th>\n",
       "      <th>Column_62</th>\n",
       "      <th>Column_63</th>\n",
       "      <th>Column_64</th>\n",
       "      <th>Column_65</th>\n",
       "      <th>Column_66</th>\n",
       "      <th>Column_67</th>\n",
       "      <th>Column_68</th>\n",
       "      <th>Column_69</th>\n",
       "      <th>Column_70</th>\n",
       "      <th>Column_71</th>\n",
       "      <th>Column_72</th>\n",
       "      <th>Column_73</th>\n",
       "      <th>Column_74</th>\n",
       "      <th>Column_75</th>\n",
       "      <th>Column_76</th>\n",
       "      <th>Column_77</th>\n",
       "      <th>Column_78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833952</td>\n",
       "      <td>8433</td>\n",
       "      <td>Pembayaran Tagihan Gagal;Saldo Berkurang;Kartu...</td>\n",
       "      <td>2023-01-01 07:00:19</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>Zaka Putra</td>\n",
       "      <td>1,23457E+14</td>\n",
       "      <td>5350000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-03 14:49:51.000</td>\n",
       "      <td>2023-12-31 00:00:00.000</td>\n",
       "      <td>ATM BRI</td>\n",
       "      <td>Pembayaran</td>\n",
       "      <td>5221234567890120</td>\n",
       "      <td>LCC-ISSUER</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Adelia Awanda Dania</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>20</td>\n",
       "      <td>90148127</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Adelia Awanda Dania</td>\n",
       "      <td>Tabungan</td>\n",
       "      <td>bricare_admin</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-03 14:49:51.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Simpanan</td>\n",
       "      <td>Met</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-02 00:00:00.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>BRI</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>BRICare Administrator</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>Dewi Kartika Sari</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>Bank BRI</td>\n",
       "      <td>Insert Ticket Berhasil</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>428</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>00229 -- Kas Kanpus</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Gagal</td>\n",
       "      <td>KAS KANPUS</td>\n",
       "      <td>Kas Kanpus</td>\n",
       "      <td>4</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-03 00:00:00.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Notes</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Call</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column_1 Column_2  \\\n",
       "0  TTB000043833952     8433   \n",
       "\n",
       "                                            Column_3            Column_4  \\\n",
       "0  Pembayaran Tagihan Gagal;Saldo Berkurang;Kartu... 2023-01-01 07:00:19   \n",
       "\n",
       "  Column_5  Column_6    Column_7     Column_8    Column_9 Column_10  \\\n",
       "0    Phone  Complain  Zaka Putra  1,23457E+14  5350000.00    Closed   \n",
       "\n",
       "                 Column_11                Column_12 Column_13   Column_14  \\\n",
       "0  2023-01-03 14:49:51.000  2023-12-31 00:00:00.000   ATM BRI  Pembayaran   \n",
       "\n",
       "          Column_15   Column_16 Column_17 Column_18 Column_19  \\\n",
       "0  5221234567890120  LCC-ISSUER      NULL      NULL      NULL   \n",
       "\n",
       "             Column_20     Column_21 Column_22 Column_23 Column_24 Column_25  \\\n",
       "0  Adelia Awanda Dania  081234567890      NULL      NULL        20  90148127   \n",
       "\n",
       "     Column_26            Column_27 Column_28      Column_29 Column_30  \\\n",
       "0  LCC-CCTCALL  Adelia Awanda Dania  Tabungan  bricare_admin      NULL   \n",
       "\n",
       "                 Column_31 Column_32 Column_33 Column_34 Column_35 Column_36  \\\n",
       "0  2023-01-03 14:49:51.000      NULL  Simpanan       Met      NULL      NULL   \n",
       "\n",
       "                 Column_37 Column_38 Column_39 Column_40 Column_41 Column_42  \\\n",
       "0  2023-01-02 00:00:00.000      NULL      NULL      NULL       BRI      NULL   \n",
       "\n",
       "  Column_43 Column_44 Column_45 Column_46 Column_47              Column_48  \\\n",
       "0      NULL      NULL        No      NULL      NULL  BRICare Administrator   \n",
       "\n",
       "  Column_49 Column_50          Column_51 Column_52 Column_53 Column_54  \\\n",
       "0      NULL        No  Dewi Kartika Sari      NULL      NULL        No   \n",
       "\n",
       "  Column_55 Column_56               Column_57 Column_58 Column_59 Column_60  \\\n",
       "0      None  Bank BRI  Insert Ticket Berhasil      NULL      NULL       428   \n",
       "\n",
       "  Column_61 Column_62            Column_63 Column_64 Column_65   Column_66  \\\n",
       "0      NULL       Yes  00229 -- Kas Kanpus      NULL     Gagal  KAS KANPUS   \n",
       "\n",
       "    Column_67 Column_68 Column_69 Column_70                Column_71  \\\n",
       "0  Kas Kanpus         4      NULL      NULL  2023-01-03 00:00:00.000   \n",
       "\n",
       "  Column_72 Column_73 Column_74 Column_75 Column_76 Column_77 Column_78  \n",
       "0      NULL      NULL      NULL     Notes      NULL      Call         1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_file(file_path):\n",
    "    # Initialize a list to hold the parsed data\n",
    "    data = []\n",
    "    date_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}')\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(';')\n",
    "            # Find the index of the first date (fourth column)\n",
    "            date_index = next(i for i, part in enumerate(parts) if date_pattern.match(part))\n",
    "\n",
    "            # Extract columns\n",
    "            ticket_id = parts[0]  # First column\n",
    "            call_type_id = parts[1]  # Second column\n",
    "            description = ';'.join(parts[2:date_index])  # Third column, concatenating all parts up to the date\n",
    "            create_date = parts[date_index]  # Fourth column, the first date found\n",
    "\n",
    "            # Append the parsed columns and the rest of the data\n",
    "            data.append([ticket_id, call_type_id, description, create_date] + parts[date_index + 1:])\n",
    "\n",
    "    # Create DataFrame with generic column names\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [f\"Column_{i+1}\" for i in range(len(df.columns))]\n",
    "\n",
    "    # Convert 'Column_4' to datetime\n",
    "    df['Column_4'] = pd.to_datetime(df['Column_4'], errors='coerce', format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\dila_1line.txt\"\n",
    "df = parse_file(file_path)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRICARE Cleaner for 2023 excluding \"Details\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_5792\\3146355793.py:65: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(apply_mapping)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 78 Columns\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "def parse_file(file_path):\n",
    "    # Initialize a list to hold the parsed data\n",
    "    data = []\n",
    "    date_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}')\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(';')\n",
    "            # Find the index of the first date (fourth column in your description)\n",
    "            date_index = next(i for i, part in enumerate(parts) if date_pattern.match(part))\n",
    "\n",
    "            # Extract columns\n",
    "            ticket_id = parts[0] \n",
    "            call_type_id = parts[1]  \n",
    "            description = ';'.join(parts[2:date_index])  # Third column, concatenating all parts up to the date\n",
    "            create_date = parts[date_index]  # Fourth column, the first date found\n",
    "\n",
    "      \n",
    "            data.append([ticket_id, call_type_id, description, create_date] + parts[date_index + 1:])\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "\n",
    "    # Date\n",
    "    df['Create_Date'] = pd.to_datetime(df['Create_Date'], errors='coerce', format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare_case_januari2023_1masking.txt\"\n",
    "df = parse_file(file_path)\n",
    "\n",
    "# Picklist mapping\n",
    "mapping_sets = [\n",
    "    {'Yes': 'TRUE', 'No': 'FALSE'},\n",
    "    {'Simpanan': 'Savings', 'Pinjaman': 'Loans'}\n",
    "]\n",
    "mapping = {}\n",
    "for mapping_set in mapping_sets:\n",
    "    mapping.update(mapping_set)\n",
    "\n",
    "# Function to apply mapping\n",
    "def apply_mapping(value):\n",
    "    return mapping.get(value, value)\n",
    "\n",
    "df = df.applymap(apply_mapping)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Display\n",
    "# df=df.iloc[:1]\n",
    "# df.iloc[:1].to_csv(\"oneline.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRICARE Cleaner for 2023 with \"Details\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833835,8701,Blokir Kartu ATM karena k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000043833951,8202,Informasi Product Banking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Processed Data\n",
       "0  TTB000043833835,8701,Blokir Kartu ATM karena k...\n",
       "1     TTB000043833951,8202,Informasi Product Banking"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The file details_2line.txt has been uploaded and we have viewed the contents.\n",
    "# Now, we will process this file as per the user's request.\n",
    "# The requirement is to find lines starting with \"TTB\", and keep only the content up to the third comma.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from the text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\details_2line.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Filter lines that start with \"TTB\" and process them\n",
    "processed_lines = []\n",
    "for line in lines:\n",
    "    if line.startswith('TTB'):\n",
    "        # Split the line by comma and take up to the first three elements\n",
    "        parts = line.split(',')\n",
    "        if len(parts) >= 3:\n",
    "            # Reconstruct the line with only the first three parts\n",
    "            processed_line = ','.join(parts[:3])  # Join only the first three parts\n",
    "            processed_lines.append(processed_line.strip())  # Strip to remove any newline characters\n",
    "\n",
    "# Convert list to a DataFrame for easy handling\n",
    "df = pd.DataFrame({'Processed Data': processed_lines})\n",
    "\n",
    "# Saving the output to a new CSV file\n",
    "output_path = r\"C:\\Users\\maste\\Downloads\\details_2line\"+\"_output\"+\".txt\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Details Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permintaan pemblokiran ATM BRI.\\nAlasan pemblo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nDATA outlet BRILINK\\nKode Outlet BRILink\\t: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nif ch call back ,layanan IB ,  pergantian ka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  Permintaan pemblokiran ATM BRI.\\nAlasan pemblo...\n",
       "1  \\nDATA outlet BRILINK\\nKode Outlet BRILink\\t: ...\n",
       "2  \\nif ch call back ,layanan IB ,  pergantian ka..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_text_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Collect entries that start with \"TTB\"\n",
    "    entries = []\n",
    "    current_entry = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('TTB'):\n",
    "            if current_entry:  # if current_entry is not empty\n",
    "                entries.append('\\n'.join(current_entry))  # join all lines collected so far and add to entries\n",
    "                current_entry = []  # reset for the next entry\n",
    "            # Start collecting lines for the new entry, skip 'TTB' line and the first three comma-separated parts\n",
    "            continue\n",
    "        current_entry.append(line.strip())\n",
    "\n",
    "    # Add the last collected entry if any\n",
    "    if current_entry:\n",
    "        entries.append('\\n'.join(current_entry))\n",
    "\n",
    "    return entries\n",
    "\n",
    "# Path to your text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\details_3line.txt\"\n",
    "processed_data = process_text_data(file_path)\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "df_final = pd.DataFrame(processed_data, columns=['Content'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_final.to_csv('exp_1.csv', index_label='Index')\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Details Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>﻿TTB000043833835,8701,Blokir Kartu ATM karena ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000043833951</td>\n",
       "      <td>#BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTB000043833734</td>\n",
       "      <td>#CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTB000043833965</td>\n",
       "      <td>Nasabah gagal melakukan transaksi tarik tunai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTB000043833833</td>\n",
       "      <td>ch infokan melakukan registrasi brimo, namun m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket ID                                            Content\n",
       "0             None  ﻿TTB000043833835,8701,Blokir Kartu ATM karena ...\n",
       "1  TTB000043833951  #BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...\n",
       "2  TTB000043833734  #CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...\n",
       "3  TTB000043833965  Nasabah gagal melakukan transaksi tarik tunai ...\n",
       "4  TTB000043833833  ch infokan melakukan registrasi brimo, namun m..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_text_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Collect entries that start with \"TTB\"\n",
    "    entries = []\n",
    "    current_entry = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('TTB'):\n",
    "            if current_entry:  # if current_entry is not empty\n",
    "                entries.append('\\n'.join(current_entry))  # join all lines collected so far and add to entries\n",
    "                current_entry = []  # reset for the next entry\n",
    "            # Start collecting lines for the new entry, skip to part after the third comma\n",
    "            parts = line.split(',', 3)\n",
    "            if len(parts) > 3:\n",
    "                current_entry.append(parts[3].strip())  # Start the entry with text after the third comma\n",
    "            continue\n",
    "        current_entry.append(line.strip())\n",
    "\n",
    "    # Add the last collected entry if any\n",
    "    if current_entry:\n",
    "        entries.append('\\n'.join(current_entry))\n",
    "\n",
    "    return entries\n",
    "\n",
    "# Path to your text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\details_2line.txt\"\n",
    "processed_data = process_text_data(file_path)\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "df_final = pd.DataFrame(processed_data, columns=['Content'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df_final.to_csv('exp_3.csv', index_label='Index')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Details Column alongside with Tiket ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>﻿TTB000043833835,8701,Blokir Kartu ATM karena ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000043833951</td>\n",
       "      <td>#BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTB000043833734</td>\n",
       "      <td>#CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTB000043833965</td>\n",
       "      <td>Nasabah gagal melakukan transaksi tarik tunai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTB000043833833</td>\n",
       "      <td>ch infokan melakukan registrasi brimo, namun m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket ID                                            Content\n",
       "0             None  ﻿TTB000043833835,8701,Blokir Kartu ATM karena ...\n",
       "1  TTB000043833951  #BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...\n",
       "2  TTB000043833734  #CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...\n",
       "3  TTB000043833965  Nasabah gagal melakukan transaksi tarik tunai ...\n",
       "4  TTB000043833833  ch infokan melakukan registrasi brimo, namun m..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_text_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Collect entries that start with \"TTB\"\n",
    "    entries = []\n",
    "    current_entry = []\n",
    "    current_ticket_id = None  # Variable to store the current Ticket ID\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('TTB'):\n",
    "            if current_entry:  # If there's collected content, append it with the Ticket ID\n",
    "                entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "                current_entry = []\n",
    "            # Extract Ticket ID and the part after the third comma\n",
    "            parts = line.split(',', 3)\n",
    "            if len(parts) > 3:\n",
    "                current_ticket_id = parts[0]  # Store the Ticket ID\n",
    "                current_entry.append(parts[3].strip())  # Start collecting the entry content\n",
    "            continue\n",
    "        current_entry.append(line.strip())\n",
    "\n",
    "    # Add the last collected entry if any\n",
    "    if current_entry:\n",
    "        entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "\n",
    "    return entries\n",
    "\n",
    "# Path to your text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare_case_januari2023_2_details.txt\"\n",
    "processed_data = process_text_data(file_path)\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "df_final = pd.DataFrame(processed_data, columns=['Ticket ID', 'Content'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df_final.to_csv('exp_4.csv', index_label='Index')\n",
    "df_final.head(5)\n",
    "# df.to_csv('exp_4.csv', index_label='Index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833951</td>\n",
       "      <td>#BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000043833734</td>\n",
       "      <td>#CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTB000043833965</td>\n",
       "      <td>Nasabah gagal melakukan transaksi tarik tunai ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket ID                                            Content\n",
       "0  TTB000043833951  #BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...\n",
       "1  TTB000043833734  #CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...\n",
       "2  TTB000043833965  Nasabah gagal melakukan transaksi tarik tunai ..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_text_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    entries = []  # To store the entries along with their Ticket IDs\n",
    "    current_entry = []  # To accumulate the lines for the current entry\n",
    "    current_ticket_id = None  # To store the current Ticket ID\n",
    "    entry_started = False  # Flag to indicate whether an entry has started\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('TTB'):\n",
    "            if entry_started:\n",
    "                # When a new TTB line is found and an entry has already started, store the previous entry\n",
    "                entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "                current_entry = []  # Reset the current entry\n",
    "            # Extract Ticket ID and the part after the third comma\n",
    "            parts = line.split(',', 3)\n",
    "            if len(parts) > 3:\n",
    "                current_ticket_id = parts[0].strip()  # Extract and store the Ticket ID\n",
    "                current_entry.append(parts[3].strip())  # Start collecting the entry content from after the third comma\n",
    "                entry_started = True  # Set the flag as we have started processing an entry\n",
    "        elif entry_started:\n",
    "            # Only collect lines if we have started a valid entry\n",
    "            current_entry.append(line.strip())\n",
    "\n",
    "    # Add the last collected entry if any\n",
    "    if entry_started and current_ticket_id is not None:\n",
    "        entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "\n",
    "    return entries\n",
    "\n",
    "# Path to your text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare_case_januari2023_2_details.txt\"\n",
    "processed_data = process_text_data(file_path)\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "df_final = pd.DataFrame(processed_data, columns=['Ticket ID', 'Content'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df_final.to_csv('your_output_path.csv', index_label='Index')\n",
    "df_final.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "      <th>Column10</th>\n",
       "      <th>Column11</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>Column22</th>\n",
       "      <th>Column23</th>\n",
       "      <th>Column24</th>\n",
       "      <th>Column25</th>\n",
       "      <th>Column26</th>\n",
       "      <th>Column27</th>\n",
       "      <th>Column28</th>\n",
       "      <th>Column29</th>\n",
       "      <th>Column30</th>\n",
       "      <th>Column31</th>\n",
       "      <th>Column32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000026204763</td>\n",
       "      <td>8425</td>\n",
       "      <td>Pen-delete-an Status Registrasi Layanan yang A...</td>\n",
       "      <td>2020-01-01 07:19:37.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>021234567890123</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2020-01-01 07:19:43.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UKO</td>\n",
       "      <td>e-channel</td>\n",
       "      <td>5221841189816746</td>\n",
       "      <td>LCC-CRC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Really Artha Ully Manik</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>90136590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Really Artha Ully Manik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000026204728</td>\n",
       "      <td>8405</td>\n",
       "      <td>Kartu ATM BRI Tertelan di MESIN ATM</td>\n",
       "      <td>2020-01-01 07:19:30.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Information</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>021234567890123</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2020-01-01 07:17:02.000</td>\n",
       "      <td>2020-01-01 00:00:00.000</td>\n",
       "      <td>ATM BRI</td>\n",
       "      <td>Kartu tertelan</td>\n",
       "      <td>5221842126912762</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DELLA LARASSARI</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>90022934</td>\n",
       "      <td>Adhi Nitidharma</td>\n",
       "      <td>20</td>\n",
       "      <td>90135196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DELLA LARASSARI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTB000026204747</td>\n",
       "      <td>8202</td>\n",
       "      <td>Informasi Product Banking</td>\n",
       "      <td>2020-01-01 07:19:27.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Information</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>021234567890123</td>\n",
       "      <td>741700.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2020-05-20 08:50:01.000</td>\n",
       "      <td>2020-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5221842112540379</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>90140806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kartika Fitriani</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>90141079</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Kartika Fitriani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTB000026204712</td>\n",
       "      <td>3203</td>\n",
       "      <td>Permintaan Penutupan Kartu Kredit tanpa Anti A...</td>\n",
       "      <td>ada tagihan</td>\n",
       "      <td>2020-01-01 07:02:10.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2020-01-14 14:18:43.000</td>\n",
       "      <td>2020-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Penutupan Kartu</td>\n",
       "      <td>5475820180657500</td>\n",
       "      <td>KKD-CRI-DATAM</td>\n",
       "      <td>90023344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Endang Siti Fitrianti</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>90135181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Endang Siti Fitrianti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTB000026204659</td>\n",
       "      <td>8812</td>\n",
       "      <td>Nasabah BRI gagal tarik tunai &amp; terdebet di AT...</td>\n",
       "      <td>2020-01-01 07:00:34.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Information</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>021234567890123</td>\n",
       "      <td>1000000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2020-01-01 07:00:29.000</td>\n",
       "      <td>2020-01-01 00:00:00.000</td>\n",
       "      <td>ATM BRI</td>\n",
       "      <td>Tarik Tunai</td>\n",
       "      <td>6013011000558717</td>\n",
       "      <td>LCC-ON US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMELIA RAHMADANI</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>00000723</td>\n",
       "      <td>Ismail</td>\n",
       "      <td>10</td>\n",
       "      <td>60443</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>AMELIA RAHMADANI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375779</th>\n",
       "      <td>TTB000026713843</td>\n",
       "      <td>8411</td>\n",
       "      <td>Salah Transfer antar BRI</td>\n",
       "      <td>2020-01-31 17:28:34.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>MUTIAH</td>\n",
       "      <td>609401002283508</td>\n",
       "      <td>1950000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-03-01 18:01:47.000</td>\n",
       "      <td>2020-01-31 00:00:00.000</td>\n",
       "      <td>ATM BRI</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>5221842102972780</td>\n",
       "      <td>00206 -- Jkt KCK</td>\n",
       "      <td>90110471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Umar Fahruddin Pratama</td>\n",
       "      <td>082136107896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>90135689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Umar Fahruddin Pratama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375780</th>\n",
       "      <td>TTB000026714586</td>\n",
       "      <td>7700</td>\n",
       "      <td>Komplain Transaksi Kartu Kredit tidak di akui</td>\n",
       "      <td>2020-01-31 18:24:32.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>MULIYA HARDIYANTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-03-08 10:08:40.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sanggahan</td>\n",
       "      <td>5188289230916308</td>\n",
       "      <td>ADMIN QSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cintia Fadila</td>\n",
       "      <td>05264513380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>90123773</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Cintia Fadila</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375781</th>\n",
       "      <td>TTB000026716286</td>\n",
       "      <td>1000</td>\n",
       "      <td>CERIA - Status Pengajuan</td>\n",
       "      <td>Aplikasi</td>\n",
       "      <td>Cara &amp; Syarat</td>\n",
       "      <td>2020-01-31 20:35:27.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>dimas mahendra dharta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-03-13 10:20:57.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3510112110920002</td>\n",
       "      <td>DCE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afrizal Nur Triadi</td>\n",
       "      <td>0315961761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>90139561</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Afrizal Nur Triadi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375782</th>\n",
       "      <td>TTB000026713292</td>\n",
       "      <td>8411</td>\n",
       "      <td>Salah Transfer antar BRI</td>\n",
       "      <td>2020-01-31 16:56:02.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>S I M O N</td>\n",
       "      <td>064201002986507</td>\n",
       "      <td>9650000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2022-10-13 16:08:20.000</td>\n",
       "      <td>2020-01-31 00:00:00.000</td>\n",
       "      <td>ATM BRI</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>5326590001246103</td>\n",
       "      <td>00252 -- Jeneponto</td>\n",
       "      <td>90110471</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alfera Dyah Pangestu</td>\n",
       "      <td>081241313888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>90138706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alfera Dyah Pangestu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375783</th>\n",
       "      <td>TTB000026717333</td>\n",
       "      <td>8411</td>\n",
       "      <td>Salah Transfer antar BRI</td>\n",
       "      <td>2020-01-31 22:08:12.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>AGUS SUPRAPTO</td>\n",
       "      <td>601401026226534</td>\n",
       "      <td>2000000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2022-10-19 08:27:51.000</td>\n",
       "      <td>2020-01-31 00:00:00.000</td>\n",
       "      <td>ATM BRI</td>\n",
       "      <td>Transfer</td>\n",
       "      <td>6013010089430095</td>\n",
       "      <td>01271 -- KK KARANGREJO</td>\n",
       "      <td>90110471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MUHAMMAD ARHANDY KOES NANDA</td>\n",
       "      <td>081228501106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>60477</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>MUHAMMAD ARHANDY KOES NANDA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375784 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Column1 Column2  \\\n",
       "0       TTB000026204763    8425   \n",
       "1       TTB000026204728    8405   \n",
       "2       TTB000026204747    8202   \n",
       "3       TTB000026204712    3203   \n",
       "4       TTB000026204659    8812   \n",
       "...                 ...     ...   \n",
       "375779  TTB000026713843    8411   \n",
       "375780  TTB000026714586    7700   \n",
       "375781  TTB000026716286    1000   \n",
       "375782  TTB000026713292    8411   \n",
       "375783  TTB000026717333    8411   \n",
       "\n",
       "                                                  Column3  \\\n",
       "0       Pen-delete-an Status Registrasi Layanan yang A...   \n",
       "1                     Kartu ATM BRI Tertelan di MESIN ATM   \n",
       "2                               Informasi Product Banking   \n",
       "3       Permintaan Penutupan Kartu Kredit tanpa Anti A...   \n",
       "4       Nasabah BRI gagal tarik tunai & terdebet di AT...   \n",
       "...                                                   ...   \n",
       "375779                           Salah Transfer antar BRI   \n",
       "375780      Komplain Transaksi Kartu Kredit tidak di akui   \n",
       "375781                           CERIA - Status Pengajuan   \n",
       "375782                           Salah Transfer antar BRI   \n",
       "375783                           Salah Transfer antar BRI   \n",
       "\n",
       "                        Column4                  Column5  \\\n",
       "0       2020-01-01 07:19:37.000                    Phone   \n",
       "1       2020-01-01 07:19:30.000                    Phone   \n",
       "2       2020-01-01 07:19:27.000                    Phone   \n",
       "3                   ada tagihan  2020-01-01 07:02:10.000   \n",
       "4       2020-01-01 07:00:34.000                    Phone   \n",
       "...                         ...                      ...   \n",
       "375779  2020-01-31 17:28:34.000                    Phone   \n",
       "375780  2020-01-31 18:24:32.000                    Phone   \n",
       "375781                 Aplikasi            Cara & Syarat   \n",
       "375782  2020-01-31 16:56:02.000                    Phone   \n",
       "375783  2020-01-31 22:08:12.000                    Phone   \n",
       "\n",
       "                        Column6            Column7            Column8  \\\n",
       "0                   Maintenance  Arif Budi Saputra    021234567890123   \n",
       "1                   Information  Arif Budi Saputra    021234567890123   \n",
       "2                   Information  Arif Budi Saputra    021234567890123   \n",
       "3                         Phone        Maintenance  Arif Budi Saputra   \n",
       "4                   Information  Arif Budi Saputra    021234567890123   \n",
       "...                         ...                ...                ...   \n",
       "375779                 Complain             MUTIAH    609401002283508   \n",
       "375780                 Complain  MULIYA HARDIYANTO                NaN   \n",
       "375781  2020-01-31 20:35:27.000              Phone           Complain   \n",
       "375782                 Complain          S I M O N    064201002986507   \n",
       "375783                 Complain      AGUS SUPRAPTO    601401026226534   \n",
       "\n",
       "                      Column9 Column10                 Column11  \\\n",
       "0                        0.00   Closed  2020-01-01 07:19:43.000   \n",
       "1                        0.00   Closed  2020-01-01 07:17:02.000   \n",
       "2                   741700.00   Closed  2020-05-20 08:50:01.000   \n",
       "3                         NaN     0.00                   Closed   \n",
       "4                  1000000.00   Closed  2020-01-01 07:00:29.000   \n",
       "...                       ...      ...                      ...   \n",
       "375779             1950000.00   Closed  2023-03-01 18:01:47.000   \n",
       "375780                   0.00   Closed  2023-03-08 10:08:40.000   \n",
       "375781  dimas mahendra dharta      NaN                     0.00   \n",
       "375782             9650000.00   Closed  2022-10-13 16:08:20.000   \n",
       "375783             2000000.00   Closed  2022-10-19 08:27:51.000   \n",
       "\n",
       "                       Column12                 Column13        Column14  \\\n",
       "0                           NaN                      UKO       e-channel   \n",
       "1       2020-01-01 00:00:00.000                  ATM BRI  Kartu tertelan   \n",
       "2       2020-01-01 00:00:00.000                      NaN             NaN   \n",
       "3       2020-01-14 14:18:43.000  2020-01-01 00:00:00.000             NaN   \n",
       "4       2020-01-01 00:00:00.000                  ATM BRI     Tarik Tunai   \n",
       "...                         ...                      ...             ...   \n",
       "375779  2020-01-31 00:00:00.000                  ATM BRI        Transfer   \n",
       "375780                      NaN                      NaN       Sanggahan   \n",
       "375781                   Closed  2023-03-13 10:20:57.000             NaN   \n",
       "375782  2020-01-31 00:00:00.000                  ATM BRI        Transfer   \n",
       "375783  2020-01-31 00:00:00.000                  ATM BRI        Transfer   \n",
       "\n",
       "                Column15                Column16          Column17  Column18  \\\n",
       "0       5221841189816746                 LCC-CRC               NaN       NaN   \n",
       "1       5221842126912762             LCC-CCTCALL               NaN       NaN   \n",
       "2       5221842112540379             LCC-CCTCALL          90140806       NaN   \n",
       "3        Penutupan Kartu        5475820180657500     KKD-CRI-DATAM  90023344   \n",
       "4       6013011000558717               LCC-ON US               NaN       NaN   \n",
       "...                  ...                     ...               ...       ...   \n",
       "375779  5221842102972780        00206 -- Jkt KCK          90110471       NaN   \n",
       "375780  5188289230916308               ADMIN QSC               NaN       NaN   \n",
       "375781               NaN                     NaN  3510112110920002       DCE   \n",
       "375782  5326590001246103      00252 -- Jeneponto          90110471         0   \n",
       "375783  6013010089430095  01271 -- KK KARANGREJO          90110471       NaN   \n",
       "\n",
       "       Column19                     Column20               Column21  \\\n",
       "0           NaN      Really Artha Ully Manik           081234567890   \n",
       "1           NaN              DELLA LARASSARI           081234567890   \n",
       "2           NaN             Kartika Fitriani           081234567890   \n",
       "3           NaN                          NaN  Endang Siti Fitrianti   \n",
       "4           NaN             AMELIA RAHMADANI           081234567890   \n",
       "...         ...                          ...                    ...   \n",
       "375779      NaN       Umar Fahruddin Pratama           082136107896   \n",
       "375780      NaN                Cintia Fadila            05264513380   \n",
       "375781      NaN                          NaN                    NaN   \n",
       "375782      NaN         Alfera Dyah Pangestu           081241313888   \n",
       "375783      NaN  MUHAMMAD ARHANDY KOES NANDA           081228501106   \n",
       "\n",
       "                  Column22         Column23 Column24  Column25     Column26  \\\n",
       "0                      NaN              NaN       20  90136590          NaN   \n",
       "1                 90022934  Adhi Nitidharma       20  90135196          NaN   \n",
       "2                      NaN              NaN       20  90141079  LCC-CCTCALL   \n",
       "3             081234567890              NaN      NaN        15     90135181   \n",
       "4                 00000723           Ismail       10     60443  LCC-CCTCALL   \n",
       "...                    ...              ...      ...       ...          ...   \n",
       "375779                 NaN              NaN       20  90135689          NaN   \n",
       "375780                 NaN              NaN       67  90123773  LCC-CCTCALL   \n",
       "375781  Afrizal Nur Triadi       0315961761      NaN       NaN            2   \n",
       "375782                 NaN              NaN       20  90138706          NaN   \n",
       "375783                 NaN              NaN       20     60477  LCC-CCTCALL   \n",
       "\n",
       "                           Column27               Column28  \\\n",
       "0           Really Artha Ully Manik                    NaN   \n",
       "1                   DELLA LARASSARI                    NaN   \n",
       "2                  Kartika Fitriani                    NaN   \n",
       "3                               NaN  Endang Siti Fitrianti   \n",
       "4                  AMELIA RAHMADANI                    NaN   \n",
       "...                             ...                    ...   \n",
       "375779       Umar Fahruddin Pratama                    NaN   \n",
       "375780                Cintia Fadila                    NaN   \n",
       "375781                     90139561            LCC-CCTCALL   \n",
       "375782         Alfera Dyah Pangestu                    NaN   \n",
       "375783  MUHAMMAD ARHANDY KOES NANDA                    NaN   \n",
       "\n",
       "                  Column29 Column30 Column31 Column32  \n",
       "0                      NaN      NaN      NaN      NaN  \n",
       "1                      NaN      NaN      NaN      NaN  \n",
       "2                      NaN      NaN      NaN      NaN  \n",
       "3                      NaN      NaN      NaN      NaN  \n",
       "4                      NaN      NaN      NaN      NaN  \n",
       "...                    ...      ...      ...      ...  \n",
       "375779                 NaN      NaN      NaN      NaN  \n",
       "375780                 NaN      NaN      NaN      NaN  \n",
       "375781  Afrizal Nur Triadi      NaN      NaN      NaN  \n",
       "375782                 NaN      NaN      NaN      NaN  \n",
       "375783                 NaN      NaN      NaN      NaN  \n",
       "\n",
       "[375784 rows x 32 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "column_list = [\n",
    "    \"Ticket_ID\",  \n",
    "    \"Call_Type_ID\",  \n",
    "    \"Call_Type\", \n",
    "    \"Create_Date\",  \n",
    "    \"gateway\",  \n",
    "    \"Jenis_Laporan\",  \n",
    "    \"Nama_Nasabah\",  \n",
    "    \"No_Rekening\", \n",
    "    \"Nominal\",  \n",
    "    \"status\",  \n",
    "    \"TanggalClosed\", \n",
    "    \"tanggalTransaksi\",  \n",
    "    \"Chanel\",  \n",
    "    \"Fitur\",  \n",
    "    \"Nomor_Kartu\", \n",
    "    \"user_group\",  \n",
    "    \"assgined_to\",  \n",
    "    \"attachment_done\",  \n",
    "    \"email\",  \n",
    "    \"full_name\",  \n",
    "    \"no_telepon\",  \n",
    "    \"approver_login\",  \n",
    "    \"approver_name\",  \n",
    "    \"SLAResolution\",  \n",
    "    \"submitter_login_id\",  \n",
    "    \"submitter_user_group\", \n",
    "    \"user_login_name\"  \n",
    "]\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\BRICARE_25042024 masking.csv\"\n",
    "df=pd.read_csv(path, delimiter=';')\n",
    "# len(column_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zendesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Ticket channel</th>\n",
       "      <th>Assignee ID</th>\n",
       "      <th>Assignee name</th>\n",
       "      <th>Requester ID</th>\n",
       "      <th>Requester name</th>\n",
       "      <th>Ticket subject</th>\n",
       "      <th>Requester created - Timestamp</th>\n",
       "      <th>Ticket created - Timestamp</th>\n",
       "      <th>Ticket solved - Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3777302</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>19918762073497</td>\n",
       "      <td>Agent Socmed 5</td>\n",
       "      <td>32077763614745</td>\n",
       "      <td>E Sae</td>\n",
       "      <td>bikin brimo yg kblokir bsa gk y?</td>\n",
       "      <td>2024-05-06 00:02:21.000000</td>\n",
       "      <td>2024-05-06 00:02:21.000000</td>\n",
       "      <td>2024-05-06 00:05:22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3777303</td>\n",
       "      <td>Instagram Direct</td>\n",
       "      <td>405258199354</td>\n",
       "      <td>Contact BRI</td>\n",
       "      <td>32077722539801</td>\n",
       "      <td>Instagram Direct User 967125328443837</td>\n",
       "      <td>Conversation with Instagram Direct User 967125...</td>\n",
       "      <td>2024-05-06 00:02:28.000000</td>\n",
       "      <td>2024-05-06 00:02:29.000000</td>\n",
       "      <td>2024-05-06 06:19:32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3777304</td>\n",
       "      <td>Any channel</td>\n",
       "      <td>19918762073497</td>\n",
       "      <td>Agent Socmed 5</td>\n",
       "      <td>32077755960985</td>\n",
       "      <td>nurul_alamin</td>\n",
       "      <td>[IGDM] Kk cara ganti no HP di aplikas... - @nu...</td>\n",
       "      <td>2024-05-06 00:02:29.000000</td>\n",
       "      <td>2024-05-06 00:02:29.000000</td>\n",
       "      <td>2024-05-06 05:43:13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3777306</td>\n",
       "      <td>Twitter Direct Message</td>\n",
       "      <td>405258199354</td>\n",
       "      <td>Contact BRI</td>\n",
       "      <td>32077776751641</td>\n",
       "      <td>namaku</td>\n",
       "      <td>Conversation with namaku</td>\n",
       "      <td>2024-05-06 00:03:51.000000</td>\n",
       "      <td>2024-05-06 00:03:52.000000</td>\n",
       "      <td>2024-05-06 14:46:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3777309</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>19918762073497</td>\n",
       "      <td>Agent Socmed 5</td>\n",
       "      <td>32077861374233</td>\n",
       "      <td>Tok Bagus</td>\n",
       "      <td>Menurut gw mirip ni 2 orang🗿</td>\n",
       "      <td>2024-05-06 00:07:13.000000</td>\n",
       "      <td>2024-05-06 00:07:13.000000</td>\n",
       "      <td>2024-05-06 00:07:39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>3779914</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>405257335633</td>\n",
       "      <td>Agent Sosmed 3</td>\n",
       "      <td>32118165205913</td>\n",
       "      <td>Hana Dwi</td>\n",
       "      <td>Brimo error gimana ya? Ga bisa ke buka https:/...</td>\n",
       "      <td>2024-05-07 04:54:12.000000</td>\n",
       "      <td>2024-05-07 04:54:20.000000</td>\n",
       "      <td>2024-05-07 04:56:37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>3779935</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>405303061074</td>\n",
       "      <td>Agent Sosmed 2</td>\n",
       "      <td>32118841105689</td>\n",
       "      <td>Ahmad Yani</td>\n",
       "      <td>Klw bisa  saat mengambil atau memotong Uang di...</td>\n",
       "      <td>2024-05-07 05:41:57.000000</td>\n",
       "      <td>2024-05-07 05:41:57.000000</td>\n",
       "      <td>2024-05-07 05:51:30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>3779940</td>\n",
       "      <td>Any channel</td>\n",
       "      <td>405303061074</td>\n",
       "      <td>Agent Sosmed 2</td>\n",
       "      <td>32119016699161</td>\n",
       "      <td>muhammadakbardurimalang</td>\n",
       "      <td>[IGDM] Selamat pagi - @muhammadakbardurimal...</td>\n",
       "      <td>2024-05-07 05:50:27.000000</td>\n",
       "      <td>2024-05-07 05:50:27.000000</td>\n",
       "      <td>2024-05-07 05:53:39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>3779942</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>405257335633</td>\n",
       "      <td>Agent Sosmed 3</td>\n",
       "      <td>32119084456601</td>\n",
       "      <td>Kang Timbul🇮🇩🇵🇸</td>\n",
       "      <td>@promo_BRI Kalau uang hilang bagaimana?</td>\n",
       "      <td>2024-05-07 05:54:21.000000</td>\n",
       "      <td>2024-05-07 05:54:21.000000</td>\n",
       "      <td>2024-05-07 05:57:39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>3779948</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>405303061074</td>\n",
       "      <td>Agent Sosmed 2</td>\n",
       "      <td>32119097263385</td>\n",
       "      <td>ruby</td>\n",
       "      <td>Selamat pagi admin, saya mau bertanya.\\nSaya i...</td>\n",
       "      <td>2024-05-07 05:59:07.000000</td>\n",
       "      <td>2024-05-07 05:59:17.000000</td>\n",
       "      <td>2024-05-07 06:00:08.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1186 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ticket ID          Ticket channel     Assignee ID   Assignee name  \\\n",
       "0       3777302                Facebook  19918762073497  Agent Socmed 5   \n",
       "1       3777303        Instagram Direct    405258199354     Contact BRI   \n",
       "2       3777304             Any channel  19918762073497  Agent Socmed 5   \n",
       "3       3777306  Twitter Direct Message    405258199354     Contact BRI   \n",
       "4       3777309                Facebook  19918762073497  Agent Socmed 5   \n",
       "...         ...                     ...             ...             ...   \n",
       "1181    3779914                 Twitter    405257335633  Agent Sosmed 3   \n",
       "1182    3779935                Facebook    405303061074  Agent Sosmed 2   \n",
       "1183    3779940             Any channel    405303061074  Agent Sosmed 2   \n",
       "1184    3779942                 Twitter    405257335633  Agent Sosmed 3   \n",
       "1185    3779948                 Twitter    405303061074  Agent Sosmed 2   \n",
       "\n",
       "        Requester ID                         Requester name  \\\n",
       "0     32077763614745                                  E Sae   \n",
       "1     32077722539801  Instagram Direct User 967125328443837   \n",
       "2     32077755960985                           nurul_alamin   \n",
       "3     32077776751641                                 namaku   \n",
       "4     32077861374233                              Tok Bagus   \n",
       "...              ...                                    ...   \n",
       "1181  32118165205913                               Hana Dwi   \n",
       "1182  32118841105689                             Ahmad Yani   \n",
       "1183  32119016699161                muhammadakbardurimalang   \n",
       "1184  32119084456601                        Kang Timbul🇮🇩🇵🇸   \n",
       "1185  32119097263385                                   ruby   \n",
       "\n",
       "                                         Ticket subject  \\\n",
       "0                      bikin brimo yg kblokir bsa gk y?   \n",
       "1     Conversation with Instagram Direct User 967125...   \n",
       "2     [IGDM] Kk cara ganti no HP di aplikas... - @nu...   \n",
       "3                              Conversation with namaku   \n",
       "4                          Menurut gw mirip ni 2 orang🗿   \n",
       "...                                                 ...   \n",
       "1181  Brimo error gimana ya? Ga bisa ke buka https:/...   \n",
       "1182  Klw bisa  saat mengambil atau memotong Uang di...   \n",
       "1183     [IGDM] Selamat pagi - @muhammadakbardurimal...   \n",
       "1184            @promo_BRI Kalau uang hilang bagaimana?   \n",
       "1185  Selamat pagi admin, saya mau bertanya.\\nSaya i...   \n",
       "\n",
       "     Requester created - Timestamp  Ticket created - Timestamp  \\\n",
       "0       2024-05-06 00:02:21.000000  2024-05-06 00:02:21.000000   \n",
       "1       2024-05-06 00:02:28.000000  2024-05-06 00:02:29.000000   \n",
       "2       2024-05-06 00:02:29.000000  2024-05-06 00:02:29.000000   \n",
       "3       2024-05-06 00:03:51.000000  2024-05-06 00:03:52.000000   \n",
       "4       2024-05-06 00:07:13.000000  2024-05-06 00:07:13.000000   \n",
       "...                            ...                         ...   \n",
       "1181    2024-05-07 04:54:12.000000  2024-05-07 04:54:20.000000   \n",
       "1182    2024-05-07 05:41:57.000000  2024-05-07 05:41:57.000000   \n",
       "1183    2024-05-07 05:50:27.000000  2024-05-07 05:50:27.000000   \n",
       "1184    2024-05-07 05:54:21.000000  2024-05-07 05:54:21.000000   \n",
       "1185    2024-05-07 05:59:07.000000  2024-05-07 05:59:17.000000   \n",
       "\n",
       "       Ticket solved - Timestamp  \n",
       "0     2024-05-06 00:05:22.000000  \n",
       "1     2024-05-06 06:19:32.000000  \n",
       "2     2024-05-06 05:43:13.000000  \n",
       "3     2024-05-06 14:46:00.000000  \n",
       "4     2024-05-06 00:07:39.000000  \n",
       "...                          ...  \n",
       "1181  2024-05-07 04:56:37.000000  \n",
       "1182  2024-05-07 05:51:30.000000  \n",
       "1183  2024-05-07 05:53:39.000000  \n",
       "1184  2024-05-07 05:57:39.000000  \n",
       "1185  2024-05-07 06:00:08.000000  \n",
       "\n",
       "[1186 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl \n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# path=r\"C:\\Users\\maste\\Downloads\\Data Zendesk.csv\"\n",
    "path=r\"C:\\Users\\maste\\Downloads\\RPA_Report_1_05072024_0802.xlsx\"\n",
    "df=pd.read_excel(path)\n",
    "\n",
    "\n",
    "# Change the datetime format\n",
    "\n",
    "date_columns= ['Requester created - Timestamp','Ticket created - Timestamp','Ticket solved - Timestamp']\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "# Remove the Ticket Column\n",
    "df=df.drop('Tickets',axis=1)\n",
    "\n",
    "\n",
    "# Save the file\n",
    "# df.to_csv('Zendesk.csv')\n",
    "# df['Ticket channel'].unique()\n",
    "df\n",
    "# Instagram Direct take out\n",
    "# Any channel = Instagram\n",
    "\n",
    "# remove all rows with Instagram Direct value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

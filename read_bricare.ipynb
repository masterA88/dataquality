{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: list index out of range\n",
      "['\\ufeffTTB000043833962', '8701', 'Blokir Kartu ATM karena kartu hilang', '2023-01-01 07:08:31.000', 'Phone', 'Maintenance', 'WATI SUSILAWATI', '436101009806534', '0.00', 'Closed', '2023-01-01 07:08:50.000', '2023-01-01 00:00:00.000', 'N/A', 'Blokir Kartu', '6013013389522694', 'LCC-CCTCALL', 'NULL', 'NULL', 'NULL', 'Novita Ayu Lestari', '085845602167', 'NULL', 'NULL', '20', 'SMG61072', '00196 -- KANWIL Semarang', 'Novita Ayu Lestari', 'Nasabah mengajukan pemblokiran kartu ATM BRI']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# List to store extracted data\n",
    "extracted_data = []\n",
    "\n",
    "try:\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        # Create a reader object to parse the CSV\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for row in reader:\n",
    "            # Assuming the data is located in a specific column, e.g., the first column\n",
    "            if \"TTB000043833962\" in row[0]:\n",
    "                extracted_data.append(row)  # Append the entire row if the ID is found\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "# Print the extracted data\n",
    "for data in extracted_data:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket_ID: TTB000043833962\n",
      "Call_Type_ID: 8701\n",
      "Call_Type: Blokir Kartu ATM karena kartu hilang\n",
      "Create_Date: 2023-01-01 07:08:31.000\n",
      "Phone: Phone\n",
      "Maintenance: Maintenance\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# File path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Regular expression patterns for the data points you listed\n",
    "patterns = {\n",
    "    \"Ticket_ID\": re.compile(r\"TTB\\d+\"),\n",
    "    \"Call_Type_ID\": re.compile(r\"\\b\\d{4}\\b\"),\n",
    "    \"Call_Type\": re.compile(r\"Blokir Kartu ATM karena kartu hilang\"),\n",
    "    \"Create_Date\": re.compile(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\"),\n",
    "    \"gateway\": re.compile(r\"Phone\"),\n",
    "    \"Maintenance\": re.compile(r\"Maintenance\"),\n",
    "    # Add more patterns as necessary\n",
    "}\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {key: None for key in patterns}\n",
    "\n",
    "# Read the file and search for patterns\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        for key, pattern in patterns.items():\n",
    "            match = pattern.search(content)\n",
    "            if match:\n",
    "                results[key] = match.group()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to read or process the file: {str(e)}\")\n",
    "\n",
    "# Display the results\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\n",
    "        \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "        \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "        \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assgined_to\", \"attachment_done\", \n",
    "        \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "        \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \"Jenis_Produk\", \n",
    "        \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \n",
    "        \"TID\", \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \n",
    "        \"Bank_BRI\", \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \n",
    "        \"Hasil_Kunjungan\", \"Log_Name\", \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \n",
    "        \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \"Notify_By\", \"Organization\", \n",
    "        \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \"Settlement_ID\", \n",
    "        \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "        \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \n",
    "        \"Tgl_In_Progress\", \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \n",
    "        \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "    ]\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "col = [\n",
    "        \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "        \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "        \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assgined_to\", \"attachment_done\", \n",
    "        \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "        \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \"Jenis_Produk\", \n",
    "        \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \n",
    "        \"TID\", \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \n",
    "        \"Bank_BRI\", \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \n",
    "        \"Hasil_Kunjungan\", \"Log_Name\", \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \n",
    "        \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \"Notify_By\", \"Organization\", \n",
    "        \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \"Settlement_ID\", \n",
    "        \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "        \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \n",
    "        \"Tgl_In_Progress\", \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \n",
    "        \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "    ]\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "def process_csv_with_complex_column(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the entire file content into a single string to process it line by line\n",
    "        content = file.read()\n",
    "        \n",
    "        # Split the content into rows based on a pattern that indicates the end of a complex entry\n",
    "        rows = content.split('================')  # This splits each \"block\" that should end up in Column 28\n",
    "        data = []\n",
    "\n",
    "        for row in rows:\n",
    "            # Split each row by commas up to Column 27, handle Column 28 separately, then continue after Column 28\n",
    "            parts = row.split(',')\n",
    "            if len(parts) > 29:  # Ensuring there are enough parts to form all columns\n",
    "                # The first 27 columns + the entire block of text that goes into Column 28\n",
    "                first_part = parts[:27]\n",
    "                col28 = ','.join(parts[27:-51])  # Joining parts that form the complex Column 28 (adjust range as needed)\n",
    "                last_part = parts[-51:]  # Remaining columns after Column 28\n",
    "                \n",
    "                # Combine all parts into a single row, ensuring 79 columns total\n",
    "                full_row = first_part + [col28] + last_part\n",
    "                if len(full_row) == 79:\n",
    "                    data.append(full_row)\n",
    "\n",
    "    # Create a DataFrame from the processed data\n",
    "    return pd.DataFrame(data, columns=col)\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path_v2 = file_path\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_v4 = process_csv_with_complex_column(csv_file_path_v2)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_v4_sample = structured_df_v4.head(10) if not structured_df_v4.empty else \"No data processed correctly.\"\n",
    "df2=structured_df_v4_sample.transpose()\n",
    "pd.set_option('display.max_columns', None)\n",
    "df2.to_csv(\"data_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>Column 10</th>\n",
       "      <th>Column 11</th>\n",
       "      <th>Column 12</th>\n",
       "      <th>Column 13</th>\n",
       "      <th>Column 14</th>\n",
       "      <th>Column 15</th>\n",
       "      <th>Column 16</th>\n",
       "      <th>Column 17</th>\n",
       "      <th>Column 18</th>\n",
       "      <th>Column 19</th>\n",
       "      <th>Column 20</th>\n",
       "      <th>Column 21</th>\n",
       "      <th>Column 22</th>\n",
       "      <th>Column 23</th>\n",
       "      <th>Column 24</th>\n",
       "      <th>Column 25</th>\n",
       "      <th>Column 26</th>\n",
       "      <th>Column 27</th>\n",
       "      <th>Column 28</th>\n",
       "      <th>Column 29</th>\n",
       "      <th>Column 30</th>\n",
       "      <th>Column 31</th>\n",
       "      <th>Column 32</th>\n",
       "      <th>Column 33</th>\n",
       "      <th>Column 34</th>\n",
       "      <th>Column 35</th>\n",
       "      <th>Column 36</th>\n",
       "      <th>Column 37</th>\n",
       "      <th>Column 38</th>\n",
       "      <th>Column 39</th>\n",
       "      <th>Column 40</th>\n",
       "      <th>Column 41</th>\n",
       "      <th>Column 42</th>\n",
       "      <th>Column 43</th>\n",
       "      <th>Column 44</th>\n",
       "      <th>Column 45</th>\n",
       "      <th>Column 46</th>\n",
       "      <th>Column 47</th>\n",
       "      <th>Column 48</th>\n",
       "      <th>Column 49</th>\n",
       "      <th>Column 50</th>\n",
       "      <th>Column 51</th>\n",
       "      <th>Column 52</th>\n",
       "      <th>Column 53</th>\n",
       "      <th>Column 54</th>\n",
       "      <th>Column 55</th>\n",
       "      <th>Column 56</th>\n",
       "      <th>Column 57</th>\n",
       "      <th>Column 58</th>\n",
       "      <th>Column 59</th>\n",
       "      <th>Column 60</th>\n",
       "      <th>Column 61</th>\n",
       "      <th>Column 62</th>\n",
       "      <th>Column 63</th>\n",
       "      <th>Column 64</th>\n",
       "      <th>Column 65</th>\n",
       "      <th>Column 66</th>\n",
       "      <th>Column 67</th>\n",
       "      <th>Column 68</th>\n",
       "      <th>Column 69</th>\n",
       "      <th>Column 70</th>\n",
       "      <th>Column 71</th>\n",
       "      <th>Column 72</th>\n",
       "      <th>Column 73</th>\n",
       "      <th>Column 74</th>\n",
       "      <th>Column 75</th>\n",
       "      <th>Column 76</th>\n",
       "      <th>Column 77</th>\n",
       "      <th>Column 78</th>\n",
       "      <th>Column 79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>085845602167</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>Nasabah mengajukan pemblokiran kartu ATM BRI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Permintaan pemblokiran ATM BRI.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alasan pemblokiran : Hilang</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tanggal Hilang : 31.12.2022</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jam Hilang : 21.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lokasi Kejadian : bri cikunir</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tanggal Pemblokiran :  01/01/2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jam Pemblokiran :  07:06 wib</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>================</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Column 1 Column 2  \\\n",
       "0                    ﻿TTB000043833962     8701   \n",
       "1     Permintaan pemblokiran ATM BRI.            \n",
       "2         Alasan pemblokiran : Hilang            \n",
       "3         Tanggal Hilang : 31.12.2022            \n",
       "4                  Jam Hilang : 21.00            \n",
       "5       Lokasi Kejadian : bri cikunir            \n",
       "6  Tanggal Pemblokiran :  01/01/2023             \n",
       "7        Jam Pemblokiran :  07:06 wib            \n",
       "8                                                \n",
       "9                    ================            \n",
       "\n",
       "                               Column 3                 Column 4 Column 5  \\\n",
       "0  Blokir Kartu ATM karena kartu hilang  2023-01-01 07:08:31.000    Phone   \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "5                                                                           \n",
       "6                                                                           \n",
       "7                                                                           \n",
       "8                                                                           \n",
       "9                                                                           \n",
       "\n",
       "      Column 6         Column 7         Column 8 Column 9 Column 10  \\\n",
       "0  Maintenance  WATI SUSILAWATI  436101009806534     0.00    Closed   \n",
       "1                                                                     \n",
       "2                                                                     \n",
       "3                                                                     \n",
       "4                                                                     \n",
       "5                                                                     \n",
       "6                                                                     \n",
       "7                                                                     \n",
       "8                                                                     \n",
       "9                                                                     \n",
       "\n",
       "                 Column 11                Column 12 Column 13     Column 14  \\\n",
       "0  2023-01-01 07:08:50.000  2023-01-01 00:00:00.000       N/A  Blokir Kartu   \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "5                                                                             \n",
       "6                                                                             \n",
       "7                                                                             \n",
       "8                                                                             \n",
       "9                                                                             \n",
       "\n",
       "          Column 15    Column 16 Column 17 Column 18 Column 19  \\\n",
       "0  6013013389522694  LCC-CCTCALL      NULL      NULL      NULL   \n",
       "1                                                                \n",
       "2                                                                \n",
       "3                                                                \n",
       "4                                                                \n",
       "5                                                                \n",
       "6                                                                \n",
       "7                                                                \n",
       "8                                                                \n",
       "9                                                                \n",
       "\n",
       "            Column 20     Column 21 Column 22 Column 23 Column 24 Column 25  \\\n",
       "0  Novita Ayu Lestari  085845602167      NULL      NULL        20  SMG61072   \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "5                                                                             \n",
       "6                                                                             \n",
       "7                                                                             \n",
       "8                                                                             \n",
       "9                                                                             \n",
       "\n",
       "                  Column 26           Column 27  \\\n",
       "0  00196 -- KANWIL Semarang  Novita Ayu Lestari   \n",
       "1                                                 \n",
       "2                                                 \n",
       "3                                                 \n",
       "4                                                 \n",
       "5                                                 \n",
       "6                                                 \n",
       "7                                                 \n",
       "8                                                 \n",
       "9                                                 \n",
       "\n",
       "                                      Column 28 Column 29 Column 30 Column 31  \\\n",
       "0  Nasabah mengajukan pemblokiran kartu ATM BRI                                 \n",
       "1                                                                               \n",
       "2                                                                               \n",
       "3                                                                               \n",
       "4                                                                               \n",
       "5                                                                               \n",
       "6                                                                               \n",
       "7                                                                               \n",
       "8                                                                               \n",
       "9                                                                               \n",
       "\n",
       "  Column 32 Column 33 Column 34 Column 35 Column 36 Column 37 Column 38  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 39 Column 40 Column 41 Column 42 Column 43 Column 44 Column 45  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 46 Column 47 Column 48 Column 49 Column 50 Column 51 Column 52  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 53 Column 54 Column 55 Column 56 Column 57 Column 58 Column 59  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 60 Column 61 Column 62 Column 63 Column 64 Column 65 Column 66  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 67 Column 68 Column 69 Column 70 Column 71 Column 72 Column 73  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 74 Column 75 Column 76 Column 77 Column 78 Column 79  \n",
       "0                                                              \n",
       "1                                                              \n",
       "2                                                              \n",
       "3                                                              \n",
       "4                                                              \n",
       "5                                                              \n",
       "6                                                              \n",
       "7                                                              \n",
       "8                                                              \n",
       "9                                                              "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Initialize a list to store the processed rows\n",
    "        data = []\n",
    "        \n",
    "        # Read the file line by line\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # Extract the first 27 columns directly\n",
    "            if len(row) < 79:\n",
    "                # Append empty fields if row is not long enough (handling potential errors in CSV formatting)\n",
    "                row += [''] * (79 - len(row))\n",
    "            \n",
    "            # Columns 1-27 are directly taken from the row based on your mapping\n",
    "            first_part = row[:27]\n",
    "            \n",
    "            # Column 28: Aggregating complex block data into one column (Example aggregation logic needed)\n",
    "            complex_data = ' '.join(row[27:28])  # Assuming we collect multiple pieces into one column here\n",
    "            \n",
    "            # Remaining columns, from 29 to 79\n",
    "            last_part = row[28:]\n",
    "\n",
    "            # Combine the parts into a full row ensuring it matches the expected 79 columns format\n",
    "            full_row = first_part + [complex_data] + last_part[:51]  # Adjust the slicing based on actual content need\n",
    "            if len(full_row) == 79:\n",
    "                data.append(full_row)\n",
    "            else:\n",
    "                # Padding in case there are missing columns to ensure each row has exactly 79 columns\n",
    "                full_row += [''] * (79 - len(full_row))\n",
    "                data.append(full_row)\n",
    "\n",
    "    # Create a DataFrame from the processed data\n",
    "    return pd.DataFrame(data, columns=[f\"Column {i+1}\" for i in range(79)])\n",
    "\n",
    "# Path to the updated CSV file\n",
    "updated_csv_file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(updated_csv_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Display a sample of the structured data\n",
    "pd.set_option('display.max_columns', None)\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "# structured_df_final_sample['Column 1'] = structured_df_final_sample['Column 1'].apply(lambda x: x if x.startswith('TTB') and len(x) == 15 else None)\n",
    "# structured_df_final_sample['Column 1'] = structured_df_final_sample.dropna(subset=['Column 1'])\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st 27 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>Column 10</th>\n",
       "      <th>Column 11</th>\n",
       "      <th>Column 12</th>\n",
       "      <th>Column 13</th>\n",
       "      <th>Column 14</th>\n",
       "      <th>Column 15</th>\n",
       "      <th>Column 16</th>\n",
       "      <th>Column 17</th>\n",
       "      <th>Column 18</th>\n",
       "      <th>Column 19</th>\n",
       "      <th>Column 20</th>\n",
       "      <th>Column 21</th>\n",
       "      <th>Column 22</th>\n",
       "      <th>Column 23</th>\n",
       "      <th>Column 24</th>\n",
       "      <th>Column 25</th>\n",
       "      <th>Column 26</th>\n",
       "      <th>Column 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>8.584560e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column 1 Column 2                              Column 3  \\\n",
       "0  TTB000043833962     8701  Blokir Kartu ATM karena kartu hilang   \n",
       "\n",
       "                  Column 4 Column 5     Column 6         Column 7  \\\n",
       "0  2023-01-01 07:08:31.000    Phone  Maintenance  WATI SUSILAWATI   \n",
       "\n",
       "          Column 8  Column 9 Column 10                Column 11  \\\n",
       "0  436101009806534       0.0    Closed  2023-01-01 07:08:50.000   \n",
       "\n",
       "                 Column 12  Column 13     Column 14         Column 15  \\\n",
       "0  2023-01-01 00:00:00.000        NaN  Blokir Kartu  6013013389522694   \n",
       "\n",
       "     Column 16  Column 17  Column 18 Column 19           Column 20  \\\n",
       "0  LCC-CCTCALL        NaN        NaN       NaN  Novita Ayu Lestari   \n",
       "\n",
       "      Column 21 Column 22  Column 23 Column 24 Column 25  \\\n",
       "0  8.584560e+10       NaN        NaN        20  SMG61072   \n",
       "\n",
       "                  Column 26           Column 27  \n",
       "0  00196 -- KANWIL Semarang  Novita Ayu Lestari  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "column_headers = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "    \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "    \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assigned_to\", \"attachment_done\", \n",
    "    \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "    \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\"\n",
    "]\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    # Load the CSV file into a DataFrame, processing only the necessary columns (first 27 columns)\n",
    "    df = pd.read_csv(file_path, usecols=range(27), header=None)\n",
    "\n",
    "    df = df.iloc[:1]\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    df.columns = [f\"Column {i+1}\" for i in range(27)]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(file_path)\n",
    "\n",
    "# Set display options for better output visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket_ID</th>\n",
       "      <th>Call_Type_ID</th>\n",
       "      <th>Call_Type</th>\n",
       "      <th>Create_Date</th>\n",
       "      <th>gateway</th>\n",
       "      <th>Jenis_Laporan</th>\n",
       "      <th>Nama_Nasabah</th>\n",
       "      <th>No_Rekening</th>\n",
       "      <th>Nominal</th>\n",
       "      <th>status</th>\n",
       "      <th>TanggalClosed</th>\n",
       "      <th>tanggalTransaksi</th>\n",
       "      <th>Chanel</th>\n",
       "      <th>Fitur</th>\n",
       "      <th>Nomor_Kartu</th>\n",
       "      <th>user_group</th>\n",
       "      <th>assigned_to</th>\n",
       "      <th>attachment_done</th>\n",
       "      <th>email</th>\n",
       "      <th>full_name</th>\n",
       "      <th>no_telepon</th>\n",
       "      <th>approver_login</th>\n",
       "      <th>approver_name</th>\n",
       "      <th>SLAResolution</th>\n",
       "      <th>submitter_login_id</th>\n",
       "      <th>submitter_user_group</th>\n",
       "      <th>user_login_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>8.584560e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket_ID Call_Type_ID                             Call_Type  \\\n",
       "0  TTB000043833962         8701  Blokir Kartu ATM karena kartu hilang   \n",
       "\n",
       "               Create_Date gateway Jenis_Laporan     Nama_Nasabah  \\\n",
       "0  2023-01-01 07:08:31.000   Phone   Maintenance  WATI SUSILAWATI   \n",
       "\n",
       "       No_Rekening  Nominal  status            TanggalClosed  \\\n",
       "0  436101009806534      0.0  Closed  2023-01-01 07:08:50.000   \n",
       "\n",
       "          tanggalTransaksi  Chanel         Fitur       Nomor_Kartu  \\\n",
       "0  2023-01-01 00:00:00.000     NaN  Blokir Kartu  6013013389522694   \n",
       "\n",
       "    user_group  assigned_to  attachment_done email           full_name  \\\n",
       "0  LCC-CCTCALL          NaN              NaN   NaN  Novita Ayu Lestari   \n",
       "\n",
       "     no_telepon approver_login  approver_name SLAResolution  \\\n",
       "0  8.584560e+10            NaN            NaN            20   \n",
       "\n",
       "  submitter_login_id      submitter_user_group     user_login_name  \n",
       "0           SMG61072  00196 -- KANWIL Semarang  Novita Ayu Lestari  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Specified column headers\n",
    "column_headers = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "    \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "    \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assigned_to\", \"attachment_done\", \n",
    "    \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "    \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\"\n",
    "]\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    # Load the CSV file into a DataFrame, processing only the necessary columns (first 27 columns)\n",
    "    df = pd.read_csv(file_path, usecols=range(27), header=None)\n",
    "\n",
    "    df = df.iloc[:1]\n",
    "\n",
    "    # Rename columns using the specified column headers\n",
    "    df.columns = column_headers\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(file_path)\n",
    "\n",
    "# Set display options for better output visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Splitting the text into a more manageable format\n",
    "    # Assume we split at the first occurrence of '================'\n",
    "    parts = text.split('================', 1)\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    # Column 1 will have 'Aku', Column 2 will have the rest of the text after '================'\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [\"Aku\"],\n",
    "        \"Column 2\": [parts[1].strip()]  # Using strip to remove leading/trailing whitespace\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace 'path_to_your_file.txt' with the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Splitting the text to extract the third column value\n",
    "    # Assume 'Tabungan' or similar values are added after the final '================,' so we split there first\n",
    "    parts = text.split('================,')\n",
    "    third_column_value = parts[1].strip() if len(parts) > 1 else \"Missing Value\"\n",
    "    \n",
    "    # Now split the first part further to separate out the main content\n",
    "    main_content_parts = parts[0].split('================', 1)\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    # Column 1 will have 'Aku', Column 2 will have the content after the first '================',\n",
    "    # and Column 3 will have the value from the third column\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [\"Aku\"],\n",
    "        \"Column 2\": [main_content_parts[1].strip() if len(main_content_parts) > 1 else \"Missing Content\"],  # Handle missing content\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace 'path_to_your_file.txt' with the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# search the ================, and set the value to be the value for the next column\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## great for 3 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Find the beginning of the content after \"Aku,\" to set up for Column 2\n",
    "    first_column_value = \"Aku\"\n",
    "    second_column_start = main_content.find(\"Aku,\") + len(\"Aku,\")\n",
    "    second_column_value = main_content[second_column_start:].strip()  # Remove any leading/trailing whitespace\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\" \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "# df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "\n",
    "df.to_csv(\"new_.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 4 starting from Kode ..., Column 5= empty, Column 6 Tabungan1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text using '================' as a separator\n",
    "    parts = text.split('================')\n",
    "    \n",
    "    # Assume the first line contains the labels for the first three columns, which are static\n",
    "    header_labels = parts[0].strip().split('\\n')[0].split(',')\n",
    "    if len(header_labels) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"Header format is not as expected. Check the first line for correct labels.\"]})\n",
    "\n",
    "    # Extracting the main body for Column 4, which includes multiple '================' sections\n",
    "    column4_content = '================'.join(parts[1:-1]).strip()\n",
    "\n",
    "    # Extract the last part for Columns 5 and 6\n",
    "    footer_labels = parts[-1].split(',')\n",
    "    if len(footer_labels) < 2:\n",
    "        return pd.DataFrame({\"Error\": [\"Footer format is not as expected. Insufficient labels after the last '================'.\"]})\n",
    "\n",
    "    # Trim and prepare the labels for the last two columns\n",
    "    column5_label = footer_labels[0].strip()\n",
    "    column6_label = footer_labels[1].strip()\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [header_labels[0].strip()],\n",
    "        \"Column 2\": [header_labels[1].strip()],\n",
    "        \"Column 3\": [header_labels[2].strip()],\n",
    "        \"Column 4\": [column4_content],\n",
    "        \"Column 5\": [column5_label],\n",
    "        \"Column 6\": [column6_label]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new4_.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text using '================' as a separator to isolate the main content and footer\n",
    "    parts = text.split('================')\n",
    "    if len(parts) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"The text does not contain enough sections separated by '================'.\"]})\n",
    "\n",
    "    # Extracting the main body for Column 4, assumed to be between the first and second '================'\n",
    "    column4_content = '\\n================\\n'.join(parts[1:-1]).strip()\n",
    "\n",
    "    # Extract the footer content right after the last '================'\n",
    "    # Assuming the footer starts with Tabungan1, Tabungan2 right after the last '================'\n",
    "    # footer_content = parts[-1].split(',')\n",
    "    # if len(footer_content) < 2:\n",
    "    #     return pd.DataFrame({\"Error\": [\"Footer content is not formatted as expected. Ensure it follows the last '================'.\"]})\n",
    "\n",
    "    footer_content=text.split('================,', 1)\n",
    "    # The first header should contain main labels if structured as expected\n",
    "    header_labels = parts[0].strip().split('\\n')[0].split(',')\n",
    "    if len(header_labels) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"Header labels are missing or incomplete.\"]})\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [header_labels[0].strip()],\n",
    "        \"Column 2\": [header_labels[1].strip()],\n",
    "        \"Column 3\": [header_labels[2].strip()],\n",
    "        \"Column 4\": [column4_content],\n",
    "        \"Column 5\": [footer_content[0].strip()]\n",
    "        # \"Column 5\": [footer_content[0].strip()],\n",
    "        # \"Column 6\": [footer_content[1].strip()]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new5_.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Column0 Column1\n",
      "0    Tab1    Tab2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with one column\n",
    "df = pd.DataFrame({'Column1': ['Tab1, Tab2']})\n",
    "\n",
    "# Split the single value in the column by comma (assuming there's only one comma)\n",
    "split_values = df['Column1'].str.split(',', expand=True)\n",
    "\n",
    "# Rename columns (optional)\n",
    "split_values.columns = ['Column0', 'Column1']\n",
    "\n",
    "# Update the DataFrame\n",
    "df = split_values.copy()\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main</td>\n",
       "      <td>Nasabah mengajukan pemblokiran kartu ATM BRI\\n...</td>\n",
       "      <td>Tabungan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column 1                                           Column 2  Column 3\n",
       "0     Main  Nasabah mengajukan pemblokiran kartu ATM BRI\\n...  Tabungan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "# df.to_csv(\"new_.csv\")\n",
    "df.to_csv(\"newbig_.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# file_path=r\"D:\\dataquality\\new_.csv\"\n",
    "file_path=r\"D:\\dataquality\\newbig_.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "column_2_expanded = data['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = data['Column 3'].str.split(',', expand=True)\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Naming the new columns\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "# Inserting these new columns before the original 'Column 2' and 'Column 3'\n",
    "new_data = pd.concat([data.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"new_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRICARE cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column 1 Column_2_1                            Column_2_2  \\\n",
      "0  ﻿TTB000043833962       8701  Blokir Kartu ATM karena kartu hilang   \n",
      "\n",
      "                Column_2_3 Column_2_4   Column_2_5       Column_2_6  \\\n",
      "0  2023-01-01 07:08:31.000      Phone  Maintenance  WATI SUSILAWATI   \n",
      "\n",
      "        Column_2_7 Column_2_8 Column_2_9  ... Column_3_42 Column_3_43  \\\n",
      "0  436101009806534       0.00     Closed  ...        NULL        NULL   \n",
      "\n",
      "  Column_3_44 Column_3_45 Column_3_46 Column_3_47 Column_3_48 Column_3_49  \\\n",
      "0        NULL        NULL        NULL        NULL       Notes        NULL   \n",
      "\n",
      "  Column_3_50      Column_3_51  \n",
      "0        Call  000000000000004  \n",
      "\n",
      "[1 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()\n",
    "\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "    second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "file_path = r\"D:\\test.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "column_2_expanded = df['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Column 3'].str.split(',', expand=True)\n",
    "\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "new_data = pd.concat([df.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"test.csv\")\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Ticket_ID Call_Type_ID                             Call_Type  \\\n",
      "0  ﻿TTB000043833962         8701  Blokir Kartu ATM karena kartu hilang   \n",
      "\n",
      "               Create_Date gateway Jenis_Laporan     Nama_Nasabah  \\\n",
      "0  2023-01-01 07:08:31.000   Phone   Maintenance  WATI SUSILAWATI   \n",
      "\n",
      "       No_Rekening Nominal  status  ... Tanggal_Settlement Tgl_Foward  \\\n",
      "0  436101009806534    0.00  Closed  ...               NULL       NULL   \n",
      "\n",
      "  Tgl_In_Progress Tgl_Returned Ticket_Referensi Tiket_Urgency Tipe_Remark  \\\n",
      "0            NULL         NULL             NULL          NULL       Notes   \n",
      "\n",
      "  UniqueID users     Usergroup_ID  \n",
      "0     NULL  Call  000000000000004  \n",
      "\n",
      "[1 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()\n",
    "\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "    second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "    # Create a DataFrame with initial rough columns\n",
    "    df = pd.DataFrame({\n",
    "        \"Initial_Column_1\": [first_column_value],\n",
    "        \"Initial_Column_2\": [second_column_value],\n",
    "        \"Initial_Column_3\": [third_column_value]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "file_path = r\"D:\\test.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "# Assuming 'Initial_Column_2' and 'Initial_Column_3' need to be expanded into multiple columns\n",
    "column_2_expanded = df['Initial_Column_2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Initial_Column_3'].str.split(',', expand=True)\n",
    "\n",
    "# List of all column names\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "# Concatenate expanded columns with the original DataFrame, dropping the initial columns used for expansion\n",
    "new_data = pd.concat([df.drop(['Initial_Column_2', 'Initial_Column_3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "# Ensure the total columns in DataFrame matches with the length of column_names\n",
    "new_data.columns = column_names[:new_data.shape[1]]\n",
    "\n",
    "new_data.to_csv(\"test.csv\")\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Line 1 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 2 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 3 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 4 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 5 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 6 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 7 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 8 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 9 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 10 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 11 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 12 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 13 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 14 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 15 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 16 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 17 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 18 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 19 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 20 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 21 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 22 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 23 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 24 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 25 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 26 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 27 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 28 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 29 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 30 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 31 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 32 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 33 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_df\n\u001b[0;32m     27\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest_bricare2line.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m---> 28\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataframe_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m column_2_expanded \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn 2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m column_3_expanded \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn 3\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mcreate_dataframe_from_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m formatted incorrectly and was skipped. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Concatenate all DataFrames into a single DataFrame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m combined_df\n",
      "File \u001b[1;32mc:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    dataframes = []  # List to hold all individual DataFrames\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line_number, line in enumerate(file, 1):  # Process each line individually\n",
    "            try:\n",
    "                main_content, third_column_value = line.split('================,', 1)\n",
    "                third_column_value = third_column_value.strip()\n",
    "\n",
    "                first_column_value = main_content.split(',', 1)[0].strip()\n",
    "                second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "                df = pd.DataFrame({\n",
    "                    \"Column 1\": [first_column_value],\n",
    "                    \"Column 2\": [second_column_value],\n",
    "                    \"Column 3\": [third_column_value]\n",
    "                })\n",
    "                dataframes.append(df)\n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: Line {line_number} formatted incorrectly and was skipped. Error: {str(e)}\")\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "file_path = r\"D:\\test_bricare2line.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "column_2_expanded = df['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Column 3'].str.split(',', expand=True)\n",
    "\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "new_data = pd.concat([df.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"test2.csv\", index=False)\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial to get everything in order before the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TTB000026204697', '5100', 'Informasi Tagihan, Status Pembayaran, Sisa limit, Fee, Bunga, Late Charge Kartu Kredit', '2020-01-01 07:06:22.000']\n"
     ]
    }
   ],
   "source": [
    "# please see my codes below, I have a list of column names \"column_names\" I want the output is dataframe and after date they would be the other columns\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "def parse_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Strip newline characters and other surrounding whitespace\n",
    "            line = line.strip()\n",
    "            # Use regular expressions to find all components\n",
    "            # Find the first column (TTB followed by 12 digits)\n",
    "            first_col = re.search(r'TTB\\d{12}', line).group(0)\n",
    "            # Find the second column (4 digits)\n",
    "            second_col = re.search(r',(\\d{4}),', line).group(1)\n",
    "            # Find the fourth column (date and time)\n",
    "            fourth_col = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}', line).group(0)\n",
    "            # Extract everything between second and fourth columns for third column\n",
    "            start_index = line.index(second_col) + len(second_col) + 1\n",
    "            end_index = line.index(fourth_col)\n",
    "            third_col = line[start_index:end_index].strip(',')\n",
    "            # Append the parsed columns to the data list\n",
    "            data.append([first_col, second_col, third_col, fourth_col])\n",
    "    return data\n",
    "\n",
    "# Usage\n",
    "file_path = r\"D:\\oneline.txt\"\n",
    "parsed_data = parse_file(file_path)\n",
    "\n",
    "for line in parsed_data:\n",
    "    print(line)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "def parse_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Strip newline characters and other surrounding whitespace\n",
    "            line = line.strip()\n",
    "            # Use regular expressions to find all components\n",
    "            # Find the first column (TTB followed by 12 digits)\n",
    "            first_col = re.search(r'TTB\\d{12}', line).group(0)\n",
    "            # Find the second column (4 digits)\n",
    "            second_col = re.search(r',(\\d{4}),', line).group(1)\n",
    "            # Find the fourth column (date and time)\n",
    "            fourth_col = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}', line).group(0)\n",
    "            # Extract everything between second and fourth columns for third column\n",
    "            start_index = line.index(second_col) + len(second_col) + 1\n",
    "            end_index = line.index(fourth_col)\n",
    "            third_col = line[start_index:end_index].strip(',')\n",
    "            # Split the rest of the line after the date for remaining columns\n",
    "            remaining_columns = line[end_index + len(fourth_col):].split(',')\n",
    "            # Append the parsed columns to the data list\n",
    "            data.append([first_col, second_col, third_col, fourth_col] + remaining_columns)\n",
    "\n",
    "#     # Create DataFrame from data list\n",
    "#     df = pd.DataFrame(data, columns=column_names)\n",
    "#     return df\n",
    "\n",
    "# # Usage\n",
    "# file_path = \"D:\\\\oneline.txt\"\n",
    "# parsed_data_df = parse_file(file_path)\n",
    "# print(parsed_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>Column_10</th>\n",
       "      <th>Column_11</th>\n",
       "      <th>Column_12</th>\n",
       "      <th>Column_13</th>\n",
       "      <th>Column_14</th>\n",
       "      <th>Column_15</th>\n",
       "      <th>Column_16</th>\n",
       "      <th>Column_17</th>\n",
       "      <th>Column_18</th>\n",
       "      <th>Column_19</th>\n",
       "      <th>Column_20</th>\n",
       "      <th>Column_21</th>\n",
       "      <th>Column_22</th>\n",
       "      <th>Column_23</th>\n",
       "      <th>Column_24</th>\n",
       "      <th>Column_25</th>\n",
       "      <th>Column_26</th>\n",
       "      <th>Column_27</th>\n",
       "      <th>Column_28</th>\n",
       "      <th>Column_29</th>\n",
       "      <th>Column_30</th>\n",
       "      <th>Column_31</th>\n",
       "      <th>Column_32</th>\n",
       "      <th>Column_33</th>\n",
       "      <th>Column_34</th>\n",
       "      <th>Column_35</th>\n",
       "      <th>Column_36</th>\n",
       "      <th>Column_37</th>\n",
       "      <th>Column_38</th>\n",
       "      <th>Column_39</th>\n",
       "      <th>Column_40</th>\n",
       "      <th>Column_41</th>\n",
       "      <th>Column_42</th>\n",
       "      <th>Column_43</th>\n",
       "      <th>Column_44</th>\n",
       "      <th>Column_45</th>\n",
       "      <th>Column_46</th>\n",
       "      <th>Column_47</th>\n",
       "      <th>Column_48</th>\n",
       "      <th>Column_49</th>\n",
       "      <th>Column_50</th>\n",
       "      <th>Column_51</th>\n",
       "      <th>Column_52</th>\n",
       "      <th>Column_53</th>\n",
       "      <th>Column_54</th>\n",
       "      <th>Column_55</th>\n",
       "      <th>Column_56</th>\n",
       "      <th>Column_57</th>\n",
       "      <th>Column_58</th>\n",
       "      <th>Column_59</th>\n",
       "      <th>Column_60</th>\n",
       "      <th>Column_61</th>\n",
       "      <th>Column_62</th>\n",
       "      <th>Column_63</th>\n",
       "      <th>Column_64</th>\n",
       "      <th>Column_65</th>\n",
       "      <th>Column_66</th>\n",
       "      <th>Column_67</th>\n",
       "      <th>Column_68</th>\n",
       "      <th>Column_69</th>\n",
       "      <th>Column_70</th>\n",
       "      <th>Column_71</th>\n",
       "      <th>Column_72</th>\n",
       "      <th>Column_73</th>\n",
       "      <th>Column_74</th>\n",
       "      <th>Column_75</th>\n",
       "      <th>Column_76</th>\n",
       "      <th>Column_77</th>\n",
       "      <th>Column_78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833952</td>\n",
       "      <td>8433</td>\n",
       "      <td>Pembayaran Tagihan Gagal;Saldo Berkurang;Kartu...</td>\n",
       "      <td>2023-01-01 07:00:19</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>Zaka Putra</td>\n",
       "      <td>1,23457E+14</td>\n",
       "      <td>5350000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-03 14:49:51.000</td>\n",
       "      <td>2023-12-31 00:00:00.000</td>\n",
       "      <td>ATM BRI</td>\n",
       "      <td>Pembayaran</td>\n",
       "      <td>5221234567890120</td>\n",
       "      <td>LCC-ISSUER</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Adelia Awanda Dania</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>20</td>\n",
       "      <td>90148127</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Adelia Awanda Dania</td>\n",
       "      <td>Tabungan</td>\n",
       "      <td>bricare_admin</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-03 14:49:51.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Simpanan</td>\n",
       "      <td>Met</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-02 00:00:00.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>BRI</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>BRICare Administrator</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>Dewi Kartika Sari</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>Bank BRI</td>\n",
       "      <td>Insert Ticket Berhasil</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>428</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>00229 -- Kas Kanpus</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Gagal</td>\n",
       "      <td>KAS KANPUS</td>\n",
       "      <td>Kas Kanpus</td>\n",
       "      <td>4</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-03 00:00:00.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Notes</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Call</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column_1 Column_2  \\\n",
       "0  TTB000043833952     8433   \n",
       "\n",
       "                                            Column_3            Column_4  \\\n",
       "0  Pembayaran Tagihan Gagal;Saldo Berkurang;Kartu... 2023-01-01 07:00:19   \n",
       "\n",
       "  Column_5  Column_6    Column_7     Column_8    Column_9 Column_10  \\\n",
       "0    Phone  Complain  Zaka Putra  1,23457E+14  5350000.00    Closed   \n",
       "\n",
       "                 Column_11                Column_12 Column_13   Column_14  \\\n",
       "0  2023-01-03 14:49:51.000  2023-12-31 00:00:00.000   ATM BRI  Pembayaran   \n",
       "\n",
       "          Column_15   Column_16 Column_17 Column_18 Column_19  \\\n",
       "0  5221234567890120  LCC-ISSUER      NULL      NULL      NULL   \n",
       "\n",
       "             Column_20     Column_21 Column_22 Column_23 Column_24 Column_25  \\\n",
       "0  Adelia Awanda Dania  081234567890      NULL      NULL        20  90148127   \n",
       "\n",
       "     Column_26            Column_27 Column_28      Column_29 Column_30  \\\n",
       "0  LCC-CCTCALL  Adelia Awanda Dania  Tabungan  bricare_admin      NULL   \n",
       "\n",
       "                 Column_31 Column_32 Column_33 Column_34 Column_35 Column_36  \\\n",
       "0  2023-01-03 14:49:51.000      NULL  Simpanan       Met      NULL      NULL   \n",
       "\n",
       "                 Column_37 Column_38 Column_39 Column_40 Column_41 Column_42  \\\n",
       "0  2023-01-02 00:00:00.000      NULL      NULL      NULL       BRI      NULL   \n",
       "\n",
       "  Column_43 Column_44 Column_45 Column_46 Column_47              Column_48  \\\n",
       "0      NULL      NULL        No      NULL      NULL  BRICare Administrator   \n",
       "\n",
       "  Column_49 Column_50          Column_51 Column_52 Column_53 Column_54  \\\n",
       "0      NULL        No  Dewi Kartika Sari      NULL      NULL        No   \n",
       "\n",
       "  Column_55 Column_56               Column_57 Column_58 Column_59 Column_60  \\\n",
       "0      None  Bank BRI  Insert Ticket Berhasil      NULL      NULL       428   \n",
       "\n",
       "  Column_61 Column_62            Column_63 Column_64 Column_65   Column_66  \\\n",
       "0      NULL       Yes  00229 -- Kas Kanpus      NULL     Gagal  KAS KANPUS   \n",
       "\n",
       "    Column_67 Column_68 Column_69 Column_70                Column_71  \\\n",
       "0  Kas Kanpus         4      NULL      NULL  2023-01-03 00:00:00.000   \n",
       "\n",
       "  Column_72 Column_73 Column_74 Column_75 Column_76 Column_77 Column_78  \n",
       "0      NULL      NULL      NULL     Notes      NULL      Call         1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_file(file_path):\n",
    "    # Initialize a list to hold the parsed data\n",
    "    data = []\n",
    "    date_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}')\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(';')\n",
    "            # Find the index of the first date (fourth column)\n",
    "            date_index = next(i for i, part in enumerate(parts) if date_pattern.match(part))\n",
    "\n",
    "            # Extract columns\n",
    "            ticket_id = parts[0]  # First column\n",
    "            call_type_id = parts[1]  # Second column\n",
    "            description = ';'.join(parts[2:date_index])  # Third column, concatenating all parts up to the date\n",
    "            create_date = parts[date_index]  # Fourth column, the first date found\n",
    "\n",
    "            # Append the parsed columns and the rest of the data\n",
    "            data.append([ticket_id, call_type_id, description, create_date] + parts[date_index + 1:])\n",
    "\n",
    "    # Create DataFrame with generic column names\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [f\"Column_{i+1}\" for i in range(len(df.columns))]\n",
    "\n",
    "    # Convert 'Column_4' to datetime\n",
    "    df['Column_4'] = pd.to_datetime(df['Column_4'], errors='coerce', format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\dila_1line.txt\"\n",
    "df = parse_file(file_path)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRICARE Cleaner for 2023 excluding \"Details\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_5792\\3146355793.py:65: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(apply_mapping)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 78 Columns\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "def parse_file(file_path):\n",
    "    # Initialize a list to hold the parsed data\n",
    "    data = []\n",
    "    date_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}')\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(';')\n",
    "            # Find the index of the first date (fourth column in your description)\n",
    "            date_index = next(i for i, part in enumerate(parts) if date_pattern.match(part))\n",
    "\n",
    "            # Extract columns\n",
    "            ticket_id = parts[0] \n",
    "            call_type_id = parts[1]  \n",
    "            description = ';'.join(parts[2:date_index])  # Third column, concatenating all parts up to the date\n",
    "            create_date = parts[date_index]  # Fourth column, the first date found\n",
    "\n",
    "      \n",
    "            data.append([ticket_id, call_type_id, description, create_date] + parts[date_index + 1:])\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "\n",
    "    # Date\n",
    "    df['Create_Date'] = pd.to_datetime(df['Create_Date'], errors='coerce', format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare_case_januari2023_1masking.txt\"\n",
    "df = parse_file(file_path)\n",
    "\n",
    "# Picklist mapping\n",
    "mapping_sets = [\n",
    "    {'Yes': 'TRUE', 'No': 'FALSE'},\n",
    "    {'Simpanan': 'Savings', 'Pinjaman': 'Loans'}\n",
    "]\n",
    "mapping = {}\n",
    "for mapping_set in mapping_sets:\n",
    "    mapping.update(mapping_set)\n",
    "\n",
    "# Function to apply mapping\n",
    "def apply_mapping(value):\n",
    "    return mapping.get(value, value)\n",
    "\n",
    "df = df.applymap(apply_mapping)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Display\n",
    "# df=df.iloc[:1]\n",
    "# df.iloc[:1].to_csv(\"oneline.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRICARE Cleaner for 2023 with \"Details\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833835,8701,Blokir Kartu ATM karena k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000043833951,8202,Informasi Product Banking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Processed Data\n",
       "0  TTB000043833835,8701,Blokir Kartu ATM karena k...\n",
       "1     TTB000043833951,8202,Informasi Product Banking"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The file details_2line.txt has been uploaded and we have viewed the contents.\n",
    "# Now, we will process this file as per the user's request.\n",
    "# The requirement is to find lines starting with \"TTB\", and keep only the content up to the third comma.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from the text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\details_2line.txt\"\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Filter lines that start with \"TTB\" and process them\n",
    "processed_lines = []\n",
    "for line in lines:\n",
    "    if line.startswith('TTB'):\n",
    "        # Split the line by comma and take up to the first three elements\n",
    "        parts = line.split(',')\n",
    "        if len(parts) >= 3:\n",
    "            # Reconstruct the line with only the first three parts\n",
    "            processed_line = ','.join(parts[:3])  # Join only the first three parts\n",
    "            processed_lines.append(processed_line.strip())  # Strip to remove any newline characters\n",
    "\n",
    "# Convert list to a DataFrame for easy handling\n",
    "df = pd.DataFrame({'Processed Data': processed_lines})\n",
    "\n",
    "# Saving the output to a new CSV file\n",
    "output_path = r\"C:\\Users\\maste\\Downloads\\details_2line\"+\"_output\"+\".txt\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Details Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permintaan pemblokiran ATM BRI.\\nAlasan pemblo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nDATA outlet BRILINK\\nKode Outlet BRILink\\t: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nif ch call back ,layanan IB ,  pergantian ka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  Permintaan pemblokiran ATM BRI.\\nAlasan pemblo...\n",
       "1  \\nDATA outlet BRILINK\\nKode Outlet BRILink\\t: ...\n",
       "2  \\nif ch call back ,layanan IB ,  pergantian ka..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_text_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Collect entries that start with \"TTB\"\n",
    "    entries = []\n",
    "    current_entry = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('TTB'):\n",
    "            if current_entry:  # if current_entry is not empty\n",
    "                entries.append('\\n'.join(current_entry))  # join all lines collected so far and add to entries\n",
    "                current_entry = []  # reset for the next entry\n",
    "            # Start collecting lines for the new entry, skip 'TTB' line and the first three comma-separated parts\n",
    "            continue\n",
    "        current_entry.append(line.strip())\n",
    "\n",
    "    # Add the last collected entry if any\n",
    "    if current_entry:\n",
    "        entries.append('\\n'.join(current_entry))\n",
    "\n",
    "    return entries\n",
    "\n",
    "# Path to your text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\details_3line.txt\"\n",
    "processed_data = process_text_data(file_path)\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "df_final = pd.DataFrame(processed_data, columns=['Content'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_final.to_csv('exp_1.csv', index_label='Index')\n",
    "df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Details Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿TTB000043833835,8701,Blokir Kartu ATM karena ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nasabah gagal melakukan transaksi tarik tunai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ch infokan melakukan registrasi brimo, namun m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  ﻿TTB000043833835,8701,Blokir Kartu ATM karena ...\n",
       "1  #BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...\n",
       "2  #CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...\n",
       "3  Nasabah gagal melakukan transaksi tarik tunai ...\n",
       "4  ch infokan melakukan registrasi brimo, namun m..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_text_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Collect entries that start with \"TTB\"\n",
    "    entries = []\n",
    "    current_entry = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('TTB'):\n",
    "            if current_entry:  # if current_entry is not empty\n",
    "                entries.append('\\n'.join(current_entry))  # join all lines collected so far and add to entries\n",
    "                current_entry = []  # reset for the next entry\n",
    "            # Start collecting lines for the new entry, skip to part after the third comma\n",
    "            parts = line.split(',', 3)\n",
    "            if len(parts) > 3:\n",
    "                current_entry.append(parts[3].strip())  # Start the entry with text after the third comma\n",
    "            continue\n",
    "        current_entry.append(line.strip())\n",
    "\n",
    "    # Add the last collected entry if any\n",
    "    if current_entry:\n",
    "        entries.append('\\n'.join(current_entry))\n",
    "\n",
    "    return entries\n",
    "\n",
    "# Path to your text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare_case_januari2023_2_details.txt\"\n",
    "processed_data = process_text_data(file_path)\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "df_final = pd.DataFrame(processed_data, columns=['Content'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df_final.to_csv('exp_3.csv', index_label='Index')\n",
    "df_final.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Details Column alongside with Tiket ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_text_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Collect entries that start with \"TTB\"\n",
    "    entries = []\n",
    "    current_entry = []\n",
    "    current_ticket_id = None  # Variable to store the current Ticket ID\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('TTB'):\n",
    "            if current_entry:  # If there's collected content, append it with the Ticket ID\n",
    "                entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "                current_entry = []\n",
    "            # Extract Ticket ID and the part after the third comma\n",
    "            parts = line.split(',', 3)\n",
    "            if len(parts) > 3:\n",
    "                current_ticket_id = parts[0]  # Store the Ticket ID\n",
    "                current_entry.append(parts[3].strip())  # Start collecting the entry content\n",
    "            continue\n",
    "        current_entry.append(line.strip())\n",
    "\n",
    "    # Add the last collected entry if any\n",
    "    if current_entry:\n",
    "        entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "\n",
    "    return entries\n",
    "\n",
    "# Path to your text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare_case_januari2023_2_details.txt\"\n",
    "processed_data = process_text_data(file_path)\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "df_final = pd.DataFrame(processed_data, columns=['Ticket ID', 'Content'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df_final.to_csv('exp_4.csv', index_label='Index')\n",
    "# df=df_final.iloc[:5]\n",
    "# df\n",
    "# df.to_csv('exp_4.csv', index_label='Index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st USE THIS, Just extract Ticket ID and Details Columns but having a problem in the first line\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>﻿TTB000043833835,8701,Blokir Kartu ATM karena ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000043833951</td>\n",
       "      <td>#BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTB000043833734</td>\n",
       "      <td>#CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTB000043833965</td>\n",
       "      <td>Nasabah gagal melakukan transaksi tarik tunai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTB000043833833</td>\n",
       "      <td>ch infokan melakukan registrasi brimo, namun m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket ID                                            Content\n",
       "0             None  ﻿TTB000043833835,8701,Blokir Kartu ATM karena ...\n",
       "1  TTB000043833951  #BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...\n",
       "2  TTB000043833734  #CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...\n",
       "3  TTB000043833965  Nasabah gagal melakukan transaksi tarik tunai ...\n",
       "4  TTB000043833833  ch infokan melakukan registrasi brimo, namun m..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_text_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    entries = []\n",
    "    current_entry = []\n",
    "    current_ticket_id = None\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('TTB'):\n",
    "            if current_entry:  # If there's collected content, append it with the Ticket ID\n",
    "                entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "                current_entry = []\n",
    "            # Extract Ticket ID and the part after the third comma\n",
    "            parts = line.split(',', 3)\n",
    "            if len(parts) > 3:\n",
    "                current_ticket_id = parts[0]  # Store the Ticket ID\n",
    "                current_entry.append(parts[3].strip())  # Start collecting the entry content\n",
    "            continue\n",
    "        current_entry.append(line.strip())\n",
    "\n",
    "    # Add the last collected entry if any\n",
    "    if current_entry:\n",
    "        entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "\n",
    "    return entries\n",
    "\n",
    "# Path to your text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare_case_januari2023_2_details.txt\"\n",
    "processed_data = process_text_data(file_path)\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "df_final = pd.DataFrame(processed_data, columns=['Ticket ID', 'Content'])\n",
    "\n",
    "# Adjust the first entry in the Content column if necessary\n",
    "if df_final.iloc[0]['Ticket ID'] and df_final.iloc[0]['Content'].startswith(df_final.iloc[0]['Ticket ID']):\n",
    "    # Remove the Ticket ID and any two characters before it from the content\n",
    "    df_final.at[0, 'Content'] = df_final.iloc[0]['Content'][len(df_final.iloc[0]['Ticket ID'])+2:]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_final.to_csv('exp_5.csv', index_label='Index')\n",
    "\n",
    "df_final.head()  # Display the first few rows to check the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Modify the first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿TTB000043833835</td>\n",
       "      <td>Nasabah mengajukan pemblokiran kartu ATM BRI\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000043833951</td>\n",
       "      <td>#BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTB000043833734</td>\n",
       "      <td>, nomor tt\\n\\n\\n\\nNasabah mengajukan pemblok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTB000043833965</td>\n",
       "      <td>Nasabah gagal melakukan transaksi tarik tunai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTB000043833833</td>\n",
       "      <td>ch infokan melakukan registrasi brimo, namun m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364802</th>\n",
       "      <td>TTB000044335239</td>\n",
       "      <td>Saldo Berkurang,Nasabah gagal melakukan transa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364803</th>\n",
       "      <td>TTB000044335249</td>\n",
       "      <td>Nasabah gagal melakukan transaksi tarik tunai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364804</th>\n",
       "      <td>TTB000044335135</td>\n",
       "      <td>\\nADDR 2, ,JL RAYA MERDEKA NO 110        ,\\nAD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364805</th>\n",
       "      <td>TTB000044335255</td>\n",
       "      <td>Saldo Berkurang,Nasabah gagal melakukan transa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364806</th>\n",
       "      <td>TTB000044335181</td>\n",
       "      <td>Nasabah gagal melakukan transaksi transfer :\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364807 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Ticket ID                                            Content\n",
       "0       ﻿TTB000043833835  Nasabah mengajukan pemblokiran kartu ATM BRI\\n...\n",
       "1        TTB000043833951  #BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...\n",
       "2        TTB000043833734    , nomor tt\\n\\n\\n\\nNasabah mengajukan pemblok...\n",
       "3        TTB000043833965  Nasabah gagal melakukan transaksi tarik tunai ...\n",
       "4        TTB000043833833  ch infokan melakukan registrasi brimo, namun m...\n",
       "...                  ...                                                ...\n",
       "364802   TTB000044335239  Saldo Berkurang,Nasabah gagal melakukan transa...\n",
       "364803   TTB000044335249  Nasabah gagal melakukan transaksi tarik tunai ...\n",
       "364804   TTB000044335135  \\nADDR 2, ,JL RAYA MERDEKA NO 110        ,\\nAD...\n",
       "364805   TTB000044335255  Saldo Berkurang,Nasabah gagal melakukan transa...\n",
       "364806   TTB000044335181  Nasabah gagal melakukan transaksi transfer :\\n...\n",
       "\n",
       "[364807 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('D:\\dataquality\\exp_5.csv', encoding='utf-8-sig')  # Handles any encoding issues like BOM\n",
    "\n",
    "# Initialize a list to store processed data\n",
    "processed_data = []\n",
    "\n",
    "# Process the first line\n",
    "first_line = data.loc[0, 'Content']\n",
    "ticket_id_first_line = first_line.split(',')[0]\n",
    "content_after_third_comma_first_line = ','.join(first_line.split(',')[3:]) if len(first_line.split(',')) > 3 else None\n",
    "processed_data.append({'Ticket ID': ticket_id_first_line, 'Content': content_after_third_comma_first_line})\n",
    "\n",
    "# Process the rest of the lines normally\n",
    "for index, row in data.iterrows():\n",
    "    if index == 0:  # Skip the first line as it is already processed\n",
    "        continue\n",
    "    if pd.notna(row['Ticket ID']) and row['Ticket ID'].startswith('TTB'):\n",
    "        content_parts = row['Content'].split(',')\n",
    "        processed_content = ','.join(content_parts[3:]) if len(content_parts) > 3 else row['Content']\n",
    "    else:\n",
    "        processed_content = row['Content']  # Keep the original content if not starting with TTB\n",
    "    processed_data.append({'Ticket ID': row['Ticket ID'], 'Content': processed_content})\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "result_df = pd.DataFrame(processed_data)\n",
    "\n",
    "\n",
    "result_df.to_csv('exp_6.csv', index=False)\n",
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833951</td>\n",
       "      <td>#BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000043833734</td>\n",
       "      <td>#CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTB000043833965</td>\n",
       "      <td>Nasabah gagal melakukan transaksi tarik tunai ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket ID                                            Content\n",
       "0  TTB000043833951  #BRILINKMOB\\n\\nDATA outlet BRILINK\\nKode Outle...\n",
       "1  TTB000043833734  #CALL TERPUTUS\\n\\nif ch call back ,layanan IB ...\n",
       "2  TTB000043833965  Nasabah gagal melakukan transaksi tarik tunai ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_text_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    entries = []  # To store the entries along with their Ticket IDs\n",
    "    current_entry = []  # To accumulate the lines for the current entry\n",
    "    current_ticket_id = None  # To store the current Ticket ID\n",
    "    entry_started = False  # Flag to indicate whether an entry has started\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('TTB'):\n",
    "            if entry_started:\n",
    "                # When a new TTB line is found and an entry has already started, store the previous entry\n",
    "                entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "                current_entry = []  # Reset the current entry\n",
    "            # Extract Ticket ID and the part after the third comma\n",
    "            parts = line.split(',', 3)\n",
    "            if len(parts) > 3:\n",
    "                current_ticket_id = parts[0].strip()  # Extract and store the Ticket ID\n",
    "                current_entry.append(parts[3].strip())  # Start collecting the entry content from after the third comma\n",
    "                entry_started = True  # Set the flag as we have started processing an entry\n",
    "        elif entry_started:\n",
    "            # Only collect lines if we have started a valid entry\n",
    "            current_entry.append(line.strip())\n",
    "\n",
    "    # Add the last collected entry if any\n",
    "    if entry_started and current_ticket_id is not None:\n",
    "        entries.append((current_ticket_id, '\\n'.join(current_entry)))\n",
    "\n",
    "    return entries\n",
    "\n",
    "# Path to your text file\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare_case_januari2023_2_details.txt\"\n",
    "processed_data = process_text_data(file_path)\n",
    "\n",
    "# Create a DataFrame from the processed data\n",
    "df_final = pd.DataFrame(processed_data, columns=['Ticket ID', 'Content'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df_final.to_csv('your_output_path.csv', index_label='Index')\n",
    "df_final.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRICARE before 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\AppData\\Local\\Temp\\ipykernel_36032\\1184298110.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Column2'] = data_cleaned['Column2'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>Column22</th>\n",
       "      <th>Column23</th>\n",
       "      <th>Column24</th>\n",
       "      <th>Column25</th>\n",
       "      <th>Column26</th>\n",
       "      <th>Column27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000026204763</td>\n",
       "      <td>8425</td>\n",
       "      <td>Pen-delete-an Status Registrasi Layanan yang A...</td>\n",
       "      <td>2020-01-01 07:19:37</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>021234567890123</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Really Artha Ully Manik</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>90136590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Really Artha Ully Manik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTB000026204728</td>\n",
       "      <td>8405</td>\n",
       "      <td>Kartu ATM BRI Tertelan di MESIN ATM</td>\n",
       "      <td>2020-01-01 07:19:30</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Information</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>021234567890123</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DELLA LARASSARI</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>90022934</td>\n",
       "      <td>Adhi Nitidharma</td>\n",
       "      <td>20</td>\n",
       "      <td>90135196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DELLA LARASSARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTB000026204747</td>\n",
       "      <td>8202</td>\n",
       "      <td>Informasi Product Banking</td>\n",
       "      <td>2020-01-01 07:19:27</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Information</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>021234567890123</td>\n",
       "      <td>741700.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kartika Fitriani</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>90141079</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Kartika Fitriani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTB000026204659</td>\n",
       "      <td>8812</td>\n",
       "      <td>Nasabah BRI gagal tarik tunai &amp; terdebet di AT...</td>\n",
       "      <td>2020-01-01 07:00:34</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Information</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>021234567890123</td>\n",
       "      <td>1000000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMELIA RAHMADANI</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>00000723</td>\n",
       "      <td>Ismail</td>\n",
       "      <td>10</td>\n",
       "      <td>60443</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>AMELIA RAHMADANI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TTB000026204577</td>\n",
       "      <td>8202</td>\n",
       "      <td>Informasi Product Banking</td>\n",
       "      <td>2020-01-01 07:09:29</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Information</td>\n",
       "      <td>Arif Budi Saputra</td>\n",
       "      <td>021234567890123</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bacuelkueh@gmail.com</td>\n",
       "      <td>Amalia Fitriana</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>60422</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Amalia Fitriana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375778</th>\n",
       "      <td>TTB000026715685</td>\n",
       "      <td>8411</td>\n",
       "      <td>Salah Transfer antar BRI</td>\n",
       "      <td>2020-01-31 19:32:26</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>HERIWATI</td>\n",
       "      <td>546501003139532</td>\n",
       "      <td>100001.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADE SUTISNA</td>\n",
       "      <td>082387480456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>90135194</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>ADE SUTISNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375779</th>\n",
       "      <td>TTB000026713843</td>\n",
       "      <td>8411</td>\n",
       "      <td>Salah Transfer antar BRI</td>\n",
       "      <td>2020-01-31 17:28:34</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>MUTIAH</td>\n",
       "      <td>609401002283508</td>\n",
       "      <td>1950000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Umar Fahruddin Pratama</td>\n",
       "      <td>082136107896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>90135689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Umar Fahruddin Pratama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375780</th>\n",
       "      <td>TTB000026714586</td>\n",
       "      <td>7700</td>\n",
       "      <td>Komplain Transaksi Kartu Kredit tidak di akui</td>\n",
       "      <td>2020-01-31 18:24:32</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>MULIYA HARDIYANTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cintia Fadila</td>\n",
       "      <td>05264513380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>90123773</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Cintia Fadila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375782</th>\n",
       "      <td>TTB000026713292</td>\n",
       "      <td>8411</td>\n",
       "      <td>Salah Transfer antar BRI</td>\n",
       "      <td>2020-01-31 16:56:02</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>S I M O N</td>\n",
       "      <td>064201002986507</td>\n",
       "      <td>9650000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alfera Dyah Pangestu</td>\n",
       "      <td>081241313888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>90138706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alfera Dyah Pangestu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375783</th>\n",
       "      <td>TTB000026717333</td>\n",
       "      <td>8411</td>\n",
       "      <td>Salah Transfer antar BRI</td>\n",
       "      <td>2020-01-31 22:08:12</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>AGUS SUPRAPTO</td>\n",
       "      <td>601401026226534</td>\n",
       "      <td>2000000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MUHAMMAD ARHANDY KOES NANDA</td>\n",
       "      <td>081228501106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>60477</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>MUHAMMAD ARHANDY KOES NANDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277037 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Column1 Column2  \\\n",
       "0       TTB000026204763    8425   \n",
       "1       TTB000026204728    8405   \n",
       "2       TTB000026204747    8202   \n",
       "4       TTB000026204659    8812   \n",
       "5       TTB000026204577    8202   \n",
       "...                 ...     ...   \n",
       "375778  TTB000026715685    8411   \n",
       "375779  TTB000026713843    8411   \n",
       "375780  TTB000026714586    7700   \n",
       "375782  TTB000026713292    8411   \n",
       "375783  TTB000026717333    8411   \n",
       "\n",
       "                                                  Column3             Column4  \\\n",
       "0       Pen-delete-an Status Registrasi Layanan yang A... 2020-01-01 07:19:37   \n",
       "1                     Kartu ATM BRI Tertelan di MESIN ATM 2020-01-01 07:19:30   \n",
       "2                               Informasi Product Banking 2020-01-01 07:19:27   \n",
       "4       Nasabah BRI gagal tarik tunai & terdebet di AT... 2020-01-01 07:00:34   \n",
       "5                               Informasi Product Banking 2020-01-01 07:09:29   \n",
       "...                                                   ...                 ...   \n",
       "375778                           Salah Transfer antar BRI 2020-01-31 19:32:26   \n",
       "375779                           Salah Transfer antar BRI 2020-01-31 17:28:34   \n",
       "375780      Komplain Transaksi Kartu Kredit tidak di akui 2020-01-31 18:24:32   \n",
       "375782                           Salah Transfer antar BRI 2020-01-31 16:56:02   \n",
       "375783                           Salah Transfer antar BRI 2020-01-31 22:08:12   \n",
       "\n",
       "       Column5      Column6            Column7          Column8     Column9  \\\n",
       "0        Phone  Maintenance  Arif Budi Saputra  021234567890123        0.00   \n",
       "1        Phone  Information  Arif Budi Saputra  021234567890123        0.00   \n",
       "2        Phone  Information  Arif Budi Saputra  021234567890123   741700.00   \n",
       "4        Phone  Information  Arif Budi Saputra  021234567890123  1000000.00   \n",
       "5        Phone  Information  Arif Budi Saputra  021234567890123   500000.00   \n",
       "...        ...          ...                ...              ...         ...   \n",
       "375778   Phone     Complain           HERIWATI  546501003139532   100001.00   \n",
       "375779   Phone     Complain             MUTIAH  609401002283508  1950000.00   \n",
       "375780   Phone     Complain  MULIYA HARDIYANTO              NaN        0.00   \n",
       "375782   Phone     Complain          S I M O N  064201002986507  9650000.00   \n",
       "375783   Phone     Complain      AGUS SUPRAPTO  601401026226534  2000000.00   \n",
       "\n",
       "       Column10  ... Column18              Column19  \\\n",
       "0        Closed  ...      NaN                   NaN   \n",
       "1        Closed  ...      NaN                   NaN   \n",
       "2        Closed  ...      NaN                   NaN   \n",
       "4        Closed  ...      NaN                   NaN   \n",
       "5        Closed  ...      NaN  bacuelkueh@gmail.com   \n",
       "...         ...  ...      ...                   ...   \n",
       "375778   Closed  ...        0                   NaN   \n",
       "375779   Closed  ...      NaN                   NaN   \n",
       "375780   Closed  ...      NaN                   NaN   \n",
       "375782   Closed  ...        0                   NaN   \n",
       "375783   Closed  ...      NaN                   NaN   \n",
       "\n",
       "                           Column20      Column21  Column22         Column23  \\\n",
       "0           Really Artha Ully Manik  081234567890       NaN              NaN   \n",
       "1                   DELLA LARASSARI  081234567890  90022934  Adhi Nitidharma   \n",
       "2                  Kartika Fitriani  081234567890       NaN              NaN   \n",
       "4                  AMELIA RAHMADANI  081234567890  00000723           Ismail   \n",
       "5                   Amalia Fitriana  081234567890       NaN              NaN   \n",
       "...                             ...           ...       ...              ...   \n",
       "375778                  ADE SUTISNA  082387480456       NaN              NaN   \n",
       "375779       Umar Fahruddin Pratama  082136107896       NaN              NaN   \n",
       "375780                Cintia Fadila   05264513380       NaN              NaN   \n",
       "375782         Alfera Dyah Pangestu  081241313888       NaN              NaN   \n",
       "375783  MUHAMMAD ARHANDY KOES NANDA  081228501106       NaN              NaN   \n",
       "\n",
       "       Column24  Column25     Column26                     Column27  \n",
       "0            20  90136590          NaN      Really Artha Ully Manik  \n",
       "1            20  90135196          NaN              DELLA LARASSARI  \n",
       "2            20  90141079  LCC-CCTCALL             Kartika Fitriani  \n",
       "4            10     60443  LCC-CCTCALL             AMELIA RAHMADANI  \n",
       "5            20     60422  LCC-CCTCALL              Amalia Fitriana  \n",
       "...         ...       ...          ...                          ...  \n",
       "375778       20  90135194  LCC-CCTCALL                  ADE SUTISNA  \n",
       "375779       20  90135689          NaN       Umar Fahruddin Pratama  \n",
       "375780       67  90123773  LCC-CCTCALL                Cintia Fadila  \n",
       "375782       20  90138706          NaN         Alfera Dyah Pangestu  \n",
       "375783       20     60477  LCC-CCTCALL  MUHAMMAD ARHANDY KOES NANDA  \n",
       "\n",
       "[277037 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "column_list = [\n",
    "    \"Ticket_ID\",  \n",
    "    \"Call_Type_ID\",  \n",
    "    \"Call_Type\", \n",
    "    \"Create_Date\",  \n",
    "    \"gateway\",  \n",
    "    \"Jenis_Laporan\",  \n",
    "    \"Nama_Nasabah\",  \n",
    "    \"No_Rekening\", \n",
    "    \"Nominal\",  \n",
    "    \"status\",  \n",
    "    \"TanggalClosed\", \n",
    "    \"tanggalTransaksi\",  \n",
    "    \"Chanel\",  \n",
    "    \"Fitur\",  \n",
    "    \"Nomor_Kartu\", \n",
    "    \"user_group\",  \n",
    "    \"assgined_to\",  \n",
    "    \"attachment_done\",  \n",
    "    \"email\",  \n",
    "    \"full_name\",  \n",
    "    \"no_telepon\",  \n",
    "    \"approver_login\",  \n",
    "    \"approver_name\",  \n",
    "    \"SLAResolution\",  \n",
    "    \"submitter_login_id\",  \n",
    "    \"submitter_user_group\", \n",
    "    \"user_login_name\"  \n",
    "]\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\BRICARE_25042024 masking.csv\"\n",
    "data=pd.read_csv(path, delimiter=';')\n",
    "\n",
    "# Convert Column1 to string if not already, and apply the regex filter for \"TTB\" followed by numbers\n",
    "data['Column1'] = data['Column1'].astype(str)\n",
    "data_cleaned = data[data['Column1'].str.match(r'TTB\\d+')]\n",
    "\n",
    "# Ensure Column2 is an integer type and contains exactly four digits\n",
    "data_cleaned['Column2'] = data_cleaned['Column2'].astype(str)\n",
    "data_cleaned = data_cleaned[data_cleaned['Column2'].str.match(r'^\\d{4}$')]\n",
    "\n",
    "# Ensure all entries in Column4 can be converted to datetime and filter out those that can't\n",
    "data_cleaned['Column4'] = pd.to_datetime(data_cleaned['Column4'], errors='coerce')\n",
    "data_cleaned = data_cleaned.dropna(subset=['Column4'])\n",
    "\n",
    "# Drop Column 28-32\n",
    "data_to_drop=['Column28','Column29','Column30','Column31','Column32']\n",
    "data_cleaned=data_cleaned.drop(columns=data_to_drop)\n",
    "\n",
    "\n",
    "# Display the cleaned data again\n",
    "# data_to_show=['Column28','Column29','Column30','Column31','Column32']\n",
    "# data_cleaned=data_cleaned[data_to_show]\n",
    "\n",
    "# Check all column containing NaN\n",
    "# data_cleaned=data_cleaned.dropna()\n",
    "# data_cleaned\n",
    "\n",
    "# data_cleaned.columns = column_list[:len(data_cleaned.columns)]\n",
    "    \n",
    "\n",
    "data_cleaned\n",
    "\n",
    "\n",
    "\n",
    "# df=df.iloc[:6]\n",
    "# df.to_csv(\"not_cleanfordate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zendesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Ticket channel</th>\n",
       "      <th>Assignee ID</th>\n",
       "      <th>Assignee name</th>\n",
       "      <th>Requester ID</th>\n",
       "      <th>Requester name</th>\n",
       "      <th>Ticket subject</th>\n",
       "      <th>Requester created - Timestamp</th>\n",
       "      <th>Ticket created - Timestamp</th>\n",
       "      <th>Ticket solved - Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3777302</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>19918762073497</td>\n",
       "      <td>Agent Socmed 5</td>\n",
       "      <td>32077763614745</td>\n",
       "      <td>E Sae</td>\n",
       "      <td>bikin brimo yg kblokir bsa gk y?</td>\n",
       "      <td>2024-05-06 00:02:21.000000</td>\n",
       "      <td>2024-05-06 00:02:21.000000</td>\n",
       "      <td>2024-05-06 00:05:22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3777303</td>\n",
       "      <td>Instagram Direct</td>\n",
       "      <td>405258199354</td>\n",
       "      <td>Contact BRI</td>\n",
       "      <td>32077722539801</td>\n",
       "      <td>Instagram Direct User 967125328443837</td>\n",
       "      <td>Conversation with Instagram Direct User 967125...</td>\n",
       "      <td>2024-05-06 00:02:28.000000</td>\n",
       "      <td>2024-05-06 00:02:29.000000</td>\n",
       "      <td>2024-05-06 06:19:32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3777304</td>\n",
       "      <td>Any channel</td>\n",
       "      <td>19918762073497</td>\n",
       "      <td>Agent Socmed 5</td>\n",
       "      <td>32077755960985</td>\n",
       "      <td>nurul_alamin</td>\n",
       "      <td>[IGDM] Kk cara ganti no HP di aplikas... - @nu...</td>\n",
       "      <td>2024-05-06 00:02:29.000000</td>\n",
       "      <td>2024-05-06 00:02:29.000000</td>\n",
       "      <td>2024-05-06 05:43:13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3777306</td>\n",
       "      <td>Twitter Direct Message</td>\n",
       "      <td>405258199354</td>\n",
       "      <td>Contact BRI</td>\n",
       "      <td>32077776751641</td>\n",
       "      <td>namaku</td>\n",
       "      <td>Conversation with namaku</td>\n",
       "      <td>2024-05-06 00:03:51.000000</td>\n",
       "      <td>2024-05-06 00:03:52.000000</td>\n",
       "      <td>2024-05-06 14:46:00.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3777309</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>19918762073497</td>\n",
       "      <td>Agent Socmed 5</td>\n",
       "      <td>32077861374233</td>\n",
       "      <td>Tok Bagus</td>\n",
       "      <td>Menurut gw mirip ni 2 orang🗿</td>\n",
       "      <td>2024-05-06 00:07:13.000000</td>\n",
       "      <td>2024-05-06 00:07:13.000000</td>\n",
       "      <td>2024-05-06 00:07:39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>3779914</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>405257335633</td>\n",
       "      <td>Agent Sosmed 3</td>\n",
       "      <td>32118165205913</td>\n",
       "      <td>Hana Dwi</td>\n",
       "      <td>Brimo error gimana ya? Ga bisa ke buka https:/...</td>\n",
       "      <td>2024-05-07 04:54:12.000000</td>\n",
       "      <td>2024-05-07 04:54:20.000000</td>\n",
       "      <td>2024-05-07 04:56:37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>3779935</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>405303061074</td>\n",
       "      <td>Agent Sosmed 2</td>\n",
       "      <td>32118841105689</td>\n",
       "      <td>Ahmad Yani</td>\n",
       "      <td>Klw bisa  saat mengambil atau memotong Uang di...</td>\n",
       "      <td>2024-05-07 05:41:57.000000</td>\n",
       "      <td>2024-05-07 05:41:57.000000</td>\n",
       "      <td>2024-05-07 05:51:30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>3779940</td>\n",
       "      <td>Any channel</td>\n",
       "      <td>405303061074</td>\n",
       "      <td>Agent Sosmed 2</td>\n",
       "      <td>32119016699161</td>\n",
       "      <td>muhammadakbardurimalang</td>\n",
       "      <td>[IGDM] Selamat pagi - @muhammadakbardurimal...</td>\n",
       "      <td>2024-05-07 05:50:27.000000</td>\n",
       "      <td>2024-05-07 05:50:27.000000</td>\n",
       "      <td>2024-05-07 05:53:39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>3779942</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>405257335633</td>\n",
       "      <td>Agent Sosmed 3</td>\n",
       "      <td>32119084456601</td>\n",
       "      <td>Kang Timbul🇮🇩🇵🇸</td>\n",
       "      <td>@promo_BRI Kalau uang hilang bagaimana?</td>\n",
       "      <td>2024-05-07 05:54:21.000000</td>\n",
       "      <td>2024-05-07 05:54:21.000000</td>\n",
       "      <td>2024-05-07 05:57:39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>3779948</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>405303061074</td>\n",
       "      <td>Agent Sosmed 2</td>\n",
       "      <td>32119097263385</td>\n",
       "      <td>ruby</td>\n",
       "      <td>Selamat pagi admin, saya mau bertanya.\\nSaya i...</td>\n",
       "      <td>2024-05-07 05:59:07.000000</td>\n",
       "      <td>2024-05-07 05:59:17.000000</td>\n",
       "      <td>2024-05-07 06:00:08.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1186 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ticket ID          Ticket channel     Assignee ID   Assignee name  \\\n",
       "0       3777302                Facebook  19918762073497  Agent Socmed 5   \n",
       "1       3777303        Instagram Direct    405258199354     Contact BRI   \n",
       "2       3777304             Any channel  19918762073497  Agent Socmed 5   \n",
       "3       3777306  Twitter Direct Message    405258199354     Contact BRI   \n",
       "4       3777309                Facebook  19918762073497  Agent Socmed 5   \n",
       "...         ...                     ...             ...             ...   \n",
       "1181    3779914                 Twitter    405257335633  Agent Sosmed 3   \n",
       "1182    3779935                Facebook    405303061074  Agent Sosmed 2   \n",
       "1183    3779940             Any channel    405303061074  Agent Sosmed 2   \n",
       "1184    3779942                 Twitter    405257335633  Agent Sosmed 3   \n",
       "1185    3779948                 Twitter    405303061074  Agent Sosmed 2   \n",
       "\n",
       "        Requester ID                         Requester name  \\\n",
       "0     32077763614745                                  E Sae   \n",
       "1     32077722539801  Instagram Direct User 967125328443837   \n",
       "2     32077755960985                           nurul_alamin   \n",
       "3     32077776751641                                 namaku   \n",
       "4     32077861374233                              Tok Bagus   \n",
       "...              ...                                    ...   \n",
       "1181  32118165205913                               Hana Dwi   \n",
       "1182  32118841105689                             Ahmad Yani   \n",
       "1183  32119016699161                muhammadakbardurimalang   \n",
       "1184  32119084456601                        Kang Timbul🇮🇩🇵🇸   \n",
       "1185  32119097263385                                   ruby   \n",
       "\n",
       "                                         Ticket subject  \\\n",
       "0                      bikin brimo yg kblokir bsa gk y?   \n",
       "1     Conversation with Instagram Direct User 967125...   \n",
       "2     [IGDM] Kk cara ganti no HP di aplikas... - @nu...   \n",
       "3                              Conversation with namaku   \n",
       "4                          Menurut gw mirip ni 2 orang🗿   \n",
       "...                                                 ...   \n",
       "1181  Brimo error gimana ya? Ga bisa ke buka https:/...   \n",
       "1182  Klw bisa  saat mengambil atau memotong Uang di...   \n",
       "1183     [IGDM] Selamat pagi - @muhammadakbardurimal...   \n",
       "1184            @promo_BRI Kalau uang hilang bagaimana?   \n",
       "1185  Selamat pagi admin, saya mau bertanya.\\nSaya i...   \n",
       "\n",
       "     Requester created - Timestamp  Ticket created - Timestamp  \\\n",
       "0       2024-05-06 00:02:21.000000  2024-05-06 00:02:21.000000   \n",
       "1       2024-05-06 00:02:28.000000  2024-05-06 00:02:29.000000   \n",
       "2       2024-05-06 00:02:29.000000  2024-05-06 00:02:29.000000   \n",
       "3       2024-05-06 00:03:51.000000  2024-05-06 00:03:52.000000   \n",
       "4       2024-05-06 00:07:13.000000  2024-05-06 00:07:13.000000   \n",
       "...                            ...                         ...   \n",
       "1181    2024-05-07 04:54:12.000000  2024-05-07 04:54:20.000000   \n",
       "1182    2024-05-07 05:41:57.000000  2024-05-07 05:41:57.000000   \n",
       "1183    2024-05-07 05:50:27.000000  2024-05-07 05:50:27.000000   \n",
       "1184    2024-05-07 05:54:21.000000  2024-05-07 05:54:21.000000   \n",
       "1185    2024-05-07 05:59:07.000000  2024-05-07 05:59:17.000000   \n",
       "\n",
       "       Ticket solved - Timestamp  \n",
       "0     2024-05-06 00:05:22.000000  \n",
       "1     2024-05-06 06:19:32.000000  \n",
       "2     2024-05-06 05:43:13.000000  \n",
       "3     2024-05-06 14:46:00.000000  \n",
       "4     2024-05-06 00:07:39.000000  \n",
       "...                          ...  \n",
       "1181  2024-05-07 04:56:37.000000  \n",
       "1182  2024-05-07 05:51:30.000000  \n",
       "1183  2024-05-07 05:53:39.000000  \n",
       "1184  2024-05-07 05:57:39.000000  \n",
       "1185  2024-05-07 06:00:08.000000  \n",
       "\n",
       "[1186 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openpyxl \n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# path=r\"C:\\Users\\maste\\Downloads\\Data Zendesk.csv\"\n",
    "path=r\"C:\\Users\\maste\\Downloads\\RPA_Report_1_05072024_0802.xlsx\"\n",
    "df=pd.read_excel(path)\n",
    "\n",
    "\n",
    "# Change the datetime format\n",
    "\n",
    "date_columns= ['Requester created - Timestamp','Ticket created - Timestamp','Ticket solved - Timestamp']\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col]).dt.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "# Remove the Ticket Column\n",
    "df=df.drop('Tickets',axis=1)\n",
    "\n",
    "\n",
    "# Save the file\n",
    "# df.to_csv('Zendesk.csv')\n",
    "# df['Ticket channel'].unique()\n",
    "df\n",
    "# Instagram Direct take out\n",
    "# Any channel = Instagram\n",
    "\n",
    "# remove all rows with Instagram Direct value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Omni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>conv_id</th>\n",
       "      <th>from</th>\n",
       "      <th>from_name</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>action_type</th>\n",
       "      <th>message</th>\n",
       "      <th>message_type</th>\n",
       "      <th>media</th>\n",
       "      <th>date_create</th>\n",
       "      <th>read</th>\n",
       "      <th>send</th>\n",
       "      <th>response_time</th>\n",
       "      <th>upd</th>\n",
       "      <th>lup</th>\n",
       "      <th>stream_to_id</th>\n",
       "      <th>stream_id</th>\n",
       "      <th>inbox_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4988313</td>\n",
       "      <td>fm_66099558df0cc</td>\n",
       "      <td>3c522cf10fb598574b77b9a33abad272</td>\n",
       "      <td>ON4</td>\n",
       "      <td>Yusuf Rohhmadi</td>\n",
       "      <td>1101</td>\n",
       "      <td>OUT</td>\n",
       "      <td>Mohon maaf karena tidak ada respons dari Sobat...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:00:32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>2024-04-01 00:00:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4988314</td>\n",
       "      <td>fm_660994841446f</td>\n",
       "      <td>de7bd824b649f254baffe541bbdf4c3d</td>\n",
       "      <td>ON4</td>\n",
       "      <td>Yusuf Rohhmadi</td>\n",
       "      <td>1101</td>\n",
       "      <td>OUT</td>\n",
       "      <td>Saya masih menunggu respons dari Sobat. Ada ha...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:01:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>2024-04-01 00:01:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4988328</td>\n",
       "      <td>fm_660994841446f</td>\n",
       "      <td>de7bd824b649f254baffe541bbdf4c3d</td>\n",
       "      <td>ON4</td>\n",
       "      <td>Yusuf Rohhmadi</td>\n",
       "      <td>1101</td>\n",
       "      <td>OUT</td>\n",
       "      <td>Semoga laporan yang dibuat lancar dan segera t...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:04:26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>2024-04-01 00:04:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4988317</td>\n",
       "      <td>fm_660996eac3590</td>\n",
       "      <td>8052f480cfe2721756c4df9421e08aab</td>\n",
       "      <td>6421888784499367</td>\n",
       "      <td>Raffi Al Khuznan</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td># Request From Bot</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:01:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:01:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4988318</td>\n",
       "      <td>fm_660996eac3590</td>\n",
       "      <td>8052f480cfe2721756c4df9421e08aab</td>\n",
       "      <td>ON4</td>\n",
       "      <td>Yusuf Rohhmadi</td>\n",
       "      <td>1101</td>\n",
       "      <td>OUT</td>\n",
       "      <td>Hai Sobat BRI Ahmad, terima kasih telah menggu...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:01:41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>2024-04-01 00:01:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212435</th>\n",
       "      <td>5202221</td>\n",
       "      <td>fm_663123466f0d8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4670717739630957</td>\n",
       "      <td>Samidan Samidan</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>image</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-30 23:58:46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 23:59:16</td>\n",
       "      <td>4.323367e+14</td>\n",
       "      <td>m_6FaOmBXV1l4ZMiQ2B3TC7m8WwQolX5e9_EoMjfXh8Ckf...</td>\n",
       "      <td>m_6FaOmBXV1l4ZMiQ2B3TC7m8WwQolX5e9_EoMjfXh8Ckf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212436</th>\n",
       "      <td>5202225</td>\n",
       "      <td>fm_663123466f0d8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4670717739630957</td>\n",
       "      <td>Samidan Samidan</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>image</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-30 23:59:17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 23:59:47</td>\n",
       "      <td>4.323367e+14</td>\n",
       "      <td>m_SlC2lglqMT2o6J_I5VZV228WwQolX5e9_EoMjfXh8Cmg...</td>\n",
       "      <td>m_SlC2lglqMT2o6J_I5VZV228WwQolX5e9_EoMjfXh8Cmg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212437</th>\n",
       "      <td>5202223</td>\n",
       "      <td>fm_6631236551aac</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3513035298739563</td>\n",
       "      <td>Sholekan Renaltae</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>image</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-04-30 23:59:17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 23:59:47</td>\n",
       "      <td>4.323367e+14</td>\n",
       "      <td>m_pJX2ciFzXk4tFVOxC3orf5mCvZD2HgVCcYG2Qq7OWdtd...</td>\n",
       "      <td>m_pJX2ciFzXk4tFVOxC3orf5mCvZD2HgVCcYG2Qq7OWdtd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212438</th>\n",
       "      <td>5202153</td>\n",
       "      <td>fm_6631227062482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7329201513793842</td>\n",
       "      <td>Dheana Listarie</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>Selamat malam</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 23:55:12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 23:55:12</td>\n",
       "      <td>4.323367e+14</td>\n",
       "      <td>m_EkBmoioxC2hv9GJlEWMJfkxG_YJo0DTkHGG2XJ3D6W_i...</td>\n",
       "      <td>m_EkBmoioxC2hv9GJlEWMJfkxG_YJo0DTkHGG2XJ3D6W_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212439</th>\n",
       "      <td>5202171</td>\n",
       "      <td>fm_6631227062482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7329201513793842</td>\n",
       "      <td>Dheana Listarie</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>Mau nanya min</td>\n",
       "      <td>Inbox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 23:56:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-30 23:56:10</td>\n",
       "      <td>4.323367e+14</td>\n",
       "      <td>m_8HiV3rMxGAYZmcu75uY3Z0xG_YJo0DTkHGG2XJ3D6W8q...</td>\n",
       "      <td>m_8HiV3rMxGAYZmcu75uY3Z0xG_YJo0DTkHGG2XJ3D6W8q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212440 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        session_id                           conv_id  \\\n",
       "0       4988313  fm_66099558df0cc  3c522cf10fb598574b77b9a33abad272   \n",
       "1       4988314  fm_660994841446f  de7bd824b649f254baffe541bbdf4c3d   \n",
       "2       4988328  fm_660994841446f  de7bd824b649f254baffe541bbdf4c3d   \n",
       "3       4988317  fm_660996eac3590  8052f480cfe2721756c4df9421e08aab   \n",
       "4       4988318  fm_660996eac3590  8052f480cfe2721756c4df9421e08aab   \n",
       "...         ...               ...                               ...   \n",
       "212435  5202221  fm_663123466f0d8                               NaN   \n",
       "212436  5202225  fm_663123466f0d8                               NaN   \n",
       "212437  5202223  fm_6631236551aac                               NaN   \n",
       "212438  5202153  fm_6631227062482                               NaN   \n",
       "212439  5202171  fm_6631227062482                               NaN   \n",
       "\n",
       "                    from          from_name  agent_id action_type  \\\n",
       "0                    ON4     Yusuf Rohhmadi      1101         OUT   \n",
       "1                    ON4     Yusuf Rohhmadi      1101         OUT   \n",
       "2                    ON4     Yusuf Rohhmadi      1101         OUT   \n",
       "3       6421888784499367   Raffi Al Khuznan         0          IN   \n",
       "4                    ON4     Yusuf Rohhmadi      1101         OUT   \n",
       "...                  ...                ...       ...         ...   \n",
       "212435  4670717739630957    Samidan Samidan         0          IN   \n",
       "212436  4670717739630957    Samidan Samidan         0          IN   \n",
       "212437  3513035298739563  Sholekan Renaltae         0          IN   \n",
       "212438  7329201513793842    Dheana Listarie         0          IN   \n",
       "212439  7329201513793842    Dheana Listarie         0          IN   \n",
       "\n",
       "                                                  message message_type media  \\\n",
       "0       Mohon maaf karena tidak ada respons dari Sobat...         text   NaN   \n",
       "1       Saya masih menunggu respons dari Sobat. Ada ha...         text   NaN   \n",
       "2       Semoga laporan yang dibuat lancar dan segera t...         text   NaN   \n",
       "3                                      # Request From Bot         text   NaN   \n",
       "4       Hai Sobat BRI Ahmad, terima kasih telah menggu...         text   NaN   \n",
       "...                                                   ...          ...   ...   \n",
       "212435                                              image        Inbox     0   \n",
       "212436                                              image        Inbox     0   \n",
       "212437                                              image        Inbox     0   \n",
       "212438                                      Selamat malam        Inbox   NaN   \n",
       "212439                                      Mau nanya min        Inbox   NaN   \n",
       "\n",
       "               date_create  read  send  response_time     upd  \\\n",
       "0      2024-04-01 00:00:32     0     0            NaN  1101.0   \n",
       "1      2024-04-01 00:01:06     0     0            NaN  1101.0   \n",
       "2      2024-04-01 00:04:26     0     0            NaN  1101.0   \n",
       "3      2024-04-01 00:01:30     0     0            NaN     NaN   \n",
       "4      2024-04-01 00:01:41     0     0            NaN  1101.0   \n",
       "...                    ...   ...   ...            ...     ...   \n",
       "212435 2024-04-30 23:58:46     0     0            NaN     NaN   \n",
       "212436 2024-04-30 23:59:17     0     0            NaN     NaN   \n",
       "212437 2024-04-30 23:59:17     0     0            NaN     NaN   \n",
       "212438 2024-04-30 23:55:12     0     0            NaN     NaN   \n",
       "212439 2024-04-30 23:56:10     0     0            NaN     NaN   \n",
       "\n",
       "                       lup  stream_to_id  \\\n",
       "0      2024-04-01 00:00:33           NaN   \n",
       "1      2024-04-01 00:01:07           NaN   \n",
       "2      2024-04-01 00:04:27           NaN   \n",
       "3      2024-04-01 00:01:30           NaN   \n",
       "4      2024-04-01 00:01:41           NaN   \n",
       "...                    ...           ...   \n",
       "212435 2024-04-30 23:59:16  4.323367e+14   \n",
       "212436 2024-04-30 23:59:47  4.323367e+14   \n",
       "212437 2024-04-30 23:59:47  4.323367e+14   \n",
       "212438 2024-04-30 23:55:12  4.323367e+14   \n",
       "212439 2024-04-30 23:56:10  4.323367e+14   \n",
       "\n",
       "                                                stream_id  \\\n",
       "0                                                     NaN   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "212435  m_6FaOmBXV1l4ZMiQ2B3TC7m8WwQolX5e9_EoMjfXh8Ckf...   \n",
       "212436  m_SlC2lglqMT2o6J_I5VZV228WwQolX5e9_EoMjfXh8Cmg...   \n",
       "212437  m_pJX2ciFzXk4tFVOxC3orf5mCvZD2HgVCcYG2Qq7OWdtd...   \n",
       "212438  m_EkBmoioxC2hv9GJlEWMJfkxG_YJo0DTkHGG2XJ3D6W_i...   \n",
       "212439  m_8HiV3rMxGAYZmcu75uY3Z0xG_YJo0DTkHGG2XJ3D6W8q...   \n",
       "\n",
       "                                                 inbox_id  \n",
       "0                                                     NaN  \n",
       "1                                                     NaN  \n",
       "2                                                     NaN  \n",
       "3                                                     NaN  \n",
       "4                                                     NaN  \n",
       "...                                                   ...  \n",
       "212435  m_6FaOmBXV1l4ZMiQ2B3TC7m8WwQolX5e9_EoMjfXh8Ckf...  \n",
       "212436  m_SlC2lglqMT2o6J_I5VZV228WwQolX5e9_EoMjfXh8Cmg...  \n",
       "212437  m_pJX2ciFzXk4tFVOxC3orf5mCvZD2HgVCcYG2Qq7OWdtd...  \n",
       "212438  m_EkBmoioxC2hv9GJlEWMJfkxG_YJo0DTkHGG2XJ3D6W_i...  \n",
       "212439  m_8HiV3rMxGAYZmcu75uY3Z0xG_YJo0DTkHGG2XJ3D6W8q...  \n",
       "\n",
       "[212440 rows x 19 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\messenger history bri.xlsx\"\n",
    "\n",
    "df=pd.read_excel(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>message_id</th>\n",
       "      <th>msgId</th>\n",
       "      <th>in_reply_to</th>\n",
       "      <th>message_id_references</th>\n",
       "      <th>from_email</th>\n",
       "      <th>to_email</th>\n",
       "      <th>cc_email</th>\n",
       "      <th>bcc_email</th>\n",
       "      <th>...</th>\n",
       "      <th>type_email</th>\n",
       "      <th>status_email</th>\n",
       "      <th>reason</th>\n",
       "      <th>is_attach</th>\n",
       "      <th>priority</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>upd</th>\n",
       "      <th>lup</th>\n",
       "      <th>account_email</th>\n",
       "      <th>response_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7709212</td>\n",
       "      <td>em_660996b2f350a</td>\n",
       "      <td>CAENPuy1Uaeh-t9oOvEN2wAdcKcokW+maSwunOau12YL1V...</td>\n",
       "      <td>CAENPuy1Uaeht9oOvEN2wAdcKcokWmaSwunOau12YL1VjL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"address\":\"kimkasmo83@gmail.com\",\"name\":\"kim...</td>\n",
       "      <td>[{\"address\":\"callbri@bri.co.id\",\"name\":\"\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:00:35</td>\n",
       "      <td>callbri@bri.co.id</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7709211</td>\n",
       "      <td>em_66099384626ac</td>\n",
       "      <td>681479e271c7cb0ed1e6752af5706ba7infomediacoid</td>\n",
       "      <td>681479e271c7cb0ed1e6752af5706ba7infomediacoid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"address\":\"7583\",\"name\":\"\"}]</td>\n",
       "      <td>[{\"address\":\"ori.caglar@gmail.com\",\"name\":\"\"}]</td>\n",
       "      <td>[{\"address\":\"\",\"name\":\"\"}]</td>\n",
       "      <td>[{\"address\":\"\",\"name\":\"\"}]</td>\n",
       "      <td>...</td>\n",
       "      <td>OUT</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:00:21</td>\n",
       "      <td>callbri@bri.co.id</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7709214</td>\n",
       "      <td>em_66099721a21a9</td>\n",
       "      <td>CACpJ0J9-knXK7_BOreWQknbPyNJvMRdiS=EHC_FAs5_Fd...</td>\n",
       "      <td>CACpJ0J9knXK7BOreWQknbPyNJvMRdiSEHCFAs5Fd9XGuw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"address\":\"rzkynvianti111@gmail.com\",\"name\":...</td>\n",
       "      <td>[{\"address\":\"callbri@bri.co.id\",\"name\":\"\"}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>IN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:02:25</td>\n",
       "      <td>callbri@bri.co.id</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7709213</td>\n",
       "      <td>em_660993c138d34</td>\n",
       "      <td>7a15b71876b7b386b83145bdb2e31c7einfomediacoid</td>\n",
       "      <td>7a15b71876b7b386b83145bdb2e31c7einfomediacoid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"address\":\"568\",\"name\":\"\"}]</td>\n",
       "      <td>[{\"address\":\"satriomanjut@gmail.com\",\"name\":\"\"}]</td>\n",
       "      <td>[{\"address\":\"\",\"name\":\"\"}]</td>\n",
       "      <td>[{\"address\":\"\",\"name\":\"\"}]</td>\n",
       "      <td>...</td>\n",
       "      <td>OUT</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:02:02</td>\n",
       "      <td>callbri@bri.co.id</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7709215</td>\n",
       "      <td>em_660993d97204d</td>\n",
       "      <td>331c2c5525f2262e8406fd95af78fe90infomediacoid</td>\n",
       "      <td>331c2c5525f2262e8406fd95af78fe90infomediacoid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"address\":\"7583\",\"name\":\"\"}]</td>\n",
       "      <td>[{\"address\":\"mtrinandaputri@gmail.com\",\"name\":...</td>\n",
       "      <td>[{\"address\":\"\",\"name\":\"\"}]</td>\n",
       "      <td>[{\"address\":\"\",\"name\":\"\"}]</td>\n",
       "      <td>...</td>\n",
       "      <td>OUT</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-01 00:03:12</td>\n",
       "      <td>callbri@bri.co.id</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        session_id  \\\n",
       "0  7709212  em_660996b2f350a   \n",
       "1  7709211  em_66099384626ac   \n",
       "2  7709214  em_66099721a21a9   \n",
       "3  7709213  em_660993c138d34   \n",
       "4  7709215  em_660993d97204d   \n",
       "\n",
       "                                          message_id  \\\n",
       "0  CAENPuy1Uaeh-t9oOvEN2wAdcKcokW+maSwunOau12YL1V...   \n",
       "1      681479e271c7cb0ed1e6752af5706ba7infomediacoid   \n",
       "2  CACpJ0J9-knXK7_BOreWQknbPyNJvMRdiS=EHC_FAs5_Fd...   \n",
       "3      7a15b71876b7b386b83145bdb2e31c7einfomediacoid   \n",
       "4      331c2c5525f2262e8406fd95af78fe90infomediacoid   \n",
       "\n",
       "                                               msgId  in_reply_to  \\\n",
       "0  CAENPuy1Uaeht9oOvEN2wAdcKcokWmaSwunOau12YL1VjL...          NaN   \n",
       "1      681479e271c7cb0ed1e6752af5706ba7infomediacoid          NaN   \n",
       "2  CACpJ0J9knXK7BOreWQknbPyNJvMRdiSEHCFAs5Fd9XGuw...          NaN   \n",
       "3      7a15b71876b7b386b83145bdb2e31c7einfomediacoid          NaN   \n",
       "4      331c2c5525f2262e8406fd95af78fe90infomediacoid          NaN   \n",
       "\n",
       "   message_id_references                                         from_email  \\\n",
       "0                    NaN  [{\"address\":\"kimkasmo83@gmail.com\",\"name\":\"kim...   \n",
       "1                    NaN                     [{\"address\":\"7583\",\"name\":\"\"}]   \n",
       "2                    NaN  [{\"address\":\"rzkynvianti111@gmail.com\",\"name\":...   \n",
       "3                    NaN                      [{\"address\":\"568\",\"name\":\"\"}]   \n",
       "4                    NaN                     [{\"address\":\"7583\",\"name\":\"\"}]   \n",
       "\n",
       "                                            to_email  \\\n",
       "0        [{\"address\":\"callbri@bri.co.id\",\"name\":\"\"}]   \n",
       "1     [{\"address\":\"ori.caglar@gmail.com\",\"name\":\"\"}]   \n",
       "2        [{\"address\":\"callbri@bri.co.id\",\"name\":\"\"}]   \n",
       "3   [{\"address\":\"satriomanjut@gmail.com\",\"name\":\"\"}]   \n",
       "4  [{\"address\":\"mtrinandaputri@gmail.com\",\"name\":...   \n",
       "\n",
       "                     cc_email                   bcc_email  ... type_email  \\\n",
       "0                         NaN                         NaN  ...         IN   \n",
       "1  [{\"address\":\"\",\"name\":\"\"}]  [{\"address\":\"\",\"name\":\"\"}]  ...        OUT   \n",
       "2                         NaN                         NaN  ...         IN   \n",
       "3  [{\"address\":\"\",\"name\":\"\"}]  [{\"address\":\"\",\"name\":\"\"}]  ...        OUT   \n",
       "4  [{\"address\":\"\",\"name\":\"\"}]  [{\"address\":\"\",\"name\":\"\"}]  ...        OUT   \n",
       "\n",
       "  status_email reason is_attach priority agent_id upd                 lup  \\\n",
       "0            0    NaN         0      NaN      0.0 NaN 2024-04-01 00:00:35   \n",
       "1            1    NaN         0      NaN      NaN NaN 2024-04-01 00:00:21   \n",
       "2            0    NaN         0      NaN      0.0 NaN 2024-04-01 00:02:25   \n",
       "3            1    NaN         0      NaN      NaN NaN 2024-04-01 00:02:02   \n",
       "4            1    NaN         0      NaN      NaN NaN 2024-04-01 00:03:12   \n",
       "\n",
       "       account_email  response_time  \n",
       "0  callbri@bri.co.id            NaN  \n",
       "1  callbri@bri.co.id            NaN  \n",
       "2  callbri@bri.co.id            NaN  \n",
       "3  callbri@bri.co.id            NaN  \n",
       "4  callbri@bri.co.id            NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\email bri.xlsx\"\n",
    "df=pd.read_excel(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nomor</th>\n",
       "      <th>session_id</th>\n",
       "      <th>From Name</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>Agent Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>message</th>\n",
       "      <th>Date Create</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>wa_66390d1d68504</td>\n",
       "      <td>gempil</td>\n",
       "      <td>1101</td>\n",
       "      <td>-</td>\n",
       "      <td>IN</td>\n",
       "      <td># Request From Bot</td>\n",
       "      <td>2024-05-07 00:02:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wa_66390d1d68504</td>\n",
       "      <td>gempil</td>\n",
       "      <td>1101</td>\n",
       "      <td>-</td>\n",
       "      <td>IN</td>\n",
       "      <td># Close From Bot</td>\n",
       "      <td>2024-05-07 00:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>wa_66390d445c06e</td>\n",
       "      <td>P Info</td>\n",
       "      <td>7528</td>\n",
       "      <td>-</td>\n",
       "      <td>IN</td>\n",
       "      <td># Request From Bot</td>\n",
       "      <td>2024-05-07 00:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>wa_66390d445c06e</td>\n",
       "      <td>Christina</td>\n",
       "      <td>7528</td>\n",
       "      <td>-</td>\n",
       "      <td>IN</td>\n",
       "      <td># Close From Bot</td>\n",
       "      <td>2024-05-07 00:03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>wa_66390cbec99c1</td>\n",
       "      <td>Sugandy</td>\n",
       "      <td>5183</td>\n",
       "      <td>-</td>\n",
       "      <td>IN</td>\n",
       "      <td># Request From Bot</td>\n",
       "      <td>2024-05-07 00:00:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145201</th>\n",
       "      <td>145202</td>\n",
       "      <td>wa_663b269a9135e</td>\n",
       "      <td>-</td>\n",
       "      <td>7614</td>\n",
       "      <td>Maimunatul Khusna</td>\n",
       "      <td>OUT</td>\n",
       "      <td>Terima kasih atas kesediaan menunggu. Kami tur...</td>\n",
       "      <td>2024-05-08 14:28:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145202</th>\n",
       "      <td>145203</td>\n",
       "      <td>wa_663b269a9135e</td>\n",
       "      <td>Rahmat</td>\n",
       "      <td>7614</td>\n",
       "      <td>-</td>\n",
       "      <td>IN</td>\n",
       "      <td>terima kasih</td>\n",
       "      <td>2024-05-08 14:30:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145203</th>\n",
       "      <td>145204</td>\n",
       "      <td>wa_663b269a9135e</td>\n",
       "      <td>-</td>\n",
       "      <td>7614</td>\n",
       "      <td>Maimunatul Khusna</td>\n",
       "      <td>OUT</td>\n",
       "      <td>Dengan senang hati. Ada hal lain yang dapat ka...</td>\n",
       "      <td>2024-05-08 14:30:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145204</th>\n",
       "      <td>145205</td>\n",
       "      <td>wa_663b269a9135e</td>\n",
       "      <td>-</td>\n",
       "      <td>7614</td>\n",
       "      <td>Maimunatul Khusna</td>\n",
       "      <td>OUT</td>\n",
       "      <td>Kami masih menunggu respons dari Sobat BRI.</td>\n",
       "      <td>2024-05-08 14:33:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145205</th>\n",
       "      <td>145206</td>\n",
       "      <td>wa_663b269a9135e</td>\n",
       "      <td>-</td>\n",
       "      <td>7614</td>\n",
       "      <td>Maimunatul Khusna</td>\n",
       "      <td>OUT</td>\n",
       "      <td>Sobat BRI Rahmat, semoga kedepannya tidak terj...</td>\n",
       "      <td>2024-05-08 14:36:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145206 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Nomor        session_id  From Name  agent_id         Agent Name Type  \\\n",
       "0            1  wa_66390d1d68504     gempil      1101                  -   IN   \n",
       "1            2  wa_66390d1d68504     gempil      1101                  -   IN   \n",
       "2            3  wa_66390d445c06e     P Info      7528                  -   IN   \n",
       "3            4  wa_66390d445c06e  Christina      7528                  -   IN   \n",
       "4            5  wa_66390cbec99c1    Sugandy      5183                  -   IN   \n",
       "...        ...               ...        ...       ...                ...  ...   \n",
       "145201  145202  wa_663b269a9135e          -      7614  Maimunatul Khusna  OUT   \n",
       "145202  145203  wa_663b269a9135e     Rahmat      7614                  -   IN   \n",
       "145203  145204  wa_663b269a9135e          -      7614  Maimunatul Khusna  OUT   \n",
       "145204  145205  wa_663b269a9135e          -      7614  Maimunatul Khusna  OUT   \n",
       "145205  145206  wa_663b269a9135e          -      7614  Maimunatul Khusna  OUT   \n",
       "\n",
       "                                                  message         Date Create  \n",
       "0                                      # Request From Bot 2024-05-07 00:02:21  \n",
       "1                                        # Close From Bot 2024-05-07 00:02:27  \n",
       "2                                      # Request From Bot 2024-05-07 00:03:00  \n",
       "3                                        # Close From Bot 2024-05-07 00:03:09  \n",
       "4                                      # Request From Bot 2024-05-07 00:00:46  \n",
       "...                                                   ...                 ...  \n",
       "145201  Terima kasih atas kesediaan menunggu. Kami tur... 2024-05-08 14:28:28  \n",
       "145202                                       terima kasih 2024-05-08 14:30:37  \n",
       "145203  Dengan senang hati. Ada hal lain yang dapat ka... 2024-05-08 14:30:47  \n",
       "145204        Kami masih menunggu respons dari Sobat BRI. 2024-05-08 14:33:05  \n",
       "145205  Sobat BRI Rahmat, semoga kedepannya tidak terj... 2024-05-08 14:36:09  \n",
       "\n",
       "[145206 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "path=r\"C:\\Users\\maste\\Downloads\\interaction_whatsapp_history.xlsx\"\n",
    "\n",
    "df=pd.read_excel(path)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

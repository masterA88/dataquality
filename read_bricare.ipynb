{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: list index out of range\n",
      "['\\ufeffTTB000043833962', '8701', 'Blokir Kartu ATM karena kartu hilang', '2023-01-01 07:08:31.000', 'Phone', 'Maintenance', 'WATI SUSILAWATI', '436101009806534', '0.00', 'Closed', '2023-01-01 07:08:50.000', '2023-01-01 00:00:00.000', 'N/A', 'Blokir Kartu', '6013013389522694', 'LCC-CCTCALL', 'NULL', 'NULL', 'NULL', 'Novita Ayu Lestari', '085845602167', 'NULL', 'NULL', '20', 'SMG61072', '00196 -- KANWIL Semarang', 'Novita Ayu Lestari', 'Nasabah mengajukan pemblokiran kartu ATM BRI']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# List to store extracted data\n",
    "extracted_data = []\n",
    "\n",
    "try:\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        # Create a reader object to parse the CSV\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for row in reader:\n",
    "            # Assuming the data is located in a specific column, e.g., the first column\n",
    "            if \"TTB000043833962\" in row[0]:\n",
    "                extracted_data.append(row)  # Append the entire row if the ID is found\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "# Print the extracted data\n",
    "for data in extracted_data:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket_ID: TTB000043833962\n",
      "Call_Type_ID: 8701\n",
      "Call_Type: Blokir Kartu ATM karena kartu hilang\n",
      "Create_Date: 2023-01-01 07:08:31.000\n",
      "Phone: Phone\n",
      "Maintenance: Maintenance\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# File path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Regular expression patterns for the data points you listed\n",
    "patterns = {\n",
    "    \"Ticket_ID\": re.compile(r\"TTB\\d+\"),\n",
    "    \"Call_Type_ID\": re.compile(r\"\\b\\d{4}\\b\"),\n",
    "    \"Call_Type\": re.compile(r\"Blokir Kartu ATM karena kartu hilang\"),\n",
    "    \"Create_Date\": re.compile(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\"),\n",
    "    \"gateway\": re.compile(r\"Phone\"),\n",
    "    \"Maintenance\": re.compile(r\"Maintenance\"),\n",
    "    # Add more patterns as necessary\n",
    "}\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {key: None for key in patterns}\n",
    "\n",
    "# Read the file and search for patterns\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        for key, pattern in patterns.items():\n",
    "            match = pattern.search(content)\n",
    "            if match:\n",
    "                results[key] = match.group()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to read or process the file: {str(e)}\")\n",
    "\n",
    "# Display the results\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\n",
    "        \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "        \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "        \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assgined_to\", \"attachment_done\", \n",
    "        \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "        \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \"Jenis_Produk\", \n",
    "        \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \n",
    "        \"TID\", \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \n",
    "        \"Bank_BRI\", \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \n",
    "        \"Hasil_Kunjungan\", \"Log_Name\", \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \n",
    "        \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \"Notify_By\", \"Organization\", \n",
    "        \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \"Settlement_ID\", \n",
    "        \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "        \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \n",
    "        \"Tgl_In_Progress\", \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \n",
    "        \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "    ]\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "col = [\n",
    "        \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "        \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "        \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assgined_to\", \"attachment_done\", \n",
    "        \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "        \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \"Jenis_Produk\", \n",
    "        \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \n",
    "        \"TID\", \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \n",
    "        \"Bank_BRI\", \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \n",
    "        \"Hasil_Kunjungan\", \"Log_Name\", \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \n",
    "        \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \"Notify_By\", \"Organization\", \n",
    "        \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \"Settlement_ID\", \n",
    "        \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "        \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \n",
    "        \"Tgl_In_Progress\", \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \n",
    "        \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "    ]\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "def process_csv_with_complex_column(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the entire file content into a single string to process it line by line\n",
    "        content = file.read()\n",
    "        \n",
    "        # Split the content into rows based on a pattern that indicates the end of a complex entry\n",
    "        rows = content.split('================')  # This splits each \"block\" that should end up in Column 28\n",
    "        data = []\n",
    "\n",
    "        for row in rows:\n",
    "            # Split each row by commas up to Column 27, handle Column 28 separately, then continue after Column 28\n",
    "            parts = row.split(',')\n",
    "            if len(parts) > 29:  # Ensuring there are enough parts to form all columns\n",
    "                # The first 27 columns + the entire block of text that goes into Column 28\n",
    "                first_part = parts[:27]\n",
    "                col28 = ','.join(parts[27:-51])  # Joining parts that form the complex Column 28 (adjust range as needed)\n",
    "                last_part = parts[-51:]  # Remaining columns after Column 28\n",
    "                \n",
    "                # Combine all parts into a single row, ensuring 79 columns total\n",
    "                full_row = first_part + [col28] + last_part\n",
    "                if len(full_row) == 79:\n",
    "                    data.append(full_row)\n",
    "\n",
    "    # Create a DataFrame from the processed data\n",
    "    return pd.DataFrame(data, columns=col)\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path_v2 = file_path\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_v4 = process_csv_with_complex_column(csv_file_path_v2)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_v4_sample = structured_df_v4.head(10) if not structured_df_v4.empty else \"No data processed correctly.\"\n",
    "df2=structured_df_v4_sample.transpose()\n",
    "pd.set_option('display.max_columns', None)\n",
    "df2.to_csv(\"data_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>Column 10</th>\n",
       "      <th>Column 11</th>\n",
       "      <th>Column 12</th>\n",
       "      <th>Column 13</th>\n",
       "      <th>Column 14</th>\n",
       "      <th>Column 15</th>\n",
       "      <th>Column 16</th>\n",
       "      <th>Column 17</th>\n",
       "      <th>Column 18</th>\n",
       "      <th>Column 19</th>\n",
       "      <th>Column 20</th>\n",
       "      <th>Column 21</th>\n",
       "      <th>Column 22</th>\n",
       "      <th>Column 23</th>\n",
       "      <th>Column 24</th>\n",
       "      <th>Column 25</th>\n",
       "      <th>Column 26</th>\n",
       "      <th>Column 27</th>\n",
       "      <th>Column 28</th>\n",
       "      <th>Column 29</th>\n",
       "      <th>Column 30</th>\n",
       "      <th>Column 31</th>\n",
       "      <th>Column 32</th>\n",
       "      <th>Column 33</th>\n",
       "      <th>Column 34</th>\n",
       "      <th>Column 35</th>\n",
       "      <th>Column 36</th>\n",
       "      <th>Column 37</th>\n",
       "      <th>Column 38</th>\n",
       "      <th>Column 39</th>\n",
       "      <th>Column 40</th>\n",
       "      <th>Column 41</th>\n",
       "      <th>Column 42</th>\n",
       "      <th>Column 43</th>\n",
       "      <th>Column 44</th>\n",
       "      <th>Column 45</th>\n",
       "      <th>Column 46</th>\n",
       "      <th>Column 47</th>\n",
       "      <th>Column 48</th>\n",
       "      <th>Column 49</th>\n",
       "      <th>Column 50</th>\n",
       "      <th>Column 51</th>\n",
       "      <th>Column 52</th>\n",
       "      <th>Column 53</th>\n",
       "      <th>Column 54</th>\n",
       "      <th>Column 55</th>\n",
       "      <th>Column 56</th>\n",
       "      <th>Column 57</th>\n",
       "      <th>Column 58</th>\n",
       "      <th>Column 59</th>\n",
       "      <th>Column 60</th>\n",
       "      <th>Column 61</th>\n",
       "      <th>Column 62</th>\n",
       "      <th>Column 63</th>\n",
       "      <th>Column 64</th>\n",
       "      <th>Column 65</th>\n",
       "      <th>Column 66</th>\n",
       "      <th>Column 67</th>\n",
       "      <th>Column 68</th>\n",
       "      <th>Column 69</th>\n",
       "      <th>Column 70</th>\n",
       "      <th>Column 71</th>\n",
       "      <th>Column 72</th>\n",
       "      <th>Column 73</th>\n",
       "      <th>Column 74</th>\n",
       "      <th>Column 75</th>\n",
       "      <th>Column 76</th>\n",
       "      <th>Column 77</th>\n",
       "      <th>Column 78</th>\n",
       "      <th>Column 79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>085845602167</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>Nasabah mengajukan pemblokiran kartu ATM BRI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Permintaan pemblokiran ATM BRI.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alasan pemblokiran : Hilang</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tanggal Hilang : 31.12.2022</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jam Hilang : 21.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lokasi Kejadian : bri cikunir</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tanggal Pemblokiran :  01/01/2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jam Pemblokiran :  07:06 wib</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>================</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Column 1 Column 2  \\\n",
       "0                    ﻿TTB000043833962     8701   \n",
       "1     Permintaan pemblokiran ATM BRI.            \n",
       "2         Alasan pemblokiran : Hilang            \n",
       "3         Tanggal Hilang : 31.12.2022            \n",
       "4                  Jam Hilang : 21.00            \n",
       "5       Lokasi Kejadian : bri cikunir            \n",
       "6  Tanggal Pemblokiran :  01/01/2023             \n",
       "7        Jam Pemblokiran :  07:06 wib            \n",
       "8                                                \n",
       "9                    ================            \n",
       "\n",
       "                               Column 3                 Column 4 Column 5  \\\n",
       "0  Blokir Kartu ATM karena kartu hilang  2023-01-01 07:08:31.000    Phone   \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "5                                                                           \n",
       "6                                                                           \n",
       "7                                                                           \n",
       "8                                                                           \n",
       "9                                                                           \n",
       "\n",
       "      Column 6         Column 7         Column 8 Column 9 Column 10  \\\n",
       "0  Maintenance  WATI SUSILAWATI  436101009806534     0.00    Closed   \n",
       "1                                                                     \n",
       "2                                                                     \n",
       "3                                                                     \n",
       "4                                                                     \n",
       "5                                                                     \n",
       "6                                                                     \n",
       "7                                                                     \n",
       "8                                                                     \n",
       "9                                                                     \n",
       "\n",
       "                 Column 11                Column 12 Column 13     Column 14  \\\n",
       "0  2023-01-01 07:08:50.000  2023-01-01 00:00:00.000       N/A  Blokir Kartu   \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "5                                                                             \n",
       "6                                                                             \n",
       "7                                                                             \n",
       "8                                                                             \n",
       "9                                                                             \n",
       "\n",
       "          Column 15    Column 16 Column 17 Column 18 Column 19  \\\n",
       "0  6013013389522694  LCC-CCTCALL      NULL      NULL      NULL   \n",
       "1                                                                \n",
       "2                                                                \n",
       "3                                                                \n",
       "4                                                                \n",
       "5                                                                \n",
       "6                                                                \n",
       "7                                                                \n",
       "8                                                                \n",
       "9                                                                \n",
       "\n",
       "            Column 20     Column 21 Column 22 Column 23 Column 24 Column 25  \\\n",
       "0  Novita Ayu Lestari  085845602167      NULL      NULL        20  SMG61072   \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "5                                                                             \n",
       "6                                                                             \n",
       "7                                                                             \n",
       "8                                                                             \n",
       "9                                                                             \n",
       "\n",
       "                  Column 26           Column 27  \\\n",
       "0  00196 -- KANWIL Semarang  Novita Ayu Lestari   \n",
       "1                                                 \n",
       "2                                                 \n",
       "3                                                 \n",
       "4                                                 \n",
       "5                                                 \n",
       "6                                                 \n",
       "7                                                 \n",
       "8                                                 \n",
       "9                                                 \n",
       "\n",
       "                                      Column 28 Column 29 Column 30 Column 31  \\\n",
       "0  Nasabah mengajukan pemblokiran kartu ATM BRI                                 \n",
       "1                                                                               \n",
       "2                                                                               \n",
       "3                                                                               \n",
       "4                                                                               \n",
       "5                                                                               \n",
       "6                                                                               \n",
       "7                                                                               \n",
       "8                                                                               \n",
       "9                                                                               \n",
       "\n",
       "  Column 32 Column 33 Column 34 Column 35 Column 36 Column 37 Column 38  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 39 Column 40 Column 41 Column 42 Column 43 Column 44 Column 45  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 46 Column 47 Column 48 Column 49 Column 50 Column 51 Column 52  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 53 Column 54 Column 55 Column 56 Column 57 Column 58 Column 59  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 60 Column 61 Column 62 Column 63 Column 64 Column 65 Column 66  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 67 Column 68 Column 69 Column 70 Column 71 Column 72 Column 73  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 74 Column 75 Column 76 Column 77 Column 78 Column 79  \n",
       "0                                                              \n",
       "1                                                              \n",
       "2                                                              \n",
       "3                                                              \n",
       "4                                                              \n",
       "5                                                              \n",
       "6                                                              \n",
       "7                                                              \n",
       "8                                                              \n",
       "9                                                              "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Initialize a list to store the processed rows\n",
    "        data = []\n",
    "        \n",
    "        # Read the file line by line\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # Extract the first 27 columns directly\n",
    "            if len(row) < 79:\n",
    "                # Append empty fields if row is not long enough (handling potential errors in CSV formatting)\n",
    "                row += [''] * (79 - len(row))\n",
    "            \n",
    "            # Columns 1-27 are directly taken from the row based on your mapping\n",
    "            first_part = row[:27]\n",
    "            \n",
    "            # Column 28: Aggregating complex block data into one column (Example aggregation logic needed)\n",
    "            complex_data = ' '.join(row[27:28])  # Assuming we collect multiple pieces into one column here\n",
    "            \n",
    "            # Remaining columns, from 29 to 79\n",
    "            last_part = row[28:]\n",
    "\n",
    "            # Combine the parts into a full row ensuring it matches the expected 79 columns format\n",
    "            full_row = first_part + [complex_data] + last_part[:51]  # Adjust the slicing based on actual content need\n",
    "            if len(full_row) == 79:\n",
    "                data.append(full_row)\n",
    "            else:\n",
    "                # Padding in case there are missing columns to ensure each row has exactly 79 columns\n",
    "                full_row += [''] * (79 - len(full_row))\n",
    "                data.append(full_row)\n",
    "\n",
    "    # Create a DataFrame from the processed data\n",
    "    return pd.DataFrame(data, columns=[f\"Column {i+1}\" for i in range(79)])\n",
    "\n",
    "# Path to the updated CSV file\n",
    "updated_csv_file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(updated_csv_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Display a sample of the structured data\n",
    "pd.set_option('display.max_columns', None)\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "# structured_df_final_sample['Column 1'] = structured_df_final_sample['Column 1'].apply(lambda x: x if x.startswith('TTB') and len(x) == 15 else None)\n",
    "# structured_df_final_sample['Column 1'] = structured_df_final_sample.dropna(subset=['Column 1'])\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st 27 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>Column 10</th>\n",
       "      <th>Column 11</th>\n",
       "      <th>Column 12</th>\n",
       "      <th>Column 13</th>\n",
       "      <th>Column 14</th>\n",
       "      <th>Column 15</th>\n",
       "      <th>Column 16</th>\n",
       "      <th>Column 17</th>\n",
       "      <th>Column 18</th>\n",
       "      <th>Column 19</th>\n",
       "      <th>Column 20</th>\n",
       "      <th>Column 21</th>\n",
       "      <th>Column 22</th>\n",
       "      <th>Column 23</th>\n",
       "      <th>Column 24</th>\n",
       "      <th>Column 25</th>\n",
       "      <th>Column 26</th>\n",
       "      <th>Column 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>8.584560e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column 1 Column 2                              Column 3  \\\n",
       "0  TTB000043833962     8701  Blokir Kartu ATM karena kartu hilang   \n",
       "\n",
       "                  Column 4 Column 5     Column 6         Column 7  \\\n",
       "0  2023-01-01 07:08:31.000    Phone  Maintenance  WATI SUSILAWATI   \n",
       "\n",
       "          Column 8  Column 9 Column 10                Column 11  \\\n",
       "0  436101009806534       0.0    Closed  2023-01-01 07:08:50.000   \n",
       "\n",
       "                 Column 12  Column 13     Column 14         Column 15  \\\n",
       "0  2023-01-01 00:00:00.000        NaN  Blokir Kartu  6013013389522694   \n",
       "\n",
       "     Column 16  Column 17  Column 18 Column 19           Column 20  \\\n",
       "0  LCC-CCTCALL        NaN        NaN       NaN  Novita Ayu Lestari   \n",
       "\n",
       "      Column 21 Column 22  Column 23 Column 24 Column 25  \\\n",
       "0  8.584560e+10       NaN        NaN        20  SMG61072   \n",
       "\n",
       "                  Column 26           Column 27  \n",
       "0  00196 -- KANWIL Semarang  Novita Ayu Lestari  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "column_headers = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "    \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "    \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assigned_to\", \"attachment_done\", \n",
    "    \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "    \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\"\n",
    "]\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    # Load the CSV file into a DataFrame, processing only the necessary columns (first 27 columns)\n",
    "    df = pd.read_csv(file_path, usecols=range(27), header=None)\n",
    "\n",
    "    df = df.iloc[:1]\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    df.columns = [f\"Column {i+1}\" for i in range(27)]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(file_path)\n",
    "\n",
    "# Set display options for better output visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket_ID</th>\n",
       "      <th>Call_Type_ID</th>\n",
       "      <th>Call_Type</th>\n",
       "      <th>Create_Date</th>\n",
       "      <th>gateway</th>\n",
       "      <th>Jenis_Laporan</th>\n",
       "      <th>Nama_Nasabah</th>\n",
       "      <th>No_Rekening</th>\n",
       "      <th>Nominal</th>\n",
       "      <th>status</th>\n",
       "      <th>TanggalClosed</th>\n",
       "      <th>tanggalTransaksi</th>\n",
       "      <th>Chanel</th>\n",
       "      <th>Fitur</th>\n",
       "      <th>Nomor_Kartu</th>\n",
       "      <th>user_group</th>\n",
       "      <th>assigned_to</th>\n",
       "      <th>attachment_done</th>\n",
       "      <th>email</th>\n",
       "      <th>full_name</th>\n",
       "      <th>no_telepon</th>\n",
       "      <th>approver_login</th>\n",
       "      <th>approver_name</th>\n",
       "      <th>SLAResolution</th>\n",
       "      <th>submitter_login_id</th>\n",
       "      <th>submitter_user_group</th>\n",
       "      <th>user_login_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>8.584560e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket_ID Call_Type_ID                             Call_Type  \\\n",
       "0  TTB000043833962         8701  Blokir Kartu ATM karena kartu hilang   \n",
       "\n",
       "               Create_Date gateway Jenis_Laporan     Nama_Nasabah  \\\n",
       "0  2023-01-01 07:08:31.000   Phone   Maintenance  WATI SUSILAWATI   \n",
       "\n",
       "       No_Rekening  Nominal  status            TanggalClosed  \\\n",
       "0  436101009806534      0.0  Closed  2023-01-01 07:08:50.000   \n",
       "\n",
       "          tanggalTransaksi  Chanel         Fitur       Nomor_Kartu  \\\n",
       "0  2023-01-01 00:00:00.000     NaN  Blokir Kartu  6013013389522694   \n",
       "\n",
       "    user_group  assigned_to  attachment_done email           full_name  \\\n",
       "0  LCC-CCTCALL          NaN              NaN   NaN  Novita Ayu Lestari   \n",
       "\n",
       "     no_telepon approver_login  approver_name SLAResolution  \\\n",
       "0  8.584560e+10            NaN            NaN            20   \n",
       "\n",
       "  submitter_login_id      submitter_user_group     user_login_name  \n",
       "0           SMG61072  00196 -- KANWIL Semarang  Novita Ayu Lestari  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Specified column headers\n",
    "column_headers = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "    \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "    \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assigned_to\", \"attachment_done\", \n",
    "    \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "    \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\"\n",
    "]\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    # Load the CSV file into a DataFrame, processing only the necessary columns (first 27 columns)\n",
    "    df = pd.read_csv(file_path, usecols=range(27), header=None)\n",
    "\n",
    "    df = df.iloc[:1]\n",
    "\n",
    "    # Rename columns using the specified column headers\n",
    "    df.columns = column_headers\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(file_path)\n",
    "\n",
    "# Set display options for better output visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Splitting the text into a more manageable format\n",
    "    # Assume we split at the first occurrence of '================'\n",
    "    parts = text.split('================', 1)\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    # Column 1 will have 'Aku', Column 2 will have the rest of the text after '================'\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [\"Aku\"],\n",
    "        \"Column 2\": [parts[1].strip()]  # Using strip to remove leading/trailing whitespace\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace 'path_to_your_file.txt' with the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Splitting the text to extract the third column value\n",
    "    # Assume 'Tabungan' or similar values are added after the final '================,' so we split there first\n",
    "    parts = text.split('================,')\n",
    "    third_column_value = parts[1].strip() if len(parts) > 1 else \"Missing Value\"\n",
    "    \n",
    "    # Now split the first part further to separate out the main content\n",
    "    main_content_parts = parts[0].split('================', 1)\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    # Column 1 will have 'Aku', Column 2 will have the content after the first '================',\n",
    "    # and Column 3 will have the value from the third column\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [\"Aku\"],\n",
    "        \"Column 2\": [main_content_parts[1].strip() if len(main_content_parts) > 1 else \"Missing Content\"],  # Handle missing content\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace 'path_to_your_file.txt' with the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# search the ================, and set the value to be the value for the next column\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## great for 3 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Find the beginning of the content after \"Aku,\" to set up for Column 2\n",
    "    first_column_value = \"Aku\"\n",
    "    second_column_start = main_content.find(\"Aku,\") + len(\"Aku,\")\n",
    "    second_column_value = main_content[second_column_start:].strip()  # Remove any leading/trailing whitespace\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\" \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "# df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "\n",
    "df.to_csv(\"new_.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 4 starting from Kode ..., Column 5= empty, Column 6 Tabungan1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text using '================' as a separator\n",
    "    parts = text.split('================')\n",
    "    \n",
    "    # Assume the first line contains the labels for the first three columns, which are static\n",
    "    header_labels = parts[0].strip().split('\\n')[0].split(',')\n",
    "    if len(header_labels) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"Header format is not as expected. Check the first line for correct labels.\"]})\n",
    "\n",
    "    # Extracting the main body for Column 4, which includes multiple '================' sections\n",
    "    column4_content = '================'.join(parts[1:-1]).strip()\n",
    "\n",
    "    # Extract the last part for Columns 5 and 6\n",
    "    footer_labels = parts[-1].split(',')\n",
    "    if len(footer_labels) < 2:\n",
    "        return pd.DataFrame({\"Error\": [\"Footer format is not as expected. Insufficient labels after the last '================'.\"]})\n",
    "\n",
    "    # Trim and prepare the labels for the last two columns\n",
    "    column5_label = footer_labels[0].strip()\n",
    "    column6_label = footer_labels[1].strip()\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [header_labels[0].strip()],\n",
    "        \"Column 2\": [header_labels[1].strip()],\n",
    "        \"Column 3\": [header_labels[2].strip()],\n",
    "        \"Column 4\": [column4_content],\n",
    "        \"Column 5\": [column5_label],\n",
    "        \"Column 6\": [column6_label]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new4_.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text using '================' as a separator to isolate the main content and footer\n",
    "    parts = text.split('================')\n",
    "    if len(parts) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"The text does not contain enough sections separated by '================'.\"]})\n",
    "\n",
    "    # Extracting the main body for Column 4, assumed to be between the first and second '================'\n",
    "    column4_content = '\\n================\\n'.join(parts[1:-1]).strip()\n",
    "\n",
    "    # Extract the footer content right after the last '================'\n",
    "    # Assuming the footer starts with Tabungan1, Tabungan2 right after the last '================'\n",
    "    # footer_content = parts[-1].split(',')\n",
    "    # if len(footer_content) < 2:\n",
    "    #     return pd.DataFrame({\"Error\": [\"Footer content is not formatted as expected. Ensure it follows the last '================'.\"]})\n",
    "\n",
    "    footer_content=text.split('================,', 1)\n",
    "    # The first header should contain main labels if structured as expected\n",
    "    header_labels = parts[0].strip().split('\\n')[0].split(',')\n",
    "    if len(header_labels) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"Header labels are missing or incomplete.\"]})\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [header_labels[0].strip()],\n",
    "        \"Column 2\": [header_labels[1].strip()],\n",
    "        \"Column 3\": [header_labels[2].strip()],\n",
    "        \"Column 4\": [column4_content],\n",
    "        \"Column 5\": [footer_content[0].strip()]\n",
    "        # \"Column 5\": [footer_content[0].strip()],\n",
    "        # \"Column 6\": [footer_content[1].strip()]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new5_.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Column0 Column1\n",
      "0    Tab1    Tab2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with one column\n",
    "df = pd.DataFrame({'Column1': ['Tab1, Tab2']})\n",
    "\n",
    "# Split the single value in the column by comma (assuming there's only one comma)\n",
    "split_values = df['Column1'].str.split(',', expand=True)\n",
    "\n",
    "# Rename columns (optional)\n",
    "split_values.columns = ['Column0', 'Column1']\n",
    "\n",
    "# Update the DataFrame\n",
    "df = split_values.copy()\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main</td>\n",
       "      <td>Nasabah mengajukan pemblokiran kartu ATM BRI\\n...</td>\n",
       "      <td>Tabungan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column 1                                           Column 2  Column 3\n",
       "0     Main  Nasabah mengajukan pemblokiran kartu ATM BRI\\n...  Tabungan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "# df.to_csv(\"new_.csv\")\n",
    "df.to_csv(\"newbig_.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# file_path=r\"D:\\dataquality\\new_.csv\"\n",
    "file_path=r\"D:\\dataquality\\newbig_.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "column_2_expanded = data['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = data['Column 3'].str.split(',', expand=True)\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Naming the new columns\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "# Inserting these new columns before the original 'Column 2' and 'Column 3'\n",
    "new_data = pd.concat([data.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"new_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRICARE cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Column 1 Column_2_1                            Column_2_2  \\\n",
      "0  ﻿TTB000043833962       8701  Blokir Kartu ATM karena kartu hilang   \n",
      "\n",
      "                Column_2_3 Column_2_4   Column_2_5       Column_2_6  \\\n",
      "0  2023-01-01 07:08:31.000      Phone  Maintenance  WATI SUSILAWATI   \n",
      "\n",
      "        Column_2_7 Column_2_8 Column_2_9  ... Column_3_42 Column_3_43  \\\n",
      "0  436101009806534       0.00     Closed  ...        NULL        NULL   \n",
      "\n",
      "  Column_3_44 Column_3_45 Column_3_46 Column_3_47 Column_3_48 Column_3_49  \\\n",
      "0        NULL        NULL        NULL        NULL       Notes        NULL   \n",
      "\n",
      "  Column_3_50      Column_3_51  \n",
      "0        Call  000000000000004  \n",
      "\n",
      "[1 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()\n",
    "\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "    second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "file_path = r\"D:\\test.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "column_2_expanded = df['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Column 3'].str.split(',', expand=True)\n",
    "\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "new_data = pd.concat([df.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"test.csv\")\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Ticket_ID Call_Type_ID                             Call_Type  \\\n",
      "0  ﻿TTB000043833962         8701  Blokir Kartu ATM karena kartu hilang   \n",
      "\n",
      "               Create_Date gateway Jenis_Laporan     Nama_Nasabah  \\\n",
      "0  2023-01-01 07:08:31.000   Phone   Maintenance  WATI SUSILAWATI   \n",
      "\n",
      "       No_Rekening Nominal  status  ... Tanggal_Settlement Tgl_Foward  \\\n",
      "0  436101009806534    0.00  Closed  ...               NULL       NULL   \n",
      "\n",
      "  Tgl_In_Progress Tgl_Returned Ticket_Referensi Tiket_Urgency Tipe_Remark  \\\n",
      "0            NULL         NULL             NULL          NULL       Notes   \n",
      "\n",
      "  UniqueID users     Usergroup_ID  \n",
      "0     NULL  Call  000000000000004  \n",
      "\n",
      "[1 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()\n",
    "\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "    second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "    # Create a DataFrame with initial rough columns\n",
    "    df = pd.DataFrame({\n",
    "        \"Initial_Column_1\": [first_column_value],\n",
    "        \"Initial_Column_2\": [second_column_value],\n",
    "        \"Initial_Column_3\": [third_column_value]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "file_path = r\"D:\\test.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "# Assuming 'Initial_Column_2' and 'Initial_Column_3' need to be expanded into multiple columns\n",
    "column_2_expanded = df['Initial_Column_2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Initial_Column_3'].str.split(',', expand=True)\n",
    "\n",
    "# List of all column names\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "# Concatenate expanded columns with the original DataFrame, dropping the initial columns used for expansion\n",
    "new_data = pd.concat([df.drop(['Initial_Column_2', 'Initial_Column_3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "# Ensure the total columns in DataFrame matches with the length of column_names\n",
    "new_data.columns = column_names[:new_data.shape[1]]\n",
    "\n",
    "new_data.to_csv(\"test.csv\")\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Line 1 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 2 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 3 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 4 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 5 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 6 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 7 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 8 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 9 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 10 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 11 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 12 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 13 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 14 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 15 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 16 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 17 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 18 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 19 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 20 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 21 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 22 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 23 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 24 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 25 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 26 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 27 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 28 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 29 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 30 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 31 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 32 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n",
      "Warning: Line 33 formatted incorrectly and was skipped. Error: not enough values to unpack (expected 2, got 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_df\n\u001b[0;32m     27\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest_bricare2line.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m---> 28\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataframe_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m column_2_expanded \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn 2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m column_3_expanded \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn 3\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36mcreate_dataframe_from_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m formatted incorrectly and was skipped. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Concatenate all DataFrames into a single DataFrame\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m combined_df\n",
      "File \u001b[1;32mc:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Users\\maste\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    dataframes = []  # List to hold all individual DataFrames\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line_number, line in enumerate(file, 1):  # Process each line individually\n",
    "            try:\n",
    "                main_content, third_column_value = line.split('================,', 1)\n",
    "                third_column_value = third_column_value.strip()\n",
    "\n",
    "                first_column_value = main_content.split(',', 1)[0].strip()\n",
    "                second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "                df = pd.DataFrame({\n",
    "                    \"Column 1\": [first_column_value],\n",
    "                    \"Column 2\": [second_column_value],\n",
    "                    \"Column 3\": [third_column_value]\n",
    "                })\n",
    "                dataframes.append(df)\n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: Line {line_number} formatted incorrectly and was skipped. Error: {str(e)}\")\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "file_path = r\"D:\\test_bricare2line.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "column_2_expanded = df['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Column 3'].str.split(',', expand=True)\n",
    "\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "new_data = pd.concat([df.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"test2.csv\", index=False)\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial to get everythin in order before the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TTB000026204697', '5100', 'Informasi Tagihan, Status Pembayaran, Sisa limit, Fee, Bunga, Late Charge Kartu Kredit', '2020-01-01 07:06:22.000']\n"
     ]
    }
   ],
   "source": [
    "# please see my codes below, I have a list of column names \"column_names\" I want the output is dataframe and after date they would be the other columns\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "def parse_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Strip newline characters and other surrounding whitespace\n",
    "            line = line.strip()\n",
    "            # Use regular expressions to find all components\n",
    "            # Find the first column (TTB followed by 12 digits)\n",
    "            first_col = re.search(r'TTB\\d{12}', line).group(0)\n",
    "            # Find the second column (4 digits)\n",
    "            second_col = re.search(r',(\\d{4}),', line).group(1)\n",
    "            # Find the fourth column (date and time)\n",
    "            fourth_col = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}', line).group(0)\n",
    "            # Extract everything between second and fourth columns for third column\n",
    "            start_index = line.index(second_col) + len(second_col) + 1\n",
    "            end_index = line.index(fourth_col)\n",
    "            third_col = line[start_index:end_index].strip(',')\n",
    "            # Append the parsed columns to the data list\n",
    "            data.append([first_col, second_col, third_col, fourth_col])\n",
    "    return data\n",
    "\n",
    "# Usage\n",
    "file_path = r\"D:\\oneline.txt\"\n",
    "parsed_data = parse_file(file_path)\n",
    "\n",
    "for line in parsed_data:\n",
    "    print(line)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "def parse_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Strip newline characters and other surrounding whitespace\n",
    "            line = line.strip()\n",
    "            # Use regular expressions to find all components\n",
    "            # Find the first column (TTB followed by 12 digits)\n",
    "            first_col = re.search(r'TTB\\d{12}', line).group(0)\n",
    "            # Find the second column (4 digits)\n",
    "            second_col = re.search(r',(\\d{4}),', line).group(1)\n",
    "            # Find the fourth column (date and time)\n",
    "            fourth_col = re.search(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}', line).group(0)\n",
    "            # Extract everything between second and fourth columns for third column\n",
    "            start_index = line.index(second_col) + len(second_col) + 1\n",
    "            end_index = line.index(fourth_col)\n",
    "            third_col = line[start_index:end_index].strip(',')\n",
    "            # Split the rest of the line after the date for remaining columns\n",
    "            remaining_columns = line[end_index + len(fourth_col):].split(',')\n",
    "            # Append the parsed columns to the data list\n",
    "            data.append([first_col, second_col, third_col, fourth_col] + remaining_columns)\n",
    "\n",
    "#     # Create DataFrame from data list\n",
    "#     df = pd.DataFrame(data, columns=column_names)\n",
    "#     return df\n",
    "\n",
    "# # Usage\n",
    "# file_path = \"D:\\\\oneline.txt\"\n",
    "# parsed_data_df = parse_file(file_path)\n",
    "# print(parsed_data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (754145583.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [6]\u001b[1;36m\u001b[0m\n\u001b[1;33m    please just delete the column names, you can name it by number, now lets just focus on this problem;\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>Column_10</th>\n",
       "      <th>Column_11</th>\n",
       "      <th>Column_12</th>\n",
       "      <th>Column_13</th>\n",
       "      <th>Column_14</th>\n",
       "      <th>Column_15</th>\n",
       "      <th>Column_16</th>\n",
       "      <th>Column_17</th>\n",
       "      <th>Column_18</th>\n",
       "      <th>Column_19</th>\n",
       "      <th>Column_20</th>\n",
       "      <th>Column_21</th>\n",
       "      <th>Column_22</th>\n",
       "      <th>Column_23</th>\n",
       "      <th>Column_24</th>\n",
       "      <th>Column_25</th>\n",
       "      <th>Column_26</th>\n",
       "      <th>Column_27</th>\n",
       "      <th>Column_28</th>\n",
       "      <th>Column_29</th>\n",
       "      <th>Column_30</th>\n",
       "      <th>Column_31</th>\n",
       "      <th>Column_32</th>\n",
       "      <th>Column_33</th>\n",
       "      <th>Column_34</th>\n",
       "      <th>Column_35</th>\n",
       "      <th>Column_36</th>\n",
       "      <th>Column_37</th>\n",
       "      <th>Column_38</th>\n",
       "      <th>Column_39</th>\n",
       "      <th>Column_40</th>\n",
       "      <th>Column_41</th>\n",
       "      <th>Column_42</th>\n",
       "      <th>Column_43</th>\n",
       "      <th>Column_44</th>\n",
       "      <th>Column_45</th>\n",
       "      <th>Column_46</th>\n",
       "      <th>Column_47</th>\n",
       "      <th>Column_48</th>\n",
       "      <th>Column_49</th>\n",
       "      <th>Column_50</th>\n",
       "      <th>Column_51</th>\n",
       "      <th>Column_52</th>\n",
       "      <th>Column_53</th>\n",
       "      <th>Column_54</th>\n",
       "      <th>Column_55</th>\n",
       "      <th>Column_56</th>\n",
       "      <th>Column_57</th>\n",
       "      <th>Column_58</th>\n",
       "      <th>Column_59</th>\n",
       "      <th>Column_60</th>\n",
       "      <th>Column_61</th>\n",
       "      <th>Column_62</th>\n",
       "      <th>Column_63</th>\n",
       "      <th>Column_64</th>\n",
       "      <th>Column_65</th>\n",
       "      <th>Column_66</th>\n",
       "      <th>Column_67</th>\n",
       "      <th>Column_68</th>\n",
       "      <th>Column_69</th>\n",
       "      <th>Column_70</th>\n",
       "      <th>Column_71</th>\n",
       "      <th>Column_72</th>\n",
       "      <th>Column_73</th>\n",
       "      <th>Column_74</th>\n",
       "      <th>Column_75</th>\n",
       "      <th>Column_76</th>\n",
       "      <th>Column_77</th>\n",
       "      <th>Column_78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833952</td>\n",
       "      <td>8433</td>\n",
       "      <td>Pembayaran Tagihan Gagal;Saldo Berkurang;Kartu...</td>\n",
       "      <td>2023-01-01 07:00:19</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Complain</td>\n",
       "      <td>Zaka Putra</td>\n",
       "      <td>1,23457E+14</td>\n",
       "      <td>5350000.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-03 14:49:51.000</td>\n",
       "      <td>2023-12-31 00:00:00.000</td>\n",
       "      <td>ATM BRI</td>\n",
       "      <td>Pembayaran</td>\n",
       "      <td>5221234567890120</td>\n",
       "      <td>LCC-ISSUER</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Adelia Awanda Dania</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>20</td>\n",
       "      <td>90148127</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Adelia Awanda Dania</td>\n",
       "      <td>Tabungan</td>\n",
       "      <td>bricare_admin</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-03 14:49:51.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Simpanan</td>\n",
       "      <td>Met</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-02 00:00:00.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>BRI</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>BRICare Administrator</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>Dewi Kartika Sari</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>Bank BRI</td>\n",
       "      <td>Insert Ticket Berhasil</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>428</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>00229 -- Kas Kanpus</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Gagal</td>\n",
       "      <td>KAS KANPUS</td>\n",
       "      <td>Kas Kanpus</td>\n",
       "      <td>4</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-03 00:00:00.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Notes</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Call</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column_1 Column_2  \\\n",
       "0  TTB000043833952     8433   \n",
       "\n",
       "                                            Column_3            Column_4  \\\n",
       "0  Pembayaran Tagihan Gagal;Saldo Berkurang;Kartu... 2023-01-01 07:00:19   \n",
       "\n",
       "  Column_5  Column_6    Column_7     Column_8    Column_9 Column_10  \\\n",
       "0    Phone  Complain  Zaka Putra  1,23457E+14  5350000.00    Closed   \n",
       "\n",
       "                 Column_11                Column_12 Column_13   Column_14  \\\n",
       "0  2023-01-03 14:49:51.000  2023-12-31 00:00:00.000   ATM BRI  Pembayaran   \n",
       "\n",
       "          Column_15   Column_16 Column_17 Column_18 Column_19  \\\n",
       "0  5221234567890120  LCC-ISSUER      NULL      NULL      NULL   \n",
       "\n",
       "             Column_20     Column_21 Column_22 Column_23 Column_24 Column_25  \\\n",
       "0  Adelia Awanda Dania  081234567890      NULL      NULL        20  90148127   \n",
       "\n",
       "     Column_26            Column_27 Column_28      Column_29 Column_30  \\\n",
       "0  LCC-CCTCALL  Adelia Awanda Dania  Tabungan  bricare_admin      NULL   \n",
       "\n",
       "                 Column_31 Column_32 Column_33 Column_34 Column_35 Column_36  \\\n",
       "0  2023-01-03 14:49:51.000      NULL  Simpanan       Met      NULL      NULL   \n",
       "\n",
       "                 Column_37 Column_38 Column_39 Column_40 Column_41 Column_42  \\\n",
       "0  2023-01-02 00:00:00.000      NULL      NULL      NULL       BRI      NULL   \n",
       "\n",
       "  Column_43 Column_44 Column_45 Column_46 Column_47              Column_48  \\\n",
       "0      NULL      NULL        No      NULL      NULL  BRICare Administrator   \n",
       "\n",
       "  Column_49 Column_50          Column_51 Column_52 Column_53 Column_54  \\\n",
       "0      NULL        No  Dewi Kartika Sari      NULL      NULL        No   \n",
       "\n",
       "  Column_55 Column_56               Column_57 Column_58 Column_59 Column_60  \\\n",
       "0      None  Bank BRI  Insert Ticket Berhasil      NULL      NULL       428   \n",
       "\n",
       "  Column_61 Column_62            Column_63 Column_64 Column_65   Column_66  \\\n",
       "0      NULL       Yes  00229 -- Kas Kanpus      NULL     Gagal  KAS KANPUS   \n",
       "\n",
       "    Column_67 Column_68 Column_69 Column_70                Column_71  \\\n",
       "0  Kas Kanpus         4      NULL      NULL  2023-01-03 00:00:00.000   \n",
       "\n",
       "  Column_72 Column_73 Column_74 Column_75 Column_76 Column_77 Column_78  \n",
       "0      NULL      NULL      NULL     Notes      NULL      Call         1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_file(file_path):\n",
    "    # Initialize a list to hold the parsed data\n",
    "    data = []\n",
    "    date_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}')\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(';')\n",
    "            # Find the index of the first date (fourth column)\n",
    "            date_index = next(i for i, part in enumerate(parts) if date_pattern.match(part))\n",
    "\n",
    "            # Extract columns\n",
    "            ticket_id = parts[0]  # First column\n",
    "            call_type_id = parts[1]  # Second column\n",
    "            description = ';'.join(parts[2:date_index])  # Third column, concatenating all parts up to the date\n",
    "            create_date = parts[date_index]  # Fourth column, the first date found\n",
    "\n",
    "            # Append the parsed columns and the rest of the data\n",
    "            data.append([ticket_id, call_type_id, description, create_date] + parts[date_index + 1:])\n",
    "\n",
    "    # Create DataFrame with generic column names\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [f\"Column_{i+1}\" for i in range(len(df.columns))]\n",
    "\n",
    "    # Convert 'Column_4' to datetime\n",
    "    df['Column_4'] = pd.to_datetime(df['Column_4'], errors='coerce', format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\dila_1line.txt\"\n",
    "df = parse_file(file_path)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket_ID</th>\n",
       "      <th>Call_Type_ID</th>\n",
       "      <th>Call_Type</th>\n",
       "      <th>Create_Date</th>\n",
       "      <th>gateway</th>\n",
       "      <th>Jenis_Laporan</th>\n",
       "      <th>Nama_Nasabah</th>\n",
       "      <th>No_Rekening</th>\n",
       "      <th>Nominal</th>\n",
       "      <th>status</th>\n",
       "      <th>TanggalClosed</th>\n",
       "      <th>tanggalTransaksi</th>\n",
       "      <th>Chanel</th>\n",
       "      <th>Fitur</th>\n",
       "      <th>Nomor_Kartu</th>\n",
       "      <th>user_group</th>\n",
       "      <th>assgined_to</th>\n",
       "      <th>attachment_done</th>\n",
       "      <th>email</th>\n",
       "      <th>full_name</th>\n",
       "      <th>no_telepon</th>\n",
       "      <th>approver_login</th>\n",
       "      <th>approver_name</th>\n",
       "      <th>SLAResolution</th>\n",
       "      <th>submitter_login_id</th>\n",
       "      <th>submitter_user_group</th>\n",
       "      <th>user_login_name</th>\n",
       "      <th>Jenis_Produk</th>\n",
       "      <th>Last_Modified_By</th>\n",
       "      <th>Merchant_ID</th>\n",
       "      <th>Modified_Date</th>\n",
       "      <th>NOTAS</th>\n",
       "      <th>Produk</th>\n",
       "      <th>SLA_Status</th>\n",
       "      <th>TID</th>\n",
       "      <th>tanggalAttachmentDone</th>\n",
       "      <th>Tgl_Assigned</th>\n",
       "      <th>Tgl_Eskalasi</th>\n",
       "      <th>AnalisaSkils</th>\n",
       "      <th>Attachment_</th>\n",
       "      <th>Bank_BRI</th>\n",
       "      <th>Biaya_Admin</th>\n",
       "      <th>Suku_Bunga</th>\n",
       "      <th>Bunga</th>\n",
       "      <th>Butuh_Attachment</th>\n",
       "      <th>Cicilan</th>\n",
       "      <th>Hasil_Kunjungan</th>\n",
       "      <th>Log_Name</th>\n",
       "      <th>MMS_Ticket_Id</th>\n",
       "      <th>Mass_Ticket_Upload_Flag</th>\n",
       "      <th>Nama_Supervisor</th>\n",
       "      <th>Nama_TL</th>\n",
       "      <th>Nama_Wakabag</th>\n",
       "      <th>Nasabah_Prioritas</th>\n",
       "      <th>Notify_By</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Output_Settlement</th>\n",
       "      <th>phone_survey</th>\n",
       "      <th>Return_Ticket</th>\n",
       "      <th>Settlement_By</th>\n",
       "      <th>Settlement_ID</th>\n",
       "      <th>Settlement</th>\n",
       "      <th>Site_User</th>\n",
       "      <th>Status_Return</th>\n",
       "      <th>Status_Transaksi</th>\n",
       "      <th>Submitter_Region</th>\n",
       "      <th>Submitter_SiteGroup</th>\n",
       "      <th>Submitter_User_group_ID</th>\n",
       "      <th>Tanggal_Settlement</th>\n",
       "      <th>Tgl_Foward</th>\n",
       "      <th>Tgl_In_Progress</th>\n",
       "      <th>Tgl_Returned</th>\n",
       "      <th>Ticket_Referensi</th>\n",
       "      <th>Tiket_Urgency</th>\n",
       "      <th>Tipe_Remark</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>users</th>\n",
       "      <th>Usergroup_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833835</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:07:15</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>Anwar</td>\n",
       "      <td>123456789012345</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:07:51.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>5221234567890120</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Meli Rahayu</td>\n",
       "      <td>081234567890</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>20</td>\n",
       "      <td>60872</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>Meli Rahayu</td>\n",
       "      <td>Tabungan</td>\n",
       "      <td>60872</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2023-01-01 07:07:51.000</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Simpanan</td>\n",
       "      <td>Met</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>BRI</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Meli Rahayu .</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>Dika Purwarini</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>Bank BRI</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>No</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Semarang</td>\n",
       "      <td>KANWIL Semarang</td>\n",
       "      <td>4</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Notes</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Call</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket_ID Call_Type_ID                             Call_Type  \\\n",
       "0  TTB000043833835         8701  Blokir Kartu ATM karena kartu hilang   \n",
       "\n",
       "          Create_Date gateway Jenis_Laporan Nama_Nasabah      No_Rekening  \\\n",
       "0 2023-01-01 07:07:15   Phone   Maintenance        Anwar  123456789012345   \n",
       "\n",
       "  Nominal  status            TanggalClosed         tanggalTransaksi Chanel  \\\n",
       "0    0.00  Closed  2023-01-01 07:07:51.000  2023-01-01 00:00:00.000    N/A   \n",
       "\n",
       "          Fitur       Nomor_Kartu   user_group assgined_to attachment_done  \\\n",
       "0  Blokir Kartu  5221234567890120  LCC-CCTCALL        NULL            NULL   \n",
       "\n",
       "  email    full_name    no_telepon approver_login approver_name SLAResolution  \\\n",
       "0  NULL  Meli Rahayu  081234567890           NULL          NULL            20   \n",
       "\n",
       "  submitter_login_id submitter_user_group user_login_name Jenis_Produk  \\\n",
       "0              60872          LCC-CCTCALL     Meli Rahayu     Tabungan   \n",
       "\n",
       "  Last_Modified_By Merchant_ID            Modified_Date NOTAS    Produk  \\\n",
       "0            60872        NULL  2023-01-01 07:07:51.000  NULL  Simpanan   \n",
       "\n",
       "  SLA_Status   TID tanggalAttachmentDone Tgl_Assigned Tgl_Eskalasi  \\\n",
       "0        Met  NULL                  NULL         NULL         NULL   \n",
       "\n",
       "  AnalisaSkils Attachment_ Bank_BRI Biaya_Admin Suku_Bunga Bunga  \\\n",
       "0         NULL        NULL      BRI        NULL       NULL  NULL   \n",
       "\n",
       "  Butuh_Attachment Cicilan Hasil_Kunjungan       Log_Name MMS_Ticket_Id  \\\n",
       "0               No    NULL            NULL  Meli Rahayu .          NULL   \n",
       "\n",
       "  Mass_Ticket_Upload_Flag Nama_Supervisor Nama_TL Nama_Wakabag  \\\n",
       "0                      No  Dika Purwarini    NULL         NULL   \n",
       "\n",
       "  Nasabah_Prioritas Notify_By Organization Output_Settlement phone_survey  \\\n",
       "0                No      None     Bank BRI              NULL         NULL   \n",
       "\n",
       "  Return_Ticket Settlement_By Settlement_ID Settlement  \\\n",
       "0          NULL          NULL          NULL         No   \n",
       "\n",
       "                  Site_User Status_Return Status_Transaksi Submitter_Region  \\\n",
       "0  00196 -- KANWIL Semarang          NULL             NULL         Semarang   \n",
       "\n",
       "  Submitter_SiteGroup Submitter_User_group_ID Tanggal_Settlement Tgl_Foward  \\\n",
       "0     KANWIL Semarang                       4               NULL       NULL   \n",
       "\n",
       "  Tgl_In_Progress Tgl_Returned Ticket_Referensi Tiket_Urgency Tipe_Remark  \\\n",
       "0            NULL         NULL             NULL          NULL       Notes   \n",
       "\n",
       "  UniqueID users Usergroup_ID  \n",
       "0     NULL  Call            4  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the column names\n",
    "column_names = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \"Nama_Nasabah\", \n",
    "    \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \n",
    "    \"user_group\", \"assgined_to\", \"attachment_done\", \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \n",
    "    \"approver_name\", \"SLAResolution\", \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \n",
    "    \"Jenis_Produk\", \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \"TID\", \n",
    "    \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \"Bank_BRI\", \n",
    "    \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \"Hasil_Kunjungan\", \"Log_Name\", \n",
    "    \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \n",
    "    \"Notify_By\", \"Organization\", \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \n",
    "    \"Settlement_ID\", \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "    \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \"Tgl_In_Progress\", \n",
    "    \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "]\n",
    "\n",
    "def parse_file(file_path):\n",
    "    # Initialize a list to hold the parsed data\n",
    "    data = []\n",
    "    date_pattern = re.compile(r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}')\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(';')\n",
    "            # Find the index of the first date (fourth column in your description)\n",
    "            date_index = next(i for i, part in enumerate(parts) if date_pattern.match(part))\n",
    "\n",
    "            # Extract columns\n",
    "            ticket_id = parts[0]  # First column\n",
    "            call_type_id = parts[1]  # Second column\n",
    "            description = ';'.join(parts[2:date_index])  # Third column, concatenating all parts up to the date\n",
    "            create_date = parts[date_index]  # Fourth column, the first date found\n",
    "\n",
    "            # Append the parsed columns and the rest of the data\n",
    "            data.append([ticket_id, call_type_id, description, create_date] + parts[date_index + 1:])\n",
    "\n",
    "    # Create DataFrame with the specified column names\n",
    "    df = pd.DataFrame(data, columns=column_names)\n",
    "\n",
    "    # Convert 'Create_Date' to datetime\n",
    "    df['Create_Date'] = pd.to_datetime(df['Create_Date'], errors='coerce', format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\maste\\Downloads\\bricare_case_januari2023_1masking.txt\"\n",
    "df = parse_file(file_path)\n",
    "\n",
    "# Display\n",
    "df=df.iloc[:1]\n",
    "df.iloc[:1].to_csv(\"oneline.csv\",index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

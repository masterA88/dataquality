{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: list index out of range\n",
      "['\\ufeffTTB000043833962', '8701', 'Blokir Kartu ATM karena kartu hilang', '2023-01-01 07:08:31.000', 'Phone', 'Maintenance', 'WATI SUSILAWATI', '436101009806534', '0.00', 'Closed', '2023-01-01 07:08:50.000', '2023-01-01 00:00:00.000', 'N/A', 'Blokir Kartu', '6013013389522694', 'LCC-CCTCALL', 'NULL', 'NULL', 'NULL', 'Novita Ayu Lestari', '085845602167', 'NULL', 'NULL', '20', 'SMG61072', '00196 -- KANWIL Semarang', 'Novita Ayu Lestari', 'Nasabah mengajukan pemblokiran kartu ATM BRI']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# List to store extracted data\n",
    "extracted_data = []\n",
    "\n",
    "try:\n",
    "    # Open the file in read mode\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        # Create a reader object to parse the CSV\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "        \n",
    "        # Iterate over each row in the CSV file\n",
    "        for row in reader:\n",
    "            # Assuming the data is located in a specific column, e.g., the first column\n",
    "            if \"TTB000043833962\" in row[0]:\n",
    "                extracted_data.append(row)  # Append the entire row if the ID is found\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "# Print the extracted data\n",
    "for data in extracted_data:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket_ID: TTB000043833962\n",
      "Call_Type_ID: 8701\n",
      "Call_Type: Blokir Kartu ATM karena kartu hilang\n",
      "Create_Date: 2023-01-01 07:08:31.000\n",
      "Phone: Phone\n",
      "Maintenance: Maintenance\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# File path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Regular expression patterns for the data points you listed\n",
    "patterns = {\n",
    "    \"Ticket_ID\": re.compile(r\"TTB\\d+\"),\n",
    "    \"Call_Type_ID\": re.compile(r\"\\b\\d{4}\\b\"),\n",
    "    \"Call_Type\": re.compile(r\"Blokir Kartu ATM karena kartu hilang\"),\n",
    "    \"Create_Date\": re.compile(r\"\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}\"),\n",
    "    \"gateway\": re.compile(r\"Phone\"),\n",
    "    \"Maintenance\": re.compile(r\"Maintenance\"),\n",
    "    # Add more patterns as necessary\n",
    "}\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = {key: None for key in patterns}\n",
    "\n",
    "# Read the file and search for patterns\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        for key, pattern in patterns.items():\n",
    "            match = pattern.search(content)\n",
    "            if match:\n",
    "                results[key] = match.group()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to read or process the file: {str(e)}\")\n",
    "\n",
    "# Display the results\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [\n",
    "        \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "        \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "        \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assgined_to\", \"attachment_done\", \n",
    "        \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "        \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \"Jenis_Produk\", \n",
    "        \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \n",
    "        \"TID\", \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \n",
    "        \"Bank_BRI\", \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \n",
    "        \"Hasil_Kunjungan\", \"Log_Name\", \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \n",
    "        \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \"Notify_By\", \"Organization\", \n",
    "        \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \"Settlement_ID\", \n",
    "        \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "        \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \n",
    "        \"Tgl_In_Progress\", \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \n",
    "        \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "    ]\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "col = [\n",
    "        \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "        \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "        \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assgined_to\", \"attachment_done\", \n",
    "        \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "        \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\", \"Details\", \"Jenis_Produk\", \n",
    "        \"Last_Modified_By\", \"Merchant_ID\", \"Modified_Date\", \"NOTAS\", \"Produk\", \"SLA_Status\", \n",
    "        \"TID\", \"tanggalAttachmentDone\", \"Tgl_Assigned\", \"Tgl_Eskalasi\", \"AnalisaSkils\", \"Attachment_\", \n",
    "        \"Bank_BRI\", \"Biaya_Admin\", \"Suku_Bunga\", \"Bunga\", \"Butuh_Attachment\", \"Cicilan\", \n",
    "        \"Hasil_Kunjungan\", \"Log_Name\", \"MMS_Ticket_Id\", \"Mass_Ticket_Upload_Flag\", \"Nama_Supervisor\", \n",
    "        \"Nama_TL\", \"Nama_Wakabag\", \"Nasabah_Prioritas\", \"Notify_By\", \"Organization\", \n",
    "        \"Output_Settlement\", \"phone_survey\", \"Return_Ticket\", \"Settlement_By\", \"Settlement_ID\", \n",
    "        \"Settlement\", \"Site_User\", \"Status_Return\", \"Status_Transaksi\", \"Submitter_Region\", \n",
    "        \"Submitter_SiteGroup\", \"Submitter_User_group_ID\", \"Tanggal_Settlement\", \"Tgl_Foward\", \n",
    "        \"Tgl_In_Progress\", \"Tgl_Returned\", \"Ticket_Referensi\", \"Tiket_Urgency\", \"Tipe_Remark\", \n",
    "        \"UniqueID\", \"users\", \"Usergroup_ID\"\n",
    "    ]\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "def process_csv_with_complex_column(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the entire file content into a single string to process it line by line\n",
    "        content = file.read()\n",
    "        \n",
    "        # Split the content into rows based on a pattern that indicates the end of a complex entry\n",
    "        rows = content.split('================')  # This splits each \"block\" that should end up in Column 28\n",
    "        data = []\n",
    "\n",
    "        for row in rows:\n",
    "            # Split each row by commas up to Column 27, handle Column 28 separately, then continue after Column 28\n",
    "            parts = row.split(',')\n",
    "            if len(parts) > 29:  # Ensuring there are enough parts to form all columns\n",
    "                # The first 27 columns + the entire block of text that goes into Column 28\n",
    "                first_part = parts[:27]\n",
    "                col28 = ','.join(parts[27:-51])  # Joining parts that form the complex Column 28 (adjust range as needed)\n",
    "                last_part = parts[-51:]  # Remaining columns after Column 28\n",
    "                \n",
    "                # Combine all parts into a single row, ensuring 79 columns total\n",
    "                full_row = first_part + [col28] + last_part\n",
    "                if len(full_row) == 79:\n",
    "                    data.append(full_row)\n",
    "\n",
    "    # Create a DataFrame from the processed data\n",
    "    return pd.DataFrame(data, columns=col)\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path_v2 = file_path\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_v4 = process_csv_with_complex_column(csv_file_path_v2)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_v4_sample = structured_df_v4.head(10) if not structured_df_v4.empty else \"No data processed correctly.\"\n",
    "df2=structured_df_v4_sample.transpose()\n",
    "pd.set_option('display.max_columns', None)\n",
    "df2.to_csv(\"data_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>Column 10</th>\n",
       "      <th>Column 11</th>\n",
       "      <th>Column 12</th>\n",
       "      <th>Column 13</th>\n",
       "      <th>Column 14</th>\n",
       "      <th>Column 15</th>\n",
       "      <th>Column 16</th>\n",
       "      <th>Column 17</th>\n",
       "      <th>Column 18</th>\n",
       "      <th>Column 19</th>\n",
       "      <th>Column 20</th>\n",
       "      <th>Column 21</th>\n",
       "      <th>Column 22</th>\n",
       "      <th>Column 23</th>\n",
       "      <th>Column 24</th>\n",
       "      <th>Column 25</th>\n",
       "      <th>Column 26</th>\n",
       "      <th>Column 27</th>\n",
       "      <th>Column 28</th>\n",
       "      <th>Column 29</th>\n",
       "      <th>Column 30</th>\n",
       "      <th>Column 31</th>\n",
       "      <th>Column 32</th>\n",
       "      <th>Column 33</th>\n",
       "      <th>Column 34</th>\n",
       "      <th>Column 35</th>\n",
       "      <th>Column 36</th>\n",
       "      <th>Column 37</th>\n",
       "      <th>Column 38</th>\n",
       "      <th>Column 39</th>\n",
       "      <th>Column 40</th>\n",
       "      <th>Column 41</th>\n",
       "      <th>Column 42</th>\n",
       "      <th>Column 43</th>\n",
       "      <th>Column 44</th>\n",
       "      <th>Column 45</th>\n",
       "      <th>Column 46</th>\n",
       "      <th>Column 47</th>\n",
       "      <th>Column 48</th>\n",
       "      <th>Column 49</th>\n",
       "      <th>Column 50</th>\n",
       "      <th>Column 51</th>\n",
       "      <th>Column 52</th>\n",
       "      <th>Column 53</th>\n",
       "      <th>Column 54</th>\n",
       "      <th>Column 55</th>\n",
       "      <th>Column 56</th>\n",
       "      <th>Column 57</th>\n",
       "      <th>Column 58</th>\n",
       "      <th>Column 59</th>\n",
       "      <th>Column 60</th>\n",
       "      <th>Column 61</th>\n",
       "      <th>Column 62</th>\n",
       "      <th>Column 63</th>\n",
       "      <th>Column 64</th>\n",
       "      <th>Column 65</th>\n",
       "      <th>Column 66</th>\n",
       "      <th>Column 67</th>\n",
       "      <th>Column 68</th>\n",
       "      <th>Column 69</th>\n",
       "      <th>Column 70</th>\n",
       "      <th>Column 71</th>\n",
       "      <th>Column 72</th>\n",
       "      <th>Column 73</th>\n",
       "      <th>Column 74</th>\n",
       "      <th>Column 75</th>\n",
       "      <th>Column 76</th>\n",
       "      <th>Column 77</th>\n",
       "      <th>Column 78</th>\n",
       "      <th>Column 79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>085845602167</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>Nasabah mengajukan pemblokiran kartu ATM BRI</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Permintaan pemblokiran ATM BRI.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alasan pemblokiran : Hilang</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tanggal Hilang : 31.12.2022</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jam Hilang : 21.00</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lokasi Kejadian : bri cikunir</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tanggal Pemblokiran :  01/01/2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jam Pemblokiran :  07:06 wib</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>================</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Column 1 Column 2  \\\n",
       "0                    ﻿TTB000043833962     8701   \n",
       "1     Permintaan pemblokiran ATM BRI.            \n",
       "2         Alasan pemblokiran : Hilang            \n",
       "3         Tanggal Hilang : 31.12.2022            \n",
       "4                  Jam Hilang : 21.00            \n",
       "5       Lokasi Kejadian : bri cikunir            \n",
       "6  Tanggal Pemblokiran :  01/01/2023             \n",
       "7        Jam Pemblokiran :  07:06 wib            \n",
       "8                                                \n",
       "9                    ================            \n",
       "\n",
       "                               Column 3                 Column 4 Column 5  \\\n",
       "0  Blokir Kartu ATM karena kartu hilang  2023-01-01 07:08:31.000    Phone   \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "5                                                                           \n",
       "6                                                                           \n",
       "7                                                                           \n",
       "8                                                                           \n",
       "9                                                                           \n",
       "\n",
       "      Column 6         Column 7         Column 8 Column 9 Column 10  \\\n",
       "0  Maintenance  WATI SUSILAWATI  436101009806534     0.00    Closed   \n",
       "1                                                                     \n",
       "2                                                                     \n",
       "3                                                                     \n",
       "4                                                                     \n",
       "5                                                                     \n",
       "6                                                                     \n",
       "7                                                                     \n",
       "8                                                                     \n",
       "9                                                                     \n",
       "\n",
       "                 Column 11                Column 12 Column 13     Column 14  \\\n",
       "0  2023-01-01 07:08:50.000  2023-01-01 00:00:00.000       N/A  Blokir Kartu   \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "5                                                                             \n",
       "6                                                                             \n",
       "7                                                                             \n",
       "8                                                                             \n",
       "9                                                                             \n",
       "\n",
       "          Column 15    Column 16 Column 17 Column 18 Column 19  \\\n",
       "0  6013013389522694  LCC-CCTCALL      NULL      NULL      NULL   \n",
       "1                                                                \n",
       "2                                                                \n",
       "3                                                                \n",
       "4                                                                \n",
       "5                                                                \n",
       "6                                                                \n",
       "7                                                                \n",
       "8                                                                \n",
       "9                                                                \n",
       "\n",
       "            Column 20     Column 21 Column 22 Column 23 Column 24 Column 25  \\\n",
       "0  Novita Ayu Lestari  085845602167      NULL      NULL        20  SMG61072   \n",
       "1                                                                             \n",
       "2                                                                             \n",
       "3                                                                             \n",
       "4                                                                             \n",
       "5                                                                             \n",
       "6                                                                             \n",
       "7                                                                             \n",
       "8                                                                             \n",
       "9                                                                             \n",
       "\n",
       "                  Column 26           Column 27  \\\n",
       "0  00196 -- KANWIL Semarang  Novita Ayu Lestari   \n",
       "1                                                 \n",
       "2                                                 \n",
       "3                                                 \n",
       "4                                                 \n",
       "5                                                 \n",
       "6                                                 \n",
       "7                                                 \n",
       "8                                                 \n",
       "9                                                 \n",
       "\n",
       "                                      Column 28 Column 29 Column 30 Column 31  \\\n",
       "0  Nasabah mengajukan pemblokiran kartu ATM BRI                                 \n",
       "1                                                                               \n",
       "2                                                                               \n",
       "3                                                                               \n",
       "4                                                                               \n",
       "5                                                                               \n",
       "6                                                                               \n",
       "7                                                                               \n",
       "8                                                                               \n",
       "9                                                                               \n",
       "\n",
       "  Column 32 Column 33 Column 34 Column 35 Column 36 Column 37 Column 38  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 39 Column 40 Column 41 Column 42 Column 43 Column 44 Column 45  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 46 Column 47 Column 48 Column 49 Column 50 Column 51 Column 52  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 53 Column 54 Column 55 Column 56 Column 57 Column 58 Column 59  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 60 Column 61 Column 62 Column 63 Column 64 Column 65 Column 66  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 67 Column 68 Column 69 Column 70 Column 71 Column 72 Column 73  \\\n",
       "0                                                                         \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3                                                                         \n",
       "4                                                                         \n",
       "5                                                                         \n",
       "6                                                                         \n",
       "7                                                                         \n",
       "8                                                                         \n",
       "9                                                                         \n",
       "\n",
       "  Column 74 Column 75 Column 76 Column 77 Column 78 Column 79  \n",
       "0                                                              \n",
       "1                                                              \n",
       "2                                                              \n",
       "3                                                              \n",
       "4                                                              \n",
       "5                                                              \n",
       "6                                                              \n",
       "7                                                              \n",
       "8                                                              \n",
       "9                                                              "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Initialize a list to store the processed rows\n",
    "        data = []\n",
    "        \n",
    "        # Read the file line by line\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            # Extract the first 27 columns directly\n",
    "            if len(row) < 79:\n",
    "                # Append empty fields if row is not long enough (handling potential errors in CSV formatting)\n",
    "                row += [''] * (79 - len(row))\n",
    "            \n",
    "            # Columns 1-27 are directly taken from the row based on your mapping\n",
    "            first_part = row[:27]\n",
    "            \n",
    "            # Column 28: Aggregating complex block data into one column (Example aggregation logic needed)\n",
    "            complex_data = ' '.join(row[27:28])  # Assuming we collect multiple pieces into one column here\n",
    "            \n",
    "            # Remaining columns, from 29 to 79\n",
    "            last_part = row[28:]\n",
    "\n",
    "            # Combine the parts into a full row ensuring it matches the expected 79 columns format\n",
    "            full_row = first_part + [complex_data] + last_part[:51]  # Adjust the slicing based on actual content need\n",
    "            if len(full_row) == 79:\n",
    "                data.append(full_row)\n",
    "            else:\n",
    "                # Padding in case there are missing columns to ensure each row has exactly 79 columns\n",
    "                full_row += [''] * (79 - len(full_row))\n",
    "                data.append(full_row)\n",
    "\n",
    "    # Create a DataFrame from the processed data\n",
    "    return pd.DataFrame(data, columns=[f\"Column {i+1}\" for i in range(79)])\n",
    "\n",
    "# Path to the updated CSV file\n",
    "updated_csv_file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(updated_csv_file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Display a sample of the structured data\n",
    "pd.set_option('display.max_columns', None)\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "# structured_df_final_sample['Column 1'] = structured_df_final_sample['Column 1'].apply(lambda x: x if x.startswith('TTB') and len(x) == 15 else None)\n",
    "# structured_df_final_sample['Column 1'] = structured_df_final_sample.dropna(subset=['Column 1'])\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st 27 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>Column 10</th>\n",
       "      <th>Column 11</th>\n",
       "      <th>Column 12</th>\n",
       "      <th>Column 13</th>\n",
       "      <th>Column 14</th>\n",
       "      <th>Column 15</th>\n",
       "      <th>Column 16</th>\n",
       "      <th>Column 17</th>\n",
       "      <th>Column 18</th>\n",
       "      <th>Column 19</th>\n",
       "      <th>Column 20</th>\n",
       "      <th>Column 21</th>\n",
       "      <th>Column 22</th>\n",
       "      <th>Column 23</th>\n",
       "      <th>Column 24</th>\n",
       "      <th>Column 25</th>\n",
       "      <th>Column 26</th>\n",
       "      <th>Column 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>8.584560e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column 1 Column 2                              Column 3  \\\n",
       "0  TTB000043833962     8701  Blokir Kartu ATM karena kartu hilang   \n",
       "\n",
       "                  Column 4 Column 5     Column 6         Column 7  \\\n",
       "0  2023-01-01 07:08:31.000    Phone  Maintenance  WATI SUSILAWATI   \n",
       "\n",
       "          Column 8  Column 9 Column 10                Column 11  \\\n",
       "0  436101009806534       0.0    Closed  2023-01-01 07:08:50.000   \n",
       "\n",
       "                 Column 12  Column 13     Column 14         Column 15  \\\n",
       "0  2023-01-01 00:00:00.000        NaN  Blokir Kartu  6013013389522694   \n",
       "\n",
       "     Column 16  Column 17  Column 18 Column 19           Column 20  \\\n",
       "0  LCC-CCTCALL        NaN        NaN       NaN  Novita Ayu Lestari   \n",
       "\n",
       "      Column 21 Column 22  Column 23 Column 24 Column 25  \\\n",
       "0  8.584560e+10       NaN        NaN        20  SMG61072   \n",
       "\n",
       "                  Column 26           Column 27  \n",
       "0  00196 -- KANWIL Semarang  Novita Ayu Lestari  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "column_headers = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "    \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "    \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assigned_to\", \"attachment_done\", \n",
    "    \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "    \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\"\n",
    "]\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    # Load the CSV file into a DataFrame, processing only the necessary columns (first 27 columns)\n",
    "    df = pd.read_csv(file_path, usecols=range(27), header=None)\n",
    "\n",
    "    df = df.iloc[:1]\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    df.columns = [f\"Column {i+1}\" for i in range(27)]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(file_path)\n",
    "\n",
    "# Set display options for better output visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket_ID</th>\n",
       "      <th>Call_Type_ID</th>\n",
       "      <th>Call_Type</th>\n",
       "      <th>Create_Date</th>\n",
       "      <th>gateway</th>\n",
       "      <th>Jenis_Laporan</th>\n",
       "      <th>Nama_Nasabah</th>\n",
       "      <th>No_Rekening</th>\n",
       "      <th>Nominal</th>\n",
       "      <th>status</th>\n",
       "      <th>TanggalClosed</th>\n",
       "      <th>tanggalTransaksi</th>\n",
       "      <th>Chanel</th>\n",
       "      <th>Fitur</th>\n",
       "      <th>Nomor_Kartu</th>\n",
       "      <th>user_group</th>\n",
       "      <th>assigned_to</th>\n",
       "      <th>attachment_done</th>\n",
       "      <th>email</th>\n",
       "      <th>full_name</th>\n",
       "      <th>no_telepon</th>\n",
       "      <th>approver_login</th>\n",
       "      <th>approver_name</th>\n",
       "      <th>SLAResolution</th>\n",
       "      <th>submitter_login_id</th>\n",
       "      <th>submitter_user_group</th>\n",
       "      <th>user_login_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTB000043833962</td>\n",
       "      <td>8701</td>\n",
       "      <td>Blokir Kartu ATM karena kartu hilang</td>\n",
       "      <td>2023-01-01 07:08:31.000</td>\n",
       "      <td>Phone</td>\n",
       "      <td>Maintenance</td>\n",
       "      <td>WATI SUSILAWATI</td>\n",
       "      <td>436101009806534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2023-01-01 07:08:50.000</td>\n",
       "      <td>2023-01-01 00:00:00.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blokir Kartu</td>\n",
       "      <td>6013013389522694</td>\n",
       "      <td>LCC-CCTCALL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "      <td>8.584560e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>SMG61072</td>\n",
       "      <td>00196 -- KANWIL Semarang</td>\n",
       "      <td>Novita Ayu Lestari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ticket_ID Call_Type_ID                             Call_Type  \\\n",
       "0  TTB000043833962         8701  Blokir Kartu ATM karena kartu hilang   \n",
       "\n",
       "               Create_Date gateway Jenis_Laporan     Nama_Nasabah  \\\n",
       "0  2023-01-01 07:08:31.000   Phone   Maintenance  WATI SUSILAWATI   \n",
       "\n",
       "       No_Rekening  Nominal  status            TanggalClosed  \\\n",
       "0  436101009806534      0.0  Closed  2023-01-01 07:08:50.000   \n",
       "\n",
       "          tanggalTransaksi  Chanel         Fitur       Nomor_Kartu  \\\n",
       "0  2023-01-01 00:00:00.000     NaN  Blokir Kartu  6013013389522694   \n",
       "\n",
       "    user_group  assigned_to  attachment_done email           full_name  \\\n",
       "0  LCC-CCTCALL          NaN              NaN   NaN  Novita Ayu Lestari   \n",
       "\n",
       "     no_telepon approver_login  approver_name SLAResolution  \\\n",
       "0  8.584560e+10            NaN            NaN            20   \n",
       "\n",
       "  submitter_login_id      submitter_user_group     user_login_name  \n",
       "0           SMG61072  00196 -- KANWIL Semarang  Novita Ayu Lestari  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path for the CSV file\n",
    "file_path = r\"D:\\bricare data 1.csv\"\n",
    "\n",
    "# Specified column headers\n",
    "column_headers = [\n",
    "    \"Ticket_ID\", \"Call_Type_ID\", \"Call_Type\", \"Create_Date\", \"gateway\", \"Jenis_Laporan\", \n",
    "    \"Nama_Nasabah\", \"No_Rekening\", \"Nominal\", \"status\", \"TanggalClosed\", \"tanggalTransaksi\", \n",
    "    \"Chanel\", \"Fitur\", \"Nomor_Kartu\", \"user_group\", \"assigned_to\", \"attachment_done\", \n",
    "    \"email\", \"full_name\", \"no_telepon\", \"approver_login\", \"approver_name\", \"SLAResolution\", \n",
    "    \"submitter_login_id\", \"submitter_user_group\", \"user_login_name\"\n",
    "]\n",
    "\n",
    "def process_csv_with_defined_columns(file_path):\n",
    "    # Load the CSV file into a DataFrame, processing only the necessary columns (first 27 columns)\n",
    "    df = pd.read_csv(file_path, usecols=range(27), header=None)\n",
    "\n",
    "    df = df.iloc[:1]\n",
    "\n",
    "    # Rename columns using the specified column headers\n",
    "    df.columns = column_headers\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process the CSV and get the structured DataFrame\n",
    "structured_df_final = process_csv_with_defined_columns(file_path)\n",
    "\n",
    "# Set display options for better output visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Display a sample of the structured data\n",
    "structured_df_final_sample = structured_df_final.head(10) if not structured_df_final.empty else \"No data processed correctly.\"\n",
    "structured_df_final_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Splitting the text into a more manageable format\n",
    "    # Assume we split at the first occurrence of '================'\n",
    "    parts = text.split('================', 1)\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    # Column 1 will have 'Aku', Column 2 will have the rest of the text after '================'\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [\"Aku\"],\n",
    "        \"Column 2\": [parts[1].strip()]  # Using strip to remove leading/trailing whitespace\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace 'path_to_your_file.txt' with the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Splitting the text to extract the third column value\n",
    "    # Assume 'Tabungan' or similar values are added after the final '================,' so we split there first\n",
    "    parts = text.split('================,')\n",
    "    third_column_value = parts[1].strip() if len(parts) > 1 else \"Missing Value\"\n",
    "    \n",
    "    # Now split the first part further to separate out the main content\n",
    "    main_content_parts = parts[0].split('================', 1)\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    # Column 1 will have 'Aku', Column 2 will have the content after the first '================',\n",
    "    # and Column 3 will have the value from the third column\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [\"Aku\"],\n",
    "        \"Column 2\": [main_content_parts[1].strip() if len(main_content_parts) > 1 else \"Missing Content\"],  # Handle missing content\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Replace 'path_to_your_file.txt' with the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# search the ================, and set the value to be the value for the next column\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## great for 3 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Find the beginning of the content after \"Aku,\" to set up for Column 2\n",
    "    first_column_value = \"Aku\"\n",
    "    second_column_start = main_content.find(\"Aku,\") + len(\"Aku,\")\n",
    "    second_column_value = main_content[second_column_start:].strip()  # Remove any leading/trailing whitespace\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\" \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "# df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "\n",
    "df.to_csv(\"new_.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column 4 starting from Kode ..., Column 5= empty, Column 6 Tabungan1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text using '================' as a separator\n",
    "    parts = text.split('================')\n",
    "    \n",
    "    # Assume the first line contains the labels for the first three columns, which are static\n",
    "    header_labels = parts[0].strip().split('\\n')[0].split(',')\n",
    "    if len(header_labels) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"Header format is not as expected. Check the first line for correct labels.\"]})\n",
    "\n",
    "    # Extracting the main body for Column 4, which includes multiple '================' sections\n",
    "    column4_content = '================'.join(parts[1:-1]).strip()\n",
    "\n",
    "    # Extract the last part for Columns 5 and 6\n",
    "    footer_labels = parts[-1].split(',')\n",
    "    if len(footer_labels) < 2:\n",
    "        return pd.DataFrame({\"Error\": [\"Footer format is not as expected. Insufficient labels after the last '================'.\"]})\n",
    "\n",
    "    # Trim and prepare the labels for the last two columns\n",
    "    column5_label = footer_labels[0].strip()\n",
    "    column6_label = footer_labels[1].strip()\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [header_labels[0].strip()],\n",
    "        \"Column 2\": [header_labels[1].strip()],\n",
    "        \"Column 3\": [header_labels[2].strip()],\n",
    "        \"Column 4\": [column4_content],\n",
    "        \"Column 5\": [column5_label],\n",
    "        \"Column 6\": [column6_label]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new4_.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text using '================' as a separator to isolate the main content and footer\n",
    "    parts = text.split('================')\n",
    "    if len(parts) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"The text does not contain enough sections separated by '================'.\"]})\n",
    "\n",
    "    # Extracting the main body for Column 4, assumed to be between the first and second '================'\n",
    "    column4_content = '\\n================\\n'.join(parts[1:-1]).strip()\n",
    "\n",
    "    # Extract the footer content right after the last '================'\n",
    "    # Assuming the footer starts with Tabungan1, Tabungan2 right after the last '================'\n",
    "    # footer_content = parts[-1].split(',')\n",
    "    # if len(footer_content) < 2:\n",
    "    #     return pd.DataFrame({\"Error\": [\"Footer content is not formatted as expected. Ensure it follows the last '================'.\"]})\n",
    "\n",
    "    footer_content=text.split('================,', 1)\n",
    "    # The first header should contain main labels if structured as expected\n",
    "    header_labels = parts[0].strip().split('\\n')[0].split(',')\n",
    "    if len(header_labels) < 3:\n",
    "        return pd.DataFrame({\"Error\": [\"Header labels are missing or incomplete.\"]})\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [header_labels[0].strip()],\n",
    "        \"Column 2\": [header_labels[1].strip()],\n",
    "        \"Column 3\": [header_labels[2].strip()],\n",
    "        \"Column 4\": [column4_content],\n",
    "        \"Column 5\": [footer_content[0].strip()]\n",
    "        # \"Column 5\": [footer_content[0].strip()],\n",
    "        # \"Column 6\": [footer_content[1].strip()]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"\n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new5_.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare2.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "df.to_csv(\"new_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Column0 Column1\n",
      "0    Tab1    Tab2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with one column\n",
    "df = pd.DataFrame({'Column1': ['Tab1, Tab2']})\n",
    "\n",
    "# Split the single value in the column by comma (assuming there's only one comma)\n",
    "split_values = df['Column1'].str.split(',', expand=True)\n",
    "\n",
    "# Rename columns (optional)\n",
    "split_values.columns = ['Column0', 'Column1']\n",
    "\n",
    "# Update the DataFrame\n",
    "df = split_values.copy()\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main</td>\n",
       "      <td>Nasabah mengajukan pemblokiran kartu ATM BRI\\n...</td>\n",
       "      <td>Tabungan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Column 1                                           Column 2  Column 3\n",
       "0     Main  Nasabah mengajukan pemblokiran kartu ATM BRI\\n...  Tabungan"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    # Split the text to separate out the third column value which is after '================,'\n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()  # Clean up whitespace\n",
    "\n",
    "    # Extract the first value dynamically before the first comma for Column 1\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "\n",
    "    # Extract everything after the first comma for Column 2\n",
    "    if len(main_content.split(',', 1)) > 1:\n",
    "        second_column_value = main_content.split(',', 1)[1].strip()\n",
    "    else:\n",
    "        second_column_value = \"Content Missing\"\n",
    "\n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Provide the path to your text file\n",
    "file_path = r\"D:\\test_bricare.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "# df.to_csv(\"new_.csv\")\n",
    "df.to_csv(\"newbig_.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# file_path=r\"D:\\dataquality\\new_.csv\"\n",
    "file_path=r\"D:\\dataquality\\newbig_.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "column_2_expanded = data['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = data['Column 3'].str.split(',', expand=True)\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Naming the new columns\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "# Inserting these new columns before the original 'Column 2' and 'Column 3'\n",
    "new_data = pd.concat([data.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"new_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRICARE cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Column 1                                         Column_2_1 Column_3_1\n",
      "0     Main  Nasabah mengajukan pemblokiran kartu ATM BRI\\n...   Tabungan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_dataframe_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    main_content, third_column_value = text.split('================,', 1)\n",
    "    third_column_value = third_column_value.strip()\n",
    "\n",
    "    first_column_value = main_content.split(',', 1)[0].strip()\n",
    "    second_column_value = main_content.split(',', 1)[1].strip() if len(main_content.split(',', 1)) > 1 else \"Content Missing\"\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Column 1\": [first_column_value],\n",
    "        \"Column 2\": [second_column_value],\n",
    "        \"Column 3\": [third_column_value]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "file_path = r\"D:\\test_bricare.txt\"  \n",
    "df = create_dataframe_from_file(file_path)\n",
    "\n",
    "column_2_expanded = df['Column 2'].str.split(',', expand=True)\n",
    "column_3_expanded = df['Column 3'].str.split(',', expand=True)\n",
    "\n",
    "column_2_expanded.columns = [f'Column_2_{i+1}' for i in range(column_2_expanded.shape[1])]\n",
    "column_3_expanded.columns = [f'Column_3_{i+1}' for i in range(column_3_expanded.shape[1])]\n",
    "\n",
    "new_data = pd.concat([df.drop(['Column 2', 'Column 3'], axis=1), column_2_expanded, column_3_expanded], axis=1)\n",
    "\n",
    "new_data.to_csv(\"new_data.csv\")\n",
    "print(new_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
